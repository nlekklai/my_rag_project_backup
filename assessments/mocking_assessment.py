# assessments/mocking_assessment.py
"""
Mocking Assessment Utilities
‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏£‡∏∞‡∏ö‡∏ö KM/Enabler Assessment ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏à‡∏£‡∏¥‡∏á
"""

import random
import logging
from typing import Dict, Any, List

logger = logging.getLogger(__name__)


# -------------------------------------------------------
# MOCK: Controlled LLM Evaluation (Deterministic)
# -------------------------------------------------------
def evaluate_with_llm_CONTROLLED_MOCK(
    statement: str,
    context: str,
    # üí° NOTE: level ‡πÅ‡∏•‡∏∞ statement_number ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤ Default ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô kwargs
    level: int = 1,
    sub_criteria_id: str = "UNKNOWN",
    statement_number: int = 1,
    **kwargs
) -> Dict[str, Any]:
    """
    Mock ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö (‡πÉ‡∏ä‡πâ‡πÅ‡∏ó‡∏ô LLM ‡∏à‡∏£‡∏¥‡∏á)

    - L1: ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (100%)
    - L2: ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Statement ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏µ‡πà (2/3)
    - L3: ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (100%)
    - L4, L5: ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (0%)
    """
    
    # üö® FIX 1: ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ level, sub_criteria_id, statement_number ‡∏à‡∏≤‡∏Å kwargs 
    # ‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà EnablerAssessment.run_assessment ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤
    level = kwargs.get("level", level)
    sub_criteria_id = kwargs.get("sub_criteria_id", sub_criteria_id)
    statement_number = kwargs.get("statement_number", statement_number)

    # üéØ ‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏ö‡∏ö‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°
    if level == 1:
        score = 1 # L1: ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    elif level == 2:
        score = 1 if statement_number % 2 == 1 else 0 # L2: ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Statement ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏µ‡πà (S1, S3)
    elif level == 3:
        score = 1 # L3: ‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    elif level in [4, 5]:
        score = 0 # L4, L5: ‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    else:
        score = 0 

    is_passed = score == 1
    
    # ‚≠ê Mock Context ‡πÅ‡∏•‡∏∞ Sources ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ EnablerAssessment.run_assessment ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô
    mock_context_snippet = f"[MOCK CONTEXT SNIPPET] Evidence found for {sub_criteria_id} L{level} S{statement_number}." if is_passed else ""
    mock_sources = [
        {"source_name": f"mock_doc_L{level}_S{statement_number}.pdf", "location": f"page_{10+statement_number}", "doc_id": f"DOC_{sub_criteria_id}"}
    ] if is_passed else []


    result = {
        "sub_criteria_id": sub_criteria_id,
        "level": level,
        "statement_number": statement_number,
        "statement": statement,
        
        # 3. ‡πÉ‡∏ä‡πâ Mock Context/Sources ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤
        "context_retrieved_snippet": mock_context_snippet, 
        "retrieved_sources_list": mock_sources,
        
        # üö® FIX 2: score ‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡∏≤‡∏°‡∏ï‡∏£‡∏£‡∏Å‡∏∞ Mock (1 ‡∏´‡∏£‡∏∑‡∏≠ 0)
        "llm_score": score, 
        
        # üö® NEW: ‡πÉ‡∏™‡πà 'score' ‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏Å‡∏±‡∏ö Real LLM Eval Function
        "score": score, 
        
        "reason": f"MOCK reason for L{level} S{statement_number} ‚Üí {'PASS' if is_passed else 'FAIL'} (Controlled Mock)",
        
        # ‚≠ê ‡∏Å‡∏≥‡∏´‡∏ô‡∏î pass_status ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        "pass_status": is_passed,
        "status_th": "‡∏ú‡πà‡∏≤‡∏ô" if is_passed else "‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô",
        "llm_result": {"is_passed": is_passed, "score": float(score)}
    }

    return result


# -------------------------------------------------------
# MOCK: Retrieval
# -------------------------------------------------------
def retrieve_context_MOCK(statement: str, sub_criteria_id: str, level: int, statement_number: int, mapping_data=None, **kwargs) -> Dict[str, Any]:
    """
    Mock retrieval context ‡∏à‡∏≤‡∏Å Vectorstore (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á)
    """
    fake_sources = [
        {"source_name": f"MOCK_DOC_{sub_criteria_id}_L{level}.pdf", "location": f"page_{10+statement_number}", "doc_id": f"DOC_{sub_criteria_id}"}
    ]
    # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö Reranking Logic (‡∏´‡∏≤‡∏Å‡∏°‡∏µ)
    return {
        "top_evidences": [
            {"content": f"[MOCK EVIDENCE 1] Primary evidence for {sub_criteria_id} L{level} S{statement_number}.", "score": 0.9, "source": fake_sources[0]['source_name'], "doc_id": fake_sources[0]['doc_id'], "metadata": {"page_number": 10+statement_number}},
            {"content": f"[MOCK EVIDENCE 2] Secondary evidence for {sub_criteria_id} L{level} S{statement_number}.", "score": 0.7, "source": fake_sources[0]['source_name'], "doc_id": fake_sources[0]['doc_id'], "metadata": {"page_number": 11+statement_number}},
        ]
    }


# -------------------------------------------------------
# MOCK: Action Plan Generation
# -------------------------------------------------------
def generate_action_plan_MOCK(failed_statements_data: List[Dict[str, Any]], sub_id: str, target_level: int) -> List[Dict[str, Any]]:
    """
    Mock LLM Action Plan
    """
    actions = []
    
    # üö® FIX: ‡πÉ‡∏ä‡πâ Action Plan ‡∏ó‡∏µ‡πà‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡πà‡∏á‡∏ä‡∏µ‡πâ‡∏ñ‡∏∂‡∏á Gap 
    actions.append({
        "Statement_ID": "ALL_L1",
        "Failed_Level": target_level,
        "Recommendation": f"‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Level {target_level} (‡πÅ‡∏•‡∏∞ Level ‡∏ó‡∏µ‡πà‡∏°‡∏µ Gap ‡∏≠‡∏∑‡πà‡∏ô‡πÜ: 1, 2, 3, 4, 5) ‡πÅ‡∏•‡∏∞‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Vector Store ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ô AI Assessment ‡πÉ‡∏ô‡πÇ‡∏´‡∏°‡∏î **FULLSCOPE** ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏ß‡πà‡∏≤ Level ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå",
        "Target_Evidence_Type": "Rerunning Assessment & New Evidence",
        "Key_Metric": f"Overall Score ‡∏Ç‡∏≠‡∏á {sub_id} ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô‡πÅ‡∏•‡∏∞ Highest Full Level ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô L{target_level}"
    })
    
    # Action Plan ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô‡πÄ‡∏õ‡πá‡∏ô List ‡∏Ç‡∏≠‡∏á Phase (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö run_assessment.py)
    return [
        {
            "Phase": "2. AI Validation & Maintenance",
            "Goal": f"‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏Å‡∏≤‡∏£ Level-Up ‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L{target_level}",
            "Actions": actions
        }
    ]


# -------------------------------------------------------
# MOCK: Summarize Context (‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Evidence Summary)
# -------------------------------------------------------
def summarize_context_with_llm_MOCK(
    context: str, 
    sub_criteria_name: str, 
    level: int, 
    **kwargs # ‡∏£‡∏±‡∏ö Argument ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏≤‡∏î‡∏Ñ‡∏¥‡∏î‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
) -> Dict[str, Any]:
    """
    Mock ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (L5)
    """
    
    sub_id = kwargs.get('sub_id', 'N/A')
    
    return {
        "summary": f"[MOCK SUMMARY] ‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á {sub_criteria_name} ({sub_id}) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Level {level}. ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏à‡∏≥‡∏•‡∏≠‡∏á ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÉ‡∏ô Vector Store ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå {sub_id} Level {level}...",
        "suggestion_for_next_level": f"[MOCK SUGGESTION] ‡∏Ñ‡∏ß‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á L{level+1}"
    }


# -------------------------------------------------------
# MOCK: Set Control Mode
# -------------------------------------------------------
def set_mock_control_mode(mode: str = "default"):
    """
    ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ behavior ‡∏Ç‡∏≠‡∏á mock (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÉ‡∏ô‡∏≠‡∏ô‡∏≤‡∏Ñ‡∏ï‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ pattern)
    """
    logger.info(f"[MOCK MODE] Using mock control mode = {mode}")
    random.seed(42)
    return True