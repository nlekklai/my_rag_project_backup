# tools/ingest_statements.py
# ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó: ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Statements (‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enabler ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î
# ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Vector Store (Chroma) ‡πÉ‡∏ô Collection ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô statement_KM

import os
import sys
import argparse
import logging
import uuid
import time
from typing import Dict, Any, List

# -------------------- PATH SETUP --------------------
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏ò‡∏£‡∏π‡∏ó‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
if project_root not in sys.path:
    sys.path.append(project_root)

# -------------------- Global Vars (‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ) --------------------
try:
    # SUPPORTED_DOC_TYPES ‡∏≠‡∏≤‡∏à‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Collection Name ‡πÉ‡∏ô _get_collection_name
    from config.global_vars import SUPPORTED_DOC_TYPES 
except ImportError as e:
    print(f"FATAL ERROR: Cannot import global_vars: {e}", file=sys.stderr)
    sys.exit(1)
    
# -------------------- Core & Assessment Imports --------------------
try:
    # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ EnablerAssessment ‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏µ‡πÄ‡∏°‡∏ò‡∏≠‡∏î get_statements() ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÅ‡∏•‡πâ‡∏ß
    from assessments.enabler_assessment import EnablerAssessment
    # ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ VectorStoreManager ‡πÅ‡∏•‡∏∞‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ Collection
    from core.vectorstore import VectorStoreManager, _get_collection_name 
except ImportError as e:
    # ‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏¥‡∏î ImportError
    print(f"FATAL ERROR: Failed to import required modules (EnablerAssessment/VectorStore): {e}", file=sys.stderr)
    sys.exit(1)

# -------------------- Logging --------------------
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO, 
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# üéØ Constant ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Statements
STATEMENT_DOC_TYPE = "statement"

def ingest_all_statements(enabler_abbr: str):
    """
    ‡∏î‡∏∂‡∏á Statements ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Ç‡∏≠‡∏á Enabler ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î, ‡∏•‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤, ‡πÅ‡∏•‡∏∞ Ingest ‡πÄ‡∏Ç‡πâ‡∏≤ Vector Store ‡πÉ‡∏´‡∏°‡πà
    ‡πÉ‡∏ä‡πâ Dynamic Collection Name: statement_<enabler_abbr>
    """
    start_time = time.perf_counter()
    enabler_abbr = enabler_abbr.upper()
    logger.info(f"--- Starting Statement Ingestion for Enabler: {enabler_abbr} ---")
    
    # 1. üéØ ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Collection ‡πÅ‡∏ö‡∏ö Dynamic
    collection_name = _get_collection_name(doc_type=STATEMENT_DOC_TYPE, enabler=enabler_abbr)
    
    try:
        # 2. ‡πÇ‡∏´‡∏•‡∏î Statements ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Assessor ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÇ‡∏´‡∏•‡∏î Vector Store ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (vectorstore_retriever=None)
        # Assessor ‡∏à‡∏∞‡πÇ‡∏´‡∏•‡∏î‡∏û‡∏≤‡∏ò‡πÑ‡∏ü‡∏•‡πå Statement JSON ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏≠‡∏á
        assessor = EnablerAssessment(enabler_abbr=enabler_abbr, vectorstore_retriever=None)
        
        # üìå ‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏ò‡∏≠‡∏î get_statements() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Statements ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        all_statements_data: List[Dict[str, Any]] = assessor.get_statements()
            
        # 2.1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î
        if not all_statements_data:
            logger.error(f"‚ùå Found 0 statements for Enabler {enabler_abbr}. Check your JSON data files.")
            return
            
        logger.info(f"‚úÖ Loaded {len(all_statements_data)} statements from {enabler_abbr} data.")

        # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Vector Store
        texts = []
        metadatas = []
        
        for statement in all_statements_data:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Statement_Text ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            statement_text = statement.get("Statement_Text", "").strip()
            if not statement_text:
                logger.warning(f"Skipping statement (ID: {statement.get('Statement_ID', 'N/A')}) because 'Statement_Text' is missing or empty.")
                continue

            texts.append(statement_text)
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Metadata ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
            metadata = {
                "Statement_ID": statement.get("Statement_ID"),
                "Sub_Criteria_ID": statement.get("Sub_Criteria_ID"),
                "Level": statement.get("Level"),
                "Enabler_Abbr": statement.get("Enabler_Abbr", enabler_abbr),
                "doc_type": STATEMENT_DOC_TYPE, # ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
                "enabler": enabler_abbr,        # ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏≠‡∏á Enabler
            }
            metadatas.append(metadata)

        # 4. Ingest Logic (‡πÉ‡∏ä‡πâ VectorStoreManager Public Methods)
        logger.info(f"Starting ingestion process into dynamic collection: {collection_name}...")
        
        if not texts:
            logger.warning("No valid texts provided for statement ingestion. Skipping.")
            return

        # 4.1. Initialize VSM and Delete the old collection
        try:
            logger.info("CHECKPOINT 1: Initializing VectorStoreManager and deleting old collection...") 
            vsm = VectorStoreManager()
            
            # üéØ ‡∏•‡∏ö Collection ‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Fresh Ingest
            if vsm.delete_collection(collection_name):
                 logger.info(f"üßπ Successfully deleted existing collection: {collection_name} for fresh ingest.")
            else:
                 logger.warning(f"Could not delete collection {collection_name} (likely did not exist). Proceeding.")

        except Exception as e:
            logger.error(f"‚ùå Could not initialize VSM or delete collection: {e}. Aborting ingestion.", exc_info=True) 
            return

        # 4.2. Get the LangChain Chroma instance 
        vectorstore = vsm.get_chroma_instance(collection_name) 
        
        if not vectorstore:
             logger.error(f"‚ùå Could not get/create Chroma instance for collection: {collection_name}. Aborting ingestion.")
             return

        # 4.3. Add new statements
        ids = [str(uuid.uuid4()) for _ in texts] # ‡∏™‡∏£‡πâ‡∏≤‡∏á ID ‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ Statement

        try:
            # üü¢ ‡πÉ‡∏ä‡πâ vectorstore.add_texts() ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Ingest ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Embeddings
            vectorstore.add_texts(texts=texts, metadatas=metadatas, ids=ids)
            
            end_time = time.perf_counter()
            runtime = round(end_time - start_time, 2)
            
            logger.info(f"‚úÖ Indexed {len(ids)} new statements into collection: {collection_name}. Persist finished.")
            logger.info(f"üéâ Statement Ingestion for {enabler_abbr} completed successfully in {runtime}s into {collection_name}!")
        except Exception as e:
            logger.error(f"‚ùå Error during Chroma indexing for {collection_name}: {e}", exc_info=True)
            return
        
    except Exception as e:
        logger.error(f"‚ùå FATAL Error during statement ingestion for {enabler_abbr}: {e}", exc_info=True)


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description="Ingest Statements into Vector Store for Mapping Suggestion Tool.")
    parser.add_argument('--enabler', 
                        type=str, 
                        required=True, 
                        choices=["CG", "L", "SP", "RM&IC", "SCM", "DT", "HCM", "KM", "IM", "IA"],
                        help="Enabler abbreviation (e.g., KM, LDR, SUC).")
    
    args = parser.parse_args()
    
    ingest_all_statements(args.enabler)