# tools/mapping_suggestor.py (à¸‰à¸šà¸±à¸šà¹à¸à¹‰à¹„à¸‚: à¹ƒà¸Šà¹‰ VSM à¹à¸¥à¸° Hard Filter Logic à¹ƒà¸«à¸¡à¹ˆ)

import os
import logging
from typing import List, Dict, Any, Optional, Tuple, Union

# Project imports
from config.global_vars import (
    DEFAULT_ENABLER,
    EVIDENCE_DOC_TYPES,
    INITIAL_TOP_K,
    FINAL_K_RERANKED,
    FINAL_K_NON_RERANKED,
    MAPPING_FILE_PATH,
)

# ðŸ’¡ NEW: à¸™à¸³à¹€à¸‚à¹‰à¸² Logic RAG à¸—à¸µà¹ˆà¹à¸à¹‰à¹„à¸‚à¹à¸¥à¹‰à¸§
from core.retrieval_utils import retrieve_context_with_filter 

# ðŸ’¡ NEW: à¸™à¸³à¹€à¸‚à¹‰à¸² VSM à¹à¸¥à¸° MultiDocRetriever (à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸£à¸“à¸µà¸à¸²à¸£à¸”à¸¶à¸‡à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸«à¸¥à¸²à¸¢à¹€à¸­à¸à¸ªà¸²à¸£)
from core.vectorstore import (
    VectorStoreManager,
    NamedRetriever,
    MultiDocRetriever,
    get_vectorstore_manager,
    load_vectorstore,
    get_global_reranker # à¹€à¸œà¸·à¹ˆà¸­à¹ƒà¸Šà¹‰ rerank à¹€à¸­à¸‡à¸™à¸­à¸ retrieval_utils
)

# ðŸ’¡ NEW: à¸™à¸³à¹€à¸‚à¹‰à¸² Helper à¹ƒà¸™à¸à¸²à¸£à¹‚à¸«à¸¥à¸” Mapping
from core.ingest import load_doc_id_mapping # à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸—à¸µà¹ˆà¸„à¸¸à¸“à¸¡à¸µà¹ƒà¸™ core/ingest.py

logger = logging.getLogger(__name__)

# ------------------------------------------------------------------
# RAG Context Generation (à¹ƒà¸Šà¹‰ Logic à¸—à¸µà¹ˆà¸–à¸¹à¸à¹à¸à¹‰à¹„à¸‚à¹à¸¥à¹‰à¸§)
# ------------------------------------------------------------------

def get_rag_context(
    query: str, 
    doc_type: str, 
    enabler: str, 
    stable_doc_ids: Optional[list] = None, # Hard Filter
    top_k: int = FINAL_K_RERANKED
) -> List[Dict[str, Any]]:
    """
    Wrapper function to get RAG context using the central retrieval logic.
    à¹ƒà¸Šà¹‰ retrieve_context_with_filter à¸ˆà¸²à¸ core/retrieval_utils.py 
    à¸‹à¸¶à¹ˆà¸‡à¸£à¸­à¸‡à¸£à¸±à¸š Hard Filter à¹à¸¥à¸° Custom Rerank Logic à¸‚à¸­à¸‡à¹€à¸£à¸²à¹à¸¥à¹‰à¸§
    """
    logger.info(f"ðŸ” Starting RAG retrieval for doc_type='{doc_type}', enabler='{enabler}', query='{query[:50]}...'")
    
    # ðŸŽ¯ à¹€à¸£à¸µà¸¢à¸à¹ƒà¸Šà¹‰à¸Ÿà¸±à¸‡à¸à¹Œà¸Šà¸±à¸™à¸—à¸µà¹ˆà¹€à¸£à¸²à¹à¸à¹‰à¹„à¸‚à¹à¸¥à¹‰à¸§
    result = retrieve_context_with_filter(
        query=query,
        doc_type=doc_type,
        enabler=enabler,
        stable_doc_ids=stable_doc_ids,
        top_k_reranked=top_k,
        disable_semantic_filter=False # à¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Rerank Logic à¸—à¸µà¹ˆà¹€à¸£à¸²à¸¢à¸·à¸™à¸¢à¸±à¸™à¹à¸¥à¹‰à¸§
    )
    
    return result.get("top_evidences", [])


# ------------------------------------------------------------------
# Assessment Core Logic (à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™)
# ------------------------------------------------------------------

def assess_statement_level(
    statement_id: str,
    target_level: int,
    rubric_text: str,
    evidence_query: str,
    stable_doc_ids: Optional[List[str]] = None,
    doc_type: str = EVIDENCE_DOC_TYPES,
    enabler: str = DEFAULT_ENABLER,
    is_multi_doc: bool = False,
    top_k: int = FINAL_K_RERANKED
) -> Dict[str, Any]:
    """
    Performs the core LLM assessment for a single statement/level.
    """
    logger.info(f"--- ASSESSING: {statement_id} (Level {target_level}) ---")
    
    # 1. Prepare RAG Context
    rag_context = get_rag_context(
        query=evidence_query,
        doc_type=doc_type,
        enabler=enabler,
        stable_doc_ids=stable_doc_ids, # à¸ªà¹ˆà¸‡ Hard Filter à¹€à¸‚à¹‰à¸²à¹„à¸›
        top_k=top_k
    )
    
    if not rag_context:
        logger.warning(f"âš ï¸ No RAG context found for {statement_id}. Skipping LLM call.")
        return {
            "statement_id": statement_id,
            "level": target_level,
            "assessment_result": "NO_EVIDENCE_FOUND",
            "context_docs": [],
            "error": "No relevant evidence documents were retrieved."
        }

    # 2. Format Context for LLM (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¸£à¸§à¸¡ context)
    formatted_context = "\n---\n".join([
        f"Document ID: {doc['metadata'].get('doc_id') or 'N/A'}\n"
        f"Source: {doc['metadata'].get('source') or 'Unknown'}\n"
        f"Content:\n{doc['content']}"
        for doc in rag_context
    ])
    
    # 3. LLM Call (Placeholder)
    # ðŸ’¡ à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡, Logic à¸•à¸£à¸‡à¸™à¸µà¹‰à¸ˆà¸°à¹€à¸£à¸µà¸¢à¸ LLM à¹€à¸žà¸·à¹ˆà¸­à¸—à¸³à¸à¸²à¸£à¸›à¸£à¸°à¹€à¸¡à¸´à¸™
    # à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡: llm_response = call_llm_for_assessment(rubric_text, evidence_query, formatted_context)
    
    llm_assessment_data = {
        "statement_id": statement_id,
        "level": target_level,
        "assessment_result": "PASSED" if rag_context else "FAILED", # à¸ªà¸¡à¸¡à¸•à¸´à¸à¸²à¸™
        "llm_reasoning": "Context was successfully retrieved and reranked via the new VSM logic.",
    }

    # 4. Final Output Formatting
    return {
        "statement_id": statement_id,
        "level": target_level,
        "assessment_result": llm_assessment_data["assessment_result"],
        "llm_reasoning": llm_assessment_data["llm_reasoning"],
        "context_docs": [
            {
                "doc_id": doc['metadata'].get('doc_id'),
                "source": doc['metadata'].get('source'),
                "chunk_uuid": doc['metadata'].get('chunk_uuid'),
            } for doc in rag_context
        ]
    }

# ------------------------------------------------------------------
# Multi-Document Assessment / Multi-Retriever (à¸–à¹‰à¸²à¹ƒà¸Šà¹‰)
# ------------------------------------------------------------------

def assess_multiple_statements(
    assessment_list: List[Dict[str, Any]],
    doc_mapping_db: Optional[Dict[str, Any]] = None # à¹ƒà¸Šà¹‰à¹€à¸žà¸·à¹ˆà¸­à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸š doc_ids
) -> List[Dict[str, Any]]:
    """
    Process a list of statements for assessment.
    """
    if doc_mapping_db is None:
        doc_mapping_db = load_doc_id_mapping(MAPPING_FILE_PATH)
        
    results = []

    for item in assessment_list:
        stable_doc_ids = item.get("stable_doc_ids")
        # ðŸ’¡ Verification: à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¸§à¹ˆà¸² Stable IDs à¸¡à¸µà¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ Mapping à¸«à¸£à¸·à¸­à¹„à¸¡à¹ˆ
        if stable_doc_ids:
            verified_ids = [
                doc_id for doc_id in stable_doc_ids 
                if doc_id in doc_mapping_db and doc_mapping_db[doc_id].get("chunk_uuids")
            ]
            if len(verified_ids) < len(stable_doc_ids):
                logger.warning(f"âš ï¸ Some Stable IDs not found/mapped for {item['statement_id']}. Using only {len(verified_ids)} IDs.")
            stable_doc_ids = verified_ids
            
        result = assess_statement_level(
            statement_id=item["statement_id"],
            target_level=item["target_level"],
            rubric_text=item["rubric_text"],
            evidence_query=item["evidence_query"],
            stable_doc_ids=stable_doc_ids, # à¸ªà¹ˆà¸‡ Hard Filter à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¸£à¸§à¸ˆà¸ªà¸­à¸šà¹à¸¥à¹‰à¸§
            doc_type=item.get("doc_type", EVIDENCE_DOC_TYPES),
            enabler=item.get("enabler", DEFAULT_ENABLER),
            top_k=FINAL_K_RERANKED
        )
        results.append(result)

    return results

# ------------------------------------------------------------------
# Main Execution (à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡)
# ------------------------------------------------------------------

def run_mapping_suggestor(assessment_list: List[Dict[str, Any]]):
    """
    Main function to run the assessment process.
    """
    if not assessment_list:
        logger.error("âŒ Assessment list is empty. Exiting.")
        return []

    # ðŸ’¡ Initialize VSM to ensure models/embeddings are loaded once
    try:
        get_vectorstore_manager()
        logger.info("âœ… VectorStoreManager initialized successfully.")
    except Exception as e:
        logger.critical(f"âŒ FATAL: VSM initialization failed: {e}")
        return []

    # Run the assessment
    assessment_results = assess_multiple_statements(assessment_list)
    
    logger.info(f"Completed assessment for {len(assessment_results)} statements.")
    return assessment_results

# Example usage (Optional, à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸—à¸”à¸ªà¸­à¸š):
if __name__ == '__main__':
    # ðŸ’¡ NOTE: à¹ƒà¸™à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¸ˆà¸£à¸´à¸‡ à¹‚à¸„à¹‰à¸”à¸™à¸µà¹‰à¸ˆà¸°à¸£à¸±à¸šà¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¸ˆà¸²à¸à¸ à¸²à¸¢à¸™à¸­à¸
    example_assessments = [
        {
            "statement_id": "S1.1",
            "target_level": 3,
            "rubric_text": "Criteria for S1.1 Level 3...",
            "evidence_query": "What are the procedures for risk assessment?",
            "stable_doc_ids": ["DOC-12345", "DOC-99999"], # à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡ Hard Filter
            "doc_type": "evidence",
            "enabler": "KM"
        },
        # ... (à¸£à¸²à¸¢à¸à¸²à¸£à¸­à¸·à¹ˆà¸™à¹†)
    ]
    
    # final_results = run_mapping_suggestor(example_assessments)
    # print(json.dumps(final_results, indent=2, ensure_ascii=False))