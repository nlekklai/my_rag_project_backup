# gen_seam_report.py (‡πÇ‡∏Ñ‡πâ‡∏î‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 4: ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠ Source ‡∏à‡∏≤‡∏Å Snippet ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÉ‡∏ô Metadata)

import json
import os
import argparse
from typing import Dict, Any, Optional, List
from datetime import datetime
import re 

# Import libraries for DOCX generation
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.enum.table import WD_ALIGN_VERTICAL

# ==========================
# 1. CONFIGURATION & GLOBAL VARS
# ==========================
EXPORT_DIR = "reports"
REPORT_DATE = datetime.now().strftime("%Y-%m-%d")
THAI_FONT_NAME = "Angsana New" 

# ‡∏û‡∏à‡∏ô‡∏≤‡∏ô‡∏∏‡∏Å‡∏£‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠ Enabler ‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°
SEAM_ENABLER_MAP = {
    "KM": "7.1 ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ (Knowledge Management)",
    "IT": "7.2 ‡πÄ‡∏ó‡∏Ñ‡πÇ‡∏ô‡πÇ‡∏•‡∏¢‡∏µ‡∏î‡∏¥‡∏à‡∏¥‡∏ó‡∏±‡∏•",
    "HR": "6.1 ‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏∏‡∏ô‡∏°‡∏ô‡∏∏‡∏©‡∏¢‡πå (Human Capital Management)",
    "CG": "1.1 ‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏Å‡∏±‡∏ö‡∏î‡∏π‡πÅ‡∏•‡∏ó‡∏µ‡πà‡∏î‡∏µ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£",
    "SP": "2.1 ‡∏Å‡∏≤‡∏£‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå",
    "RM": "3.1 ‡∏Å‡∏≤‡∏£‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏†‡∏≤‡∏¢‡πÉ‡∏ô",
    "SCM": "4.1 ‡∏Å‡∏≤‡∏£‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏ú‡∏π‡πâ‡∏°‡∏µ‡∏™‡πà‡∏ß‡∏ô‡πÑ‡∏î‡πâ‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡πÅ‡∏•‡∏∞‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤",
    "IM": "7.2 ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°",
    "IA": "8.1 ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏†‡∏≤‡∏¢‡πÉ‡∏ô"
}

# ==========================
# 2. DATA LOADING & UTILITY
# ==========================

def load_data(file_path: str, file_type: str) -> Optional[Dict[str, Any]]:
    """‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå JSON ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data
    except FileNotFoundError:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {file_type}: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå '{file_path}'") 
        return None
    except Exception as e:
        print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå {file_type} '{file_path}': {e}") 
        return None

def setup_output_folder(file_path):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á folder output"""
    output_dir = os.path.dirname(file_path)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir)

def setup_document(doc):
    """Sets up document-wide formatting like margins and default font."""
    section = doc.sections[0]
    section.top_margin = Inches(1.0)
    section.bottom_margin = Inches(1.0)
    section.left_margin = Inches(0.75) 
    section.right_margin = Inches(0.75)

    doc.styles['Normal'].font.name = THAI_FONT_NAME
    
def add_paragraph(doc, text, bold=False, italic=False, color=None, style=None):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Utility ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Paragraph ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏á‡πà‡∏≤‡∏¢ (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≥‡∏´‡∏ô‡∏î Angsana New)"""
    p = doc.add_paragraph(style=style) if style else doc.add_paragraph()
    run = p.add_run(text)
    
    run.font.name = THAI_FONT_NAME 
    
    run.bold = bold
    run.italic = italic
    if color:
        run.font.color.rgb = RGBColor(*color)
    run.font.size = Pt(11)
    return p

def set_heading(doc, text, level=1):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Utility ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏° Heading (‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≥‡∏´‡∏ô‡∏î Angsana New)"""
    p = doc.add_heading(text, level=level)
    p.alignment = WD_ALIGN_PARAGRAPH.CENTER if level == 1 else WD_ALIGN_PARAGRAPH.LEFT
    
    for run in p.runs:
        run.font.name = THAI_FONT_NAME 

def flatten_raw_data(raw_data_dict: Dict[str, Any]) -> List[Dict[str, Any]]:
    """
    ‡∏î‡∏∂‡∏á Statement ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å Raw Data Dictionary 
    (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á List ‡∏Ç‡∏≠‡∏á Statements ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)
    """
    statements = []
    
    # 1. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á List ‡∏Ç‡∏≠‡∏á Statements ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö New Single-File Export)
    if isinstance(raw_data_dict, list):
        statements = [s for s in raw_data_dict if isinstance(s, dict)]
        if statements:
            return statements
            
    # 2. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Raw Details ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏õ‡πá‡∏ô Dictionary)
    if isinstance(raw_data_dict, dict) and 'sub_criteria_results' in raw_data_dict:
        sub_results = raw_data_dict.get('sub_criteria_results', [])
        for sub_item in sub_results:
            if isinstance(sub_item, dict) and 'raw_results_ref' in sub_item:
                raw_statements = sub_item['raw_results_ref']
                if isinstance(raw_statements, list):
                    statements.extend([s for s in raw_statements if isinstance(s, dict)])
        if statements:
            return statements
            
    # 3. ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏Å‡πà‡∏≤‡∏°‡∏≤‡∏Å (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏ß‡πâ)
    details = raw_data_dict.get("Assessment_Details") if isinstance(raw_data_dict, dict) else None
    if isinstance(details, dict):
        for sub_id_statements in details.values():
            if isinstance(sub_id_statements, list):
                statements.extend([s for s in sub_id_statements if isinstance(s, dict)])
                
    return statements

# ==========================
# 3. REPORT GENERATION FUNCTIONS (DOCX)
# ==========================

def generate_overall_summary_docx(document: Document, summary_data: Dict[str, Any], enabler_name_full: str): 
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° (Overall) [SECTION 1] ‡πÉ‡∏ô DOCX"""
    
    set_heading(document, f'[SECTION 1] ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô {enabler_name_full} ‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°', level=1)
    
    # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏à‡∏≤‡∏Å New Single-File structure (‡∏ã‡∏∂‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å 'summary')
    achieved_score = summary_data.get('Total Weighted Score Achieved', 0.0)
    overall_max_score = summary_data.get('Total Possible Weight', 0.0)

    # Percentage calculation
    overall_percent = summary_data.get('Overall Progress Percentage (0.0 - 1.0)', 0.0) * 100

    # Maturity Score & Level: 
    maturity_score = summary_data.get('Overall Maturity Score (Avg.)', 0.0) 
    maturity_level = summary_data.get('Overall Maturity Level (Weighted)', 'N/A')
    
    table = document.add_table(rows=5, cols=2) 
    table.style = 'Table Grid'
    
    def add_summary_row(row_index, label, value):
        table.cell(row_index, 0).text = label
        table.cell(row_index, 1).text = value
        table.cell(row_index, 0).paragraphs[0].runs[0].font.bold = True
        table.cell(row_index, 1).paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.RIGHT
        
    enabler_id = summary_data.get("enabler", summary_data.get("enabler_id", "N/A")).upper()
    add_summary_row(0, "‡∏ï‡∏±‡∏ß‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô (Enabler):", f"{enabler_id}\n({enabler_name_full})") 
    add_summary_row(1, "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ:", f"{achieved_score:.2f} / {overall_max_score:.2f}")
    add_summary_row(2, "‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏°:", f"{overall_percent:.2f}%")
    add_summary_row(3, "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ß‡∏∏‡∏í‡∏¥‡∏†‡∏≤‡∏ß‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° (Maturity Score):", f"{maturity_score:.2f}")
    add_summary_row(4, "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ß‡∏∏‡∏í‡∏¥‡∏†‡∏≤‡∏ß‡∏∞‡πÇ‡∏î‡∏¢‡∏£‡∏ß‡∏° (Maturity Level):", maturity_level)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡πÉ‡∏´‡πâ Table Headers ‡πÅ‡∏•‡∏∞ Content
    for row in table.rows:
        for cell in row.cells:
            for p in cell.paragraphs:
                for run in p.runs:
                    run.font.name = THAI_FONT_NAME
    
    document.add_paragraph() 

def generate_executive_summary_docx(document: Document, summary_data: Dict[str, Any], sub_results: List[Dict[str, Any]]):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£ (Executive Summary) [SECTION 2] ‡πÉ‡∏ô DOCX"""
    if not summary_data: return
    set_heading(document, "[SECTION 2] ‡∏™‡∏£‡∏∏‡∏õ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£ (Executive Summary)", level=1)

    # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å Summary Section 
    achieved_score = summary_data.get('Total Weighted Score Achieved', 0.0)
    overall_max_score = summary_data.get('Total Possible Weight', 0.0)
    
    overall_percent = summary_data.get('Overall Progress Percentage (0.0 - 1.0)', 0.0) * 100
    maturity_score = summary_data.get('Overall Maturity Score (Avg.)', 0.0)
    maturity_level = summary_data.get('Overall Maturity Level (Weighted)', 'N/A')

    add_paragraph(document, f"‚úÖ ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°: {achieved_score:.2f} / {overall_max_score:.2f}")
    add_paragraph(document, f"‚úÖ ‡∏£‡πâ‡∏≠‡∏¢‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {overall_percent:.2f}%")
    add_paragraph(document, f"‚úÖ ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡πÉ‡∏´‡∏ç‡πà: {maturity_score:.2f} ({maturity_level})")
    document.add_paragraph()

    if sub_results:
        # Strength: Top 3 highest scoring
        add_paragraph(document, "üìà ‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡∏ó‡∏µ‡πà‡πÇ‡∏î‡∏î‡πÄ‡∏î‡πà‡∏ô (Top Strengths):", bold=True, color=(0x00, 0x70, 0xC0))
        top_strengths = sorted(sub_results, key=lambda x: (x.get("weighted_score", 0) / x.get("weight", 1)) if x.get("weight", 1) > 0 else 0, reverse=True)[:3]
        for s in top_strengths:
            sub_id = s.get('sub_criteria_id', 'N/A')
            sub_name = s.get('sub_criteria_name', 'N/A')
            add_paragraph(document, f"‚Ä¢ {sub_id} - {sub_name} (L{s.get('highest_full_level', 0)} ‡πÑ‡∏î‡πâ {s.get('weighted_score', 0):.2f}/{s.get('weight', 0):.2f})", style="List Bullet")

        document.add_paragraph()
        
        # Weakness: Top 3 with Gap (or lowest scoring with Gap)
        add_paragraph(document, "üö® ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏û‡∏±‡∏í‡∏ô‡∏≤ (Development Areas):", bold=True, color=(0xFF, 0x00, 0x00))
        gaps = [s for s in sub_results if not s.get("target_level_achieved", True)]
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (Highest Full Level) ‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
        top_weaknesses = sorted(gaps, key=lambda x: x.get("highest_full_level", 0))[:3] 
        for s in top_weaknesses:
            sub_id = s.get('sub_criteria_id', 'N/A')
            sub_name = s.get('sub_criteria_name', 'N/A')
            add_paragraph(document, f"‚Ä¢ {sub_id} - {sub_name} (‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ú‡πà‡∏≤‡∏ô: L{s.get('highest_full_level', 0)})", style="List Bullet")
    
    document.add_paragraph()

def generate_sub_criteria_status_docx(document: Document, sub_results: List[Dict[str, Any]]) -> Dict[str, Any]:
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ [SECTION 3] ‡πÉ‡∏ô DOCX ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ Gap"""
    
    document.add_heading('[SECTION 3] ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢‡πÅ‡∏•‡∏∞ Gap', level=1)
    
    table = document.add_table(rows=1, cols=5)
    table.style = 'Table Grid'
    
    # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
    table.columns[0].width = Inches(0.5) 
    table.columns[1].width = Inches(4.5) 
    table.columns[2].width = Inches(0.8) # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô/‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
    table.columns[3].width = Inches(0.7) 
    table.columns[4].width = Inches(0.8) # Gap
    
    header_cells = table.rows[0].cells
    headers = ["ID", "‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô/‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å", "Level", "Gap"] 
    for i, h in enumerate(headers):
        header_cells[i].text = h
        header_cells[i].paragraphs[0].runs[0].font.bold = True
        header_cells[i].paragraphs[0].runs[0].font.name = THAI_FONT_NAME 
        header_cells[i].vertical_alignment = WD_ALIGN_VERTICAL.CENTER

    gap_criteria = {}
    
    for info in sub_results:
        sub_id = info.get('sub_criteria_id')
        if not sub_id: continue

        row_cells = table.add_row().cells
        
        name = info.get('sub_criteria_name', 'N/A') 
        score = info.get('weighted_score', 0.0) 
        weight = info.get('weight', 0.0) 
        level = info.get('highest_full_level', 0)
        has_gap = "‚ùå YES" if not info.get('target_level_achieved', True) else "‚úÖ NO"
        
        if not info.get('target_level_achieved', True):
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sub-criteria ‡∏ó‡∏µ‡πà‡∏°‡∏µ Gap
            gap_criteria[sub_id] = info 
            
        row_cells[0].text = sub_id
        row_cells[1].text = name
        row_cells[2].text = f"{score:.2f} / {weight:.2f}" 
        row_cells[3].text = f"L{level}"
        row_cells[4].text = has_gap
        
        # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        for row in table.rows: # Re-apply font to all rows/cells for consistency
            for cell in row.cells:
                for p in cell.paragraphs:
                    for run in p.runs:
                        run.font.name = THAI_FONT_NAME

        row_cells[0].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        row_cells[2].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        row_cells[3].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
        row_cells[4].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER

    document.add_paragraph() 
    return gap_criteria

def generate_action_plan_report_docx(document: Document, gap_criteria: Dict[str, Any]):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ (Action Plan) [SECTION 4] ‡πÉ‡∏ô DOCX"""
    
    document.add_heading('[SECTION 4] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (Action Plan)', level=1)
    
    if not gap_criteria:
        add_paragraph(document, "‚úÖ ‡∏ó‡∏∏‡∏Å‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡πÅ‡∏•‡πâ‡∏ß ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ Action Plan ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°")
        return

    add_paragraph(document, 
        "‚ÑπÔ∏è ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏ '‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∞‡∏ö‡∏ö' (Systemic Gap) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏ö‡∏£‡∏£‡∏•‡∏∏‡∏ß‡∏∏‡∏í‡∏¥‡∏†‡∏≤‡∏ß‡∏∞ Level ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ ‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£‡∏Ñ‡∏ß‡∏£‡∏ô‡∏≥‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡πÅ‡∏ï‡∏Å‡πÄ‡∏õ‡πá‡∏ô '‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏¢‡πà‡∏≠‡∏¢ (Detailed Work Plan)' ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°, ‡∏ú‡∏π‡πâ‡∏£‡∏±‡∏ö‡∏ú‡∏¥‡∏î‡∏ä‡∏≠‡∏ö, ‡πÅ‡∏•‡∏∞‡πÑ‡∏ó‡∏°‡πå‡πÑ‡∏•‡∏ô‡πå ‡∏†‡∏≤‡∏¢‡πÉ‡∏ï‡πâ‡∏Å‡∏£‡∏≠‡∏ö PDCA ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ",
        italic=True,
        color=(0x80, 0x80, 0x80)
    )
    document.add_paragraph()

    for sub_id, sub_info in gap_criteria.items():
        sub_name = sub_info.get('sub_criteria_name', 'N/A')
        
        document.add_heading(f"‚Ä¢ ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ {sub_id}: {sub_name} (Highest Full Level: L{sub_info.get('highest_full_level', 0)})", level=2)
        
        # ‡∏î‡∏∂‡∏á Summary Evidence ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        evidence_summary_L5 = sub_info.get("evidence_summary_L5", {})
        evidence_summary_L4 = sub_info.get("evidence_summary_L4", {})
        
        if evidence_summary_L5.get('summary'):
            add_paragraph(document, "üí° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö L5 (‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î):", bold=True, color=(0x00, 0x70, 0xC0))
            add_paragraph(document, f"   - ‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô: {evidence_summary_L5.get('summary', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏£‡∏∏‡∏õ L5')}", italic=True)
            p_sugg = add_paragraph(document, f"   - ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞: ", italic=True)
            run_sugg = p_sugg.add_run(evidence_summary_L5.get('suggestion_for_next_level', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏ô‡∏≠‡πÅ‡∏ô‡∏∞'))
            run_sugg.font.bold = True
            run_sugg.font.name = THAI_FONT_NAME
            document.add_paragraph()
        
        if evidence_summary_L4.get('summary'):
            add_paragraph(document, "üí° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö L4:", bold=True, color=(0x00, 0x70, 0xC0))
            add_paragraph(document, f"   - ‡∏™‡∏£‡∏∏‡∏õ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô: {evidence_summary_L4.get('summary', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏£‡∏∏‡∏õ L4')}", italic=True)
            document.add_paragraph()
        
        action_plans = sub_info.get('action_plan', [])
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° Action Plan ‡∏ï‡∏≤‡∏° PDCA (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏Å‡∏£‡∏ì‡∏µ LLM ‡∏™‡∏£‡πâ‡∏≤‡∏á Action Plan ‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ Phase/Goal)
        pdca_actions = {
            'P (Plan / ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô)': [],
            'D (Do / ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)': [],
            'C (Check / ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö)': [],
            'A (Act / ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)': []
        }

        # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô (Phase/Goal/Actions)
        is_complex_structure = (
             isinstance(action_plans, list) and 
             action_plans and 
             isinstance(action_plans[0], dict) and 
             'Phase' in action_plans[0]
        )

        if is_complex_structure:
            # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÅ‡∏•‡∏∞‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Phase/Goal/Actions
            for plan in action_plans:
                # Basic mapping based on name prefix
                phase = plan.get('Phase', 'D (Do / ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)')
                if 'P (' in phase: pdca_key = 'P (Plan / ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô)'
                elif 'D (' in phase: pdca_key = 'D (Do / ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)'
                elif 'C (' in phase: pdca_key = 'C (Check / ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö)'
                elif 'A (' in phase: pdca_key = 'A (Act / ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)'
                else: pdca_key = 'D (Do / ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)' 
                    
                for action in plan.get('Actions', []):
                    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ Action Plan ‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏°‡∏µ‡πÅ‡∏Ñ‡πà Recommendation
                    pdca_actions[pdca_key].append({
                        'rec': action.get('Recommendation', ''), 
                        'target_evidence': '-', # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ô‡∏µ‡πâ
                        'key_metric': '-' # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ô‡∏µ‡πâ
                    })
        
        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢ (List of Recommendations ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå Target_Evidence_Type, Key_Metric)
        elif isinstance(action_plans, list) and all(isinstance(a, dict) and 'Recommendation' in a for a in action_plans):
            for action in action_plans:
                rec = action.get('Recommendation', '')
                failed_level = action.get('Failed_Level', 5)
                target_evidence = action.get('Target_Evidence_Type', '-')
                key_metric = action.get('Key_Metric', '-')
                
                # Logic ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° PDCA (‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Action Plan)
                if '‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á' in rec or '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö' in rec or failed_level == 5:
                    pdca_key = 'A (Act / ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)'
                elif '‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°' in rec or '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•' in rec or '‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô' in rec:
                    pdca_key = 'C (Check / ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö)'
                elif failed_level in [1, 2] or '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÅ‡∏ú‡∏ô' in rec or '‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå' in rec:
                    pdca_key = 'P (Plan / ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô)' 
                else:
                    pdca_key = 'D (Do / ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥)'

                pdca_actions[pdca_key].append({
                    'rec': rec, 
                    'target_evidence': target_evidence,
                    'key_metric': key_metric
                })
                
        # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô PDCA ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÅ‡∏•‡πâ‡∏ß
        if any(actions for actions in pdca_actions.values()):
            document.add_paragraph()
            add_paragraph(document, "üìã ‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏¥‡∏î‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ï‡∏≤‡∏°‡∏ß‡∏á‡∏à‡∏£ PDCA (User Guideline)", bold=True, color=(0x00, 0x00, 0x00))

            for phase, actions in pdca_actions.items():
                if actions:
                    document.add_heading(f"--- {phase} ---", level=4)
                    
                    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏á‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏°‡∏µ Target/Metric)
                    if not is_complex_structure and all(a.get('target_evidence') != '-' for a in actions):
                        action_table = document.add_table(rows=1, cols=3, style='Table Grid')
                        
                        header_cells = action_table.rows[0].cells
                        header_cells[0].text = "‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ (Recommendation)"
                        header_cells[1].text = "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ (Evidence Type)"
                        header_cells[2].text = "‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Key Metric)"
                        
                        for cell in action_table.rows[0].cells:
                             cell.paragraphs[0].runs[0].font.bold = True
                             cell.paragraphs[0].runs[0].font.name = THAI_FONT_NAME 
                        
                        for action in actions:
                            row_cells = action_table.add_row().cells
                            
                            row_cells[0].text = action['rec']
                            
                            p_evidence = row_cells[1].paragraphs[0]
                            run_evidence = p_evidence.add_run(action['target_evidence'])
                            run_evidence.font.bold = True
                            run_evidence.font.color.rgb = RGBColor(0x00, 0x70, 0xC0) 
                            
                            p_metric = row_cells[2].paragraphs[0]
                            run_metric = p_metric.add_run(action['key_metric'])
                            run_metric.font.bold = True
                            run_metric.font.color.rgb = RGBColor(0xFF, 0x00, 0x00)
                            
                            for cell in row_cells:
                                cell.vertical_alignment = WD_ALIGN_VERTICAL.TOP
                                for p_cell in cell.paragraphs:
                                    for run in p_cell.runs:
                                        run.font.name = THAI_FONT_NAME
                                        run.font.size = Pt(11) 
                    
                    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≤‡∏î Target/Metric ‡πÉ‡∏´‡πâ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏õ‡πá‡∏ô List Bullet ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤
                    else:
                        for action in actions:
                            add_paragraph(document, f"‚Ä¢ {action['rec']}", style="List Bullet")
                    
                    document.add_paragraph() 
        else:
            add_paragraph(document, f">>> [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•]: ‡πÑ‡∏°‡πà‡∏°‡∏µ Action Plan ‡∏ñ‡∏π‡∏Å‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÑ‡∏ß‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ {sub_id}", style='List Bullet')
        document.add_paragraph()

def generate_raw_details_report_docx(document: Document, raw_data_list: List[Dict[str, Any]]): 
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (Raw Details) [SECTION 5] ‡πÉ‡∏ô DOCX
    ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: raw_data_list ‡∏Ñ‡∏∑‡∏≠ List ‡∏Ç‡∏≠‡∏á Statements ‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏à‡∏≤‡∏Å 'raw_llm_results'
    """
    
    document.add_heading('[SECTION 5] ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏•‡∏∂‡∏Å (Raw Details)', level=1)
    
    if not raw_data_list or not isinstance(raw_data_list, list):
        add_paragraph(document, f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Raw Statements ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Input (‡∏Ñ‡∏µ‡∏¢‡πå 'raw_llm_results' ‡∏≠‡∏≤‡∏à‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤)", bold=True, color=(0xFF, 0x80, 0x00)) 
        return
        
    assessment_details = {}
    for statement in raw_data_list:
        sub_id = statement.get('sub_criteria_id', 'N/A')
        if sub_id != 'N/A' and isinstance(statement, dict):
            if sub_id not in assessment_details:
                assessment_details[sub_id] = []
            assessment_details[sub_id].append(statement)
    
    sorted_assessment_details = dict(sorted(assessment_details.items()))
    
    if not sorted_assessment_details:
        add_paragraph(document, "üö® **‡πÑ‡∏°‡πà‡∏û‡∏ö Raw Statements ‡πÉ‡∏î‡πÜ** (‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå Input JSON ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á)", bold=True, color=(0xFF, 0x00, 0x00))
        return 

    for sub_id, statements in sorted_assessment_details.items():
        document.add_heading(f"‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢: {sub_id}", level=2)
        
        table = document.add_table(rows=1, cols=5, style='Table Grid')

        table.columns[0].width = Inches(1.0)  
        table.columns[1].width = Inches(1.0)  
        table.columns[2].width = Inches(2.5)  
        table.columns[3].width = Inches(2.0)  
        table.columns[4].width = Inches(3.0)  
        
        header_cells = table.rows[0].cells
        
        headers = ["Statement ID (Level)", "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•/‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", "‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤", "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô/‡∏ö‡∏£‡∏¥‡∏ö‡∏ó (Snippet)"] 
        for i, h in enumerate(headers):
            header_cells[i].text = h
            header_cells[i].paragraphs[0].runs[0].font.bold = True
            header_cells[i].paragraphs[0].runs[0].font.name = THAI_FONT_NAME 

        if not statements or not all(isinstance(s, dict) for s in statements):
            row_cells = table.add_row().cells
            row_cells[0].merge(row_cells[4]) 
            merged_cell = row_cells[0]
            merged_cell.text = "‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Raw Statements ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏ô‡∏µ‡πâ"
            
            for p_cell in merged_cell.paragraphs:
                run = p_cell.runs[0]
                run.font.name = THAI_FONT_NAME
                run.font.size = Pt(11)
                run.font.color.rgb = RGBColor(0xFF, 0x80, 0x00) 
            
            document.add_paragraph()
            continue 
            
        # Regex pattern to find source entries in the raw context snippet
        # [SOURCE: filename.ext (ID:hash)]
        SOURCE_PATTERN = re.compile(r'\[SOURCE:\s*(.*?)\s*\(ID:([0-9a-f]+)...?\)\s*\]', re.DOTALL)


        for statement in statements:
            is_passed = statement.get('is_passed', statement.get('is_pass', False)) 
            status = "‚úÖ PASS" if is_passed else "‚ùå FAIL"
            level = statement.get('level', '-')
            reason_text = statement.get('reason', 'N/A')

            # --- START: ‡∏î‡∏∂‡∏á Source/Snippet ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå Custom ---
            sources_list_raw = statement.get('retrieved_full_source_info', []) 
            
            # 1. ‡∏î‡∏∂‡∏á Snippet ‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ã‡πà‡∏≠‡∏ô‡πÑ‡∏ß‡πâ
            context_snippet_raw = statement.get('aggregated_context_used', '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô') 
            extracted_names_from_snippet = {} # {doc_id_prefix: file_name}
            
            for match in SOURCE_PATTERN.finditer(context_snippet_raw):
                file_name = match.group(1).strip()
                doc_id_prefix = match.group(2).strip() # Hash ID Prefix
                # ‡πÉ‡∏ä‡πâ Prefix 8 ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
                extracted_names_from_snippet[doc_id_prefix] = file_name 
            
            
            valid_sources = []
            if isinstance(sources_list_raw, list): 
                for src in sources_list_raw:
                    # 2.1 ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏Ñ‡∏µ‡∏¢‡πå‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Å‡πà‡∏≠‡∏ô
                    name = (
                        src.get('file_name') or 
                        src.get('source_name') or 
                        src.get('title') # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ 'title'
                    )
                    
                    # 2.2 ‡∏î‡∏∂‡∏á doc_id ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà
                    doc_id = str(src.get('doc_id') or src.get('document_id', '')).strip()
                    doc_id_prefix = doc_id[:8]

                    # 2.3 ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å Snippet ‡πÅ‡∏ó‡∏ô (‡∏ñ‡πâ‡∏≤‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà Hash Prefix)
                    if not name and doc_id_prefix and doc_id_prefix in extracted_names_from_snippet:
                         name = extracted_names_from_snippet[doc_id_prefix] # ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤
                    
                    
                    location = src.get('page')
                    rank = src.get('retrieved_rank')
                    
                    if name: # ‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏î‡πâ (‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏ï‡∏£‡∏á‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å snippet)
                        location_display = f" (p.{location})" if location and str(location).strip() != "" else ''
                        rank_display = f" (Rank {rank})" if rank is not None else ""
                        
                        valid_sources.append(f"{name}{location_display}{rank_display}")
                    else:
                        # Fallback message (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠)
                        if doc_id:
                            # Check if it's the long hash the user complained about
                            if len(doc_id) > 20:
                                 valid_sources.append(f"[ERROR: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (Hash: {doc_id_prefix}...)]")
                            else:
                                 valid_sources.append(f"[ERROR: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (ID: {doc_id})]")
                        else:
                            valid_sources.append("[ERROR: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤]")

            sources_text = "\n".join(valid_sources) if valid_sources else '‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤'
            
            # --- END: ‡∏î‡∏∂‡∏á Source/Snippet ---

            row_cells = table.add_row().cells
            
            # Column 1
            row_cells[0].text = f"{statement.get('sub_criteria_id', '-')}\n(L{level})"
            
            # Column 2
            llm_score = statement.get('llm_score', '-')
            if llm_score != '-':
                row_cells[1].text = f"{status}\n({llm_score}/1)" 
            else:
                 row_cells[1].text = status
            
            # Column 3
            row_cells[2].text = reason_text 
            
            # Column 4 (Source)
            row_cells[3].text = sources_text 
            
            # Column 5 (Snippet) - ‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Source Prefix ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å Snippet
            context_snippet_cleaned = context_snippet_raw
            
            # FIX 2: Clean the Snippet by removing the [SOURCE: ...] prefix if present 
            # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ Regex ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î
            # ‡πÄ‡∏£‡∏≤‡πÉ‡∏ä‡πâ sub() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏û‡∏ö pattern ‡∏î‡πâ‡∏ß‡∏¢‡∏™‡∏ï‡∏£‡∏¥‡∏á‡∏ß‡πà‡∏≤‡∏á
            context_snippet_cleaned = SOURCE_PATTERN.sub('', context_snippet_raw).strip() 

            if not context_snippet_cleaned:
                context_snippet_cleaned = '‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡∏ñ‡∏π‡∏Å‡∏•‡∏ö Source Prefix ‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ)'
            
            # Take only the first 300 characters for a snippet if full context is too long
            if len(context_snippet_cleaned) > 300:
                row_cells[4].text = context_snippet_cleaned[:300] + "..."
            else:
                row_cells[4].text = context_snippet_cleaned
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ü‡∏≠‡∏ô‡∏ï‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ñ‡∏ß‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            for cell in row_cells:
                cell.vertical_alignment = WD_ALIGN_VERTICAL.TOP
                for p_cell in cell.paragraphs:
                    for run in p_cell.runs:
                        run.font.name = THAI_FONT_NAME
                        run.font.size = Pt(11)

            row_cells[1].paragraphs[0].alignment = WD_ALIGN_PARAGRAPH.CENTER
            if not is_passed:
                row_cells[1].paragraphs[0].runs[0].font.bold = True 

        document.add_paragraph()

# ==========================
# 4. MAIN EXECUTION (Updated for Single-File Input)
# ==========================
def main():
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Input 1 ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà)"""
    
    parser = argparse.ArgumentParser(description="Generate Comprehensive SEAM Assessment Reports (Using the new Single-File Export).")
    parser.add_argument("--mode", choices=["all", "sub"], default="all", help="all: Generate full report. sub: Generate report for a specific sub-criteria.")
    parser.add_argument("--sub", type=str, help="SubCriteria ID (e.g., 2.2) if mode=sub.")
    
    # *** üü¢ ‡∏£‡∏±‡∏ö 1 ‡πÑ‡∏ü‡∏•‡πå Input ***
    parser.add_argument("--results_file", type=str, required=True, help="Path to the unified JSON results file (e.g., seam_assessment_results_km_L5_...json).") 
    
    parser.add_argument("--output_path", type=str, default="reports/SEAM_Comprehensive_Report", help="Output directory and base filename prefix (e.g., reports/SEAM_Comprehensive_Report).")
    
    args = parser.parse_args()
    
    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Folder Output ‡πÅ‡∏•‡∏∞‡πÅ‡∏¢‡∏Å Directory
    output_dir = os.path.dirname(args.output_path)
    if not output_dir:
         output_dir = EXPORT_DIR 
    setup_output_folder(output_dir)
    
    # 2. ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Single Results File
    results_data_loaded = load_data(args.results_file, "Unified Results File")
    
    if not results_data_loaded:
        print("üö® ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå Results Data ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ")
        return
        
    # --- 3. ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Single-File Export ---
    
    # 3.1 GOAL 1: Get Summary Section (for Sections 1 & 2)
    summary_section = results_data_loaded.get("summary", {})
    if not summary_section:
        print("üö® ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏µ‡∏¢‡πå 'summary' ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå Results Data (‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå)")
        return
    
    # 3.2 GOAL 2: Synthesize Sub Results Full (for Sections 2, 3, 4)
    # FIX: Access 'sub_criteria_results' as a LIST
    sub_results_list = results_data_loaded.get("sub_criteria_results")
    sub_results_full = []
    
    if sub_results_list and isinstance(sub_results_list, list):
        print("‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Results File (summary/sub_criteria_results ‡πÄ‡∏õ‡πá‡∏ô List) ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        
        for item in sub_results_list:
            if isinstance(item, dict):
                sub_results_full.append({
                    "sub_criteria_id": item.get('sub_criteria_id', 'N/A'),
                    "sub_criteria_name": item.get('sub_criteria_name', 'N/A'),
                    "weighted_score": item.get('weighted_score', 0.0), 
                    "weight": item.get('weight', 0.0),      
                    "highest_full_level": item.get('highest_full_level', 0),
                    "target_level_achieved": item.get('target_level_achieved', False), 
                    "action_plan": item.get('action_plan', []),
                    "evidence_summary_L5": item.get('evidence_summary_L5', {}),
                    "evidence_summary_L4": item.get('evidence_summary_L4', {}),
                })
    else:
         print("üö® ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á 'sub_criteria_results' ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")
         return
         
    # 3.3 GOAL 3: Raw Data (for Section 5)
    # FIX: Correct key name to 'raw_llm_results'
    raw_data_for_section5 = results_data_loaded.get("raw_llm_results") 
    
    if not raw_data_for_section5:
         print("üö® ‡πÑ‡∏°‡πà‡∏û‡∏ö Raw Data ‡πÉ‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå 'raw_llm_results' (Section 5 ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏Ç‡πâ‡∏≤‡∏°)")
         raw_data_for_section5 = [] 
         
    # ‡∏î‡∏∂‡∏á ENABLER ‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
    enabler_id = summary_section.get("enabler", summary_section.get("enabler_id", "KM")).upper()
    enabler_name_full = SEAM_ENABLER_MAP.get(enabler_id, f"Unknown Enabler ({enabler_id})")
    
    final_sub_results = sub_results_full
    
    # --- 4. ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏°‡∏î 'sub' ---
    
    base_prefix = os.path.basename(args.output_path)
    if not base_prefix or base_prefix == "SEAM_Comprehensive_Report":
        base_prefix = f"{enabler_id}_Comprehensive_Report"
        
    if args.mode == "sub" and args.sub:
        sub_id_filter = args.sub.upper()
        print(f"üîπ ‡πÇ‡∏´‡∏°‡∏î: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ {sub_id_filter} ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {enabler_name_full}")
        
        # ‡∏Å‡∏£‡∏≠‡∏á Sub Results
        final_sub_results = [
            res for res in sub_results_full 
            if res.get("sub_criteria_id", "").upper() == sub_id_filter
        ]
        
        # ‡∏Å‡∏£‡∏≠‡∏á Raw Data 
        if raw_data_for_section5:
            raw_data_for_section5 = [
                stmt for stmt in raw_data_for_section5 
                if stmt.get("sub_criteria_id", "").upper() == sub_id_filter
            ]
            
        base_prefix = f"{enabler_id}_Report_{sub_id_filter}"
    
    else:
        print(f"üîπ ‡πÇ‡∏´‡∏°‡∏î: ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {enabler_name_full}")
        
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏∑‡πà‡∏≠ Output ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ (‡∏£‡∏ß‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà)
    final_base_name = f"{base_prefix}_{REPORT_DATE}"
    
    # ** ‡πÉ‡∏ô‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á 2 ‡πÑ‡∏ü‡∏•‡πå DOCX **
    strategic_path = os.path.join(output_dir, f"{final_base_name}_Strategic.docx")
    detail_path = os.path.join(output_dir, f"{final_base_name}_RawDetails.docx")

    # --- A. ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DOCX ---
    
    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Strategic Report (Sections 1-4)
    if not final_sub_results:
        print("üö® ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡πâ‡∏≤‡∏á Strategic Report ‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Sub-Criteria ‡∏ó‡∏µ‡πà‡∏Å‡∏£‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß")
        if args.mode == "sub":
             print(f"   (‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ {args.sub})")
        # ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡πÑ‡∏õ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô 2 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Raw Details (‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)
    else:
        print(f"\n‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DOCX [Strategic Report]...")
        strategic_doc = Document()
        setup_document(strategic_doc) 
        
        # SECTION 1: Overall Summary 
        generate_overall_summary_docx(strategic_doc, summary_section, enabler_name_full) 
        # SECTION 2: Executive Summary
        generate_executive_summary_docx(strategic_doc, summary_section, final_sub_results)
        # SECTION 3: Sub-Criteria Status & Gap 
        gap_criteria_docx = generate_sub_criteria_status_docx(strategic_doc, final_sub_results)
        # SECTION 4: Action Plan Report
        generate_action_plan_report_docx(strategic_doc, gap_criteria_docx)

        strategic_doc.save(strategic_path)
        print(f"üéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DOCX [Strategic Report] ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {strategic_path}")


    # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Raw Details Working Document (Section 5)
    print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DOCX [Raw Details]...")
    detail_doc = Document()
    setup_document(detail_doc) 
    
    # SECTION 5: Raw Details (‡∏™‡πà‡∏á List ‡∏Ç‡∏≠‡∏á Statements ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á)
    generate_raw_details_report_docx(detail_doc, raw_data_for_section5)
    
    detail_doc.save(detail_path)
    print(f"üéâ ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå DOCX [Raw Details] ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏µ‡πà: {detail_path}")

    print("\n‚úÖ ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô SEAM Assessment ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")


if __name__ == "__main__":
    main()