import os
import sys
import logging
import argparse 
from typing import List, Optional, Any, Tuple
from langchain.schema import Document
from langchain.schema.retriever import BaseRetriever 
import glob # ADDED: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö

# -------------------- Logging Setup --------------------
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stdout # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ Log ‡∏≠‡∏≠‡∏Å Console
)
logger = logging.getLogger(__name__)

# -------------------- Import Core Modules --------------------
try:
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤ core.vectorstore ‡∏ñ‡∏π‡∏Å Import ‡πÑ‡∏î‡πâ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ MultiDocRetriever, NamedRetriever ‡∏≠‡∏¢‡∏π‡πà
    from core.vectorstore import VectorStoreManager, load_all_vectorstores, MultiDocRetriever, NamedRetriever 
    from core.ingest import SUPPORTED_DOC_TYPES 
except ImportError as e:
    logger.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ Import core.vectorstore ‡πÑ‡∏î‡πâ: {e}")
    logger.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏ñ‡∏π‡∏Å‡∏£‡∏±‡∏ô‡∏à‡∏≤‡∏Å Root Directory ‡∏Ç‡∏≠‡∏á‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå")
    sys.exit(1)

# -------------------- Argument Parsing --------------------
def parse_arguments():
    """Parses command line arguments for retrieval testing."""
    parser = argparse.ArgumentParser(description="Test RAG Retrieval from Vector Stores.")
    
    parser.add_argument(
        "doc_type",
        nargs='?', 
        default="document", 
        help=f"Document type to test (default: document, supported: {SUPPORTED_DOC_TYPES})",
    )
    
    parser.add_argument(
        "--enabler",
        type=str,
        default=None, 
        help="Specific enabler code for 'evidence' type (e.g., KM, L).",
    )
    
    parser.add_argument(
        "--doc_id",
        type=str,
        default=None,
        help="Stable Document UUID to test direct chunk retrieval (optional).",
    )
    
    parser.add_argument(
        "--query",
        type=str,
        default="‡∏ß‡∏¥‡∏™‡∏±‡∏¢‡∏ó‡∏±‡∏®‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡∏™‡πà‡∏ß‡∏ô‡∏†‡∏π‡∏°‡∏¥‡∏†‡∏≤‡∏Ñ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£",
        help="The query/question to use for the similarity search test.",
    )
    
    return parser.parse_args()

def test_count_vectors(retriever_wrapper: MultiDocRetriever, collection_name: str):
    """
    Test the total count of vectors (chunks) and unique documents 
    in the specified collection ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ retriever_wrapper ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    """
    print("\n" + "-" * 50)
    print(f"--- 3. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Vector (Chunks) ‡πÅ‡∏•‡∏∞ Unique Documents ‡πÉ‡∏ô Collection '{collection_name}' ---")
    print("-" * 50)
    
    try:
        if not retriever_wrapper._retrievers_list:
             print("‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: MultiDocRetriever ‡πÑ‡∏°‡πà‡∏û‡∏ö Retriever ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î")
             return

        # 1. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á NamedRetriever ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å (‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ô‡∏µ‡πâ)
        named_retriever_instance: NamedRetriever = retriever_wrapper._retrievers_list[0]

        # 2. ‡πÇ‡∏´‡∏•‡∏î BaseRetriever (ContextualCompressionRetriever ‡∏´‡∏£‡∏∑‡∏≠ ChromaRetriever)
        retriever_instance: BaseRetriever = named_retriever_instance.load_instance()
        
        # 3. ‡∏î‡∏∂‡∏á Vector Store Instance (Chroma Object)
        base_retriever = getattr(retriever_instance, 'base_retriever', None)
        vectorstore = getattr(base_retriever, 'vectorstore', None) 
        
        # Fallback: ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô BaseRetriever ‡∏ò‡∏£‡∏£‡∏°‡∏î‡∏≤ (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ Reranker)
        if not vectorstore:
            vectorstore = getattr(retriever_instance, 'vectorstore', None)


        if vectorstore and hasattr(vectorstore, 'get'):
            
            # üìå FIX: ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ "Expected where to have exactly one operator, got {} in get."
            query_where = {
                "doc_id": {
                    "$ne": "non_existent_doc_id_placeholder_to_force_query"
                }
            }
            
            # üö© MODIFIED: Request metadatas ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡∏ô‡∏±‡∏ö Unique Documents
            count_result = vectorstore.get(
                where=query_where,  # ‡πÉ‡∏ä‡πâ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≤‡∏° Chroma
                limit=None, 
                include=['metadatas'] # MODIFIED: ‡∏Ç‡∏≠ metadatas ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á doc_id
            )
            
            total_count = len(count_result['ids'])
            
            # --- NEW: Count Unique Documents ---
            # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ñ‡πà‡∏≤ doc_id ‡∏à‡∏≤‡∏Å metadatas ‡∏ó‡∏µ‡πà‡∏î‡∏∂‡∏á‡∏°‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            all_doc_ids = [m.get('doc_id') for m in count_result.get('metadatas', []) if m.get('doc_id')]
            
            # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô doc_id ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô (‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å Ingest ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à)
            unique_doc_ids = set(all_doc_ids)
            unique_doc_count = len(unique_doc_ids)
            # --- END NEW ---

            print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_count} Vector (Chunks) ‡πÉ‡∏ô Collection '{collection_name}'")
            print(f"   - ‡∏û‡∏ö {unique_doc_count} Source Document ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å Ingest ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à (Unique Doc IDs)")
        else:
            print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (Count Vectors): ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Vector Store Instance ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Collection '{collection_name}'")

    except Exception as e:
        print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (Count Vectors): {e}")

def count_source_files(collection_name: str):
    """
    Counts and reports the number of source files (.pdf, .docx, .png, .jpg)
    in the corresponding data directory (e.g., data/evidence_km).
    """
    source_dir = os.path.join('data', collection_name)
    print("\n" + "-" * 50)
    print(f"--- 3.5. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Source File ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå '{source_dir}' ---")
    print("-" * 50)
    
    file_types = {
        '.pdf': 0,
        '.docx': 0,
        '.png': 0,
        '.jpg': 0,
    }
    
    total_files = 0
    
    if not os.path.isdir(source_dir):
        print(f"‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡πÑ‡∏°‡πà‡∏û‡∏ö Source Data Directory: {source_dir}. ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö.")
        return

    try:
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢
        for file_ext in file_types.keys():
            # ‡πÉ‡∏ä‡πâ glob.glob ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏ö‡∏ö recursive
            pattern = os.path.join(source_dir, '**', f"*{file_ext}")
            files = glob.glob(pattern, recursive=True)
            file_types[file_ext] = len(files)
            total_files += len(files)

        if total_files > 0:
            print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {total_files} ‡πÑ‡∏ü‡∏•‡πå:")
            # ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå
            for ft, count in file_types.items():
                if count > 0:
                    print(f"   - {ft} : {count} ‡πÑ‡∏ü‡∏•‡πå")
        else:
            print("‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö (.pdf, .docx, .png, .jpg) ‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ô‡∏µ‡πâ.")

    except Exception as e:
        print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (Count Source Files): {e}")

def test_vectorstore_retrieval(
    doc_type: str, 
    enabler: Optional[str], 
    doc_id: Optional[str], 
    query: str
):
    doc_type_lower = doc_type.lower()
    retriever_wrapper: Optional[MultiDocRetriever] = None
    
    print("\n" + "=" * 60)
    print("--- 1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö ---")
    print(f"Collection: **{doc_type_lower}** (Enabler: {enabler or '-'})")
    print(f"Query: **{query}**")
    print(f"Stable Doc ID (Direct Test): **{doc_id or 'Skip'}**")
    print("=" * 60)

    # ------------------ A. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏´‡∏•‡∏î Vector Store ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Query ------------------
    print("\n" + "-" * 50)
    print("--- 2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö load_all_vectorstores ‡πÅ‡∏•‡∏∞ Query ---")
    print("-" * 50)
    
    collection_to_load = f"{doc_type_lower}_{enabler.lower()}" if doc_type_lower == 'evidence' and enabler else doc_type_lower
    
    try:
        # ‡πÉ‡∏ä‡πâ evidence_enabler ‡∏ï‡∏≤‡∏° signature ‡πÉ‡∏ô core/vectorstore.py
        retriever_wrapper = load_all_vectorstores(
            doc_types=[doc_type], 
            evidence_enabler=enabler 
        )
        
        # üìå ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï: ‡πÉ‡∏ä‡πâ ._retrievers_list
        print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! MultiDocRetriever ‡∏ñ‡∏π‡∏Å‡πÇ‡∏´‡∏•‡∏î‡∏î‡πâ‡∏ß‡∏¢ {len(retriever_wrapper._retrievers_list)} Retriever(s) (Collection: '{collection_to_load}')")
        
        # ------------------ B. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Query ‡∏ú‡πà‡∏≤‡∏ô Retriever ------------------
        # MultiDocRetriever ‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ method invoke
        results: List[Document] = retriever_wrapper.invoke(query)
        
        if results:
            print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏û‡∏ö {len(results)} Chunk ‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            print(f"   - Source File: {results[0].metadata.get('source_file', 'N/A')}")
            print(f"   - ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: '{results[0].page_content[:150]}...'")
        else:
            print("‚ö†Ô∏è ‡∏Ñ‡∏≥‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô: Query ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á")

    except Exception as e:
        print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (load_all_vectorstores/Query): {e}")
        
    # ------------------ C. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏±‡∏ö Vector ------------------
    if retriever_wrapper:
        # üö© NEW: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏±‡∏ö Vector ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ retriever_wrapper ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡πâ‡∏ß
        test_count_vectors(retriever_wrapper, collection_to_load)
    else:
        print("‚ùå ‡∏Ç‡πâ‡∏≤‡∏°‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö Vector: load_all_vectorstores ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà 2.")

    # ------------------ C.5. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏ô‡∏±‡∏ö Source Files ------------------
    # üö© NEW: ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏£‡πâ‡∏≠‡∏á‡∏Ç‡∏≠
    count_source_files(collection_to_load)

    # ------------------ D. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ Stable ID ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ------------------
    if doc_id:
        print("\n" + "-" * 50)
        print(f"--- 4. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ Stable ID '{doc_id}' ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á ---")
        print("-" * 50)
        
        manager = VectorStoreManager() # ‡πÇ‡∏´‡∏•‡∏î Singleton Manager
        try:
            documents = manager.get_chunks_from_doc_ids( 
                stable_doc_ids=[doc_id], 
                doc_type=doc_type_lower,
                enabler=enabler 
            )
            
            if documents:
                print(f"‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏î‡∏∂‡∏á {len(documents)} Chunk ‡∏î‡πâ‡∏ß‡∏¢ Stable ID '{doc_id}'")
                print(f"   - ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô: '{documents[0].page_content[:150]}...'")
            else:
                print(f"‚ùå ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: ‡∏î‡∏∂‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢ Stable ID '{doc_id}' ‡πÑ‡∏î‡πâ 0 ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå")
            
        except Exception as e:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏î‡πâ‡∏ß‡∏¢ Stable ID: {e}")

if __name__ == "__main__":
    args = parse_arguments()
    
    # üìå ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Enabler ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Evidence
    if args.doc_type.lower() == 'evidence' and not args.enabler:
         logger.error("‚ùå ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏ --enabler ‡πÄ‡∏°‡∏∑‡πà‡∏≠ doc_type ‡∏Ñ‡∏∑‡∏≠ 'evidence'")
         sys.exit(1)
         
    test_vectorstore_retrieval(args.doc_type, args.enabler, args.doc_id, args.query)
