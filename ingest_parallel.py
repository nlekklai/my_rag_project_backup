# core/ingest_parallel.py
import os
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
from core.ingest import process_document, DATA_DIR, SUPPORTED_TYPES

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def ingest_all_documents_parallel(max_workers: int = 4):
    """
    Parallel ingestion ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô DATA_DIR
    - ‡πÉ‡∏ä‡πâ ThreadPoolExecutor
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡∏≤‡∏° SUPPORTED_TYPES
    """
    logger.info("üöÄ Starting parallel ingestion for all documents in %s", DATA_DIR)

    if not os.path.exists(DATA_DIR):
        logger.warning("‚ö†Ô∏è DATA_DIR %s does not exist", DATA_DIR)
        return

    # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° list ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞ ingest
    files_to_process = []
    for root, _, files in os.walk(DATA_DIR):
        for f in files:
            ext = os.path.splitext(f)[1].lower()
            if ext in SUPPORTED_TYPES:
                filepath = os.path.join(root, f)
                files_to_process.append(filepath)

    if not files_to_process:
        logger.info("‚ö†Ô∏è No files found for ingestion in %s", DATA_DIR)
        return

    results = []

    # ‡πÉ‡∏ä‡πâ ThreadPoolExecutor
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {
            executor.submit(process_document, f, os.path.basename(f)): f
            for f in files_to_process
        }

        for future in as_completed(future_to_file):
            f = future_to_file[future]
            try:
                doc_id = future.result()
                results.append({"file": f, "doc_id": doc_id, "status": "processed"})
                logger.info("‚úÖ Successfully ingested %s -> %s", f, doc_id)
            except Exception as e:
                results.append({"file": f, "doc_id": None, "status": "failed", "error": str(e)})
                logger.error("‚ùå Error ingesting %s: %s", f, str(e))

    logger.info("‚úÖ Parallel ingestion completed for %d files", len(results))
    return results


if __name__ == "__main__":
    ingest_all_documents_parallel(max_workers=4)
