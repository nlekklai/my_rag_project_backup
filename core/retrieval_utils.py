import logging
import random 
import json   
from typing import List, Dict, Any, Optional, Union

# ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤ vectorstore ‡πÅ‡∏•‡∏∞ rag_prompts ‡∏ñ‡∏π‡∏Å import ‡πÑ‡∏î‡πâ
from core.vectorstore import VectorStoreManager, load_all_vectorstores 
from core.rag_prompts import SYSTEM_ASSESSMENT_PROMPT 

# Import LLM Instance Explicitly to avoid module name conflict
from models.llm import llm as llm_instance 
from langchain.schema import SystemMessage, HumanMessage 
from langchain.schema import Document 

logger = logging.getLogger(__name__)
# üö® ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô DEBUG ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Log ‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')


# =================================================================
# === MOCKING LOGIC AND GLOBAL FLAGS ===
# =================================================================

_MOCK_CONTROL_FLAG = False
_MOCK_COUNTER = 0

def set_mock_control_mode(enable: bool):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡πÇ‡∏´‡∏°‡∏î‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (CONTROLLED MOCK)"""
    global _MOCK_CONTROL_FLAG, _MOCK_COUNTER
    _MOCK_CONTROL_FLAG = enable
    if enable:
        _MOCK_COUNTER = 0
        logger.info("üîë CONTROLLED MOCK Mode ENABLED. Score will be 1 for first 5 statements, then 0.")
    else:
        logger.info("‚ùå CONTROLLED MOCK Mode DISABLED.")


# =================================================================
# === RETRIEVAL FUNCTIONS (INCLUDING THE NEW FILTER FUNCTION) ===
# =================================================================

def retrieve_statements(statements: List[str], doc_id: Optional[str] = None) -> Dict[str, List[Document]]:
    """
    Retrieve documents ‡∏à‡∏≤‡∏Å vectorstore ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö list ‡∏Ç‡∏≠‡∏á statements
    NOTE: ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏≠‡∏≤‡∏à‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÉ‡∏ô Assessment Process
    """
    vs_manager = VectorStoreManager()
    retriever = vs_manager.get_retriever(k=5) 
    if retriever is None:
        logger.error("Retriever not initialized.")
        return {stmt: [] for stmt in statements}

    results: Dict[str, List[Document]] = {}
    for stmt in statements:
        try:
            # NOTE: ‡πÉ‡∏ä‡πâ retriever.get_relevant_documents
            # (‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î‡πÉ‡∏´‡∏°‡πà ‡πÄ‡∏£‡∏≤‡∏Ñ‡∏ß‡∏£‡πÉ‡∏ä‡πâ .invoke() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏•‡∏µ‡∏Å‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á DeprecationWarning)
            docs = retriever.invoke(stmt) 
            if not docs:
                logger.warning(f"‚ö†Ô∏è No results found for statement: {stmt[:50]}...")
            results[stmt] = docs
        except Exception as e:
            logger.error(f"Retrieval failed for statement: {stmt[:50]}... Error: {e}")
            results[stmt] = []
    return results


# üö® NEW FUNCTION: retrieve_context_with_filter (‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏´‡∏•‡∏±‡∏Å)
def retrieve_context_with_filter(query: str, retriever: Any, filter_document_ids: List[str]) -> Dict[str, Any]:
    """
    Retrieval function ‡∏ó‡∏µ‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (Document ID Filter)
    ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ retriever ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    """
    if retriever is None:
        return {"top_evidences": []}

    # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á Filter Metadata (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Log ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Implement ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô)
    metadata_filter = None
    if filter_document_ids:
        metadata_filter = {
            "doc_id": {"$in": filter_document_ids}
        }
        logger.debug(f"RAG Filter Applied: {len(filter_document_ids)} documents for query: '{query[:30]}...'")

    try:
        # 2. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Search (‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô .invoke() ‡∏ï‡∏≤‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Ç‡∏≠‡∏á LangChain)
        # LangChainDeprecationWarning ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
        docs: List[Document] = retriever.invoke(query) 
        
        # 3. ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏°‡∏∑‡∏≠ ‡∏´‡∏≤‡∏Å VectorStore ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Filter ‡πÉ‡∏ô .get_relevant_documents()
        filtered_docs = []
        if filter_document_ids:
            # üí° [DEBUG FIX] ‡πÄ‡∏û‡∏¥‡πà‡∏° Log ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Filter
            logger.debug(f"Filter List: {filter_document_ids}") 

            for doc in docs:
                doc_id_in_metadata = doc.metadata.get("doc_id") # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ doc_id
                
                # üí° [DEBUG FIX] Log ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á/‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
                if doc_id_in_metadata is None:
                    logger.debug(f"Document missing 'doc_id' key. Source: {doc.metadata.get('source')}")
                elif doc_id_in_metadata not in filter_document_ids:
                    logger.debug(f"Doc ID mismatch: Metadata='{doc_id_in_metadata}' not in Filter.")

                # ‡πÇ‡∏Ñ‡πâ‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å
                if doc_id_in_metadata in filter_document_ids:
                    filtered_docs.append(doc)
            
            docs = filtered_docs
            logger.debug(f"Found {len(docs)} documents after manual filtering.")
        
        top_evidences = []
        for d in docs:
            meta = d.metadata
            top_evidences.append({
                "doc_id": meta.get("doc_id"),
                "source": meta.get("source"),
                "content": d.page_content.strip()
            })
            
        return {"top_evidences": top_evidences}
        
    except Exception as e:
        logger.error(f"Error during RAG retrieval with filter: {e}")
        return {"top_evidences": []}


# =================================================================
# === EVALUATION FUNCTION (MOCK & REAL LLM) ===
# =================================================================

def evaluate_with_llm(statement: str, context: str, standard: str) -> Dict[str, Any]:
    """
    ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ LLM ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á (‡πÇ‡∏Ñ‡πâ‡∏î‡πÄ‡∏î‡∏¥‡∏°)
    """
    global _MOCK_CONTROL_FLAG, _MOCK_COUNTER
    
    # 1. MOCK CONTROL LOGIC
    if _MOCK_CONTROL_FLAG:
        _MOCK_COUNTER += 1
        
        if _MOCK_COUNTER <= 3: 
            score = 1
            reason_text = f"MOCK: FORCED PASS (L1, Statement {_MOCK_COUNTER})"
        elif _MOCK_COUNTER in [4, 5]:
            score = 1
            reason_text = f"MOCK: FORCED PASS (L2, Statement {_MOCK_COUNTER})"
        else:
            score = 0
            reason_text = f"MOCK: FORCED FAIL (L2+, Statement {_MOCK_COUNTER})"

        logger.debug(f"MOCK COUNT: {_MOCK_COUNTER} | SCORE: {score} | STMT: '{statement[:20]}...'")
        return {"score": score, "reason": reason_text}

    
    # 2. REAL LLM CALL LOGIC

    if llm_instance is None:
        logger.error("‚ùå LLM Instance is not initialized (likely failed to connect to Ollama).")
        score = random.choice([0, 1])
        reason = f"LLM Initialization Failed (Fallback to Random Score {score})"
        return {"score": score, "reason": reason}

    # 1. ‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö User Prompt (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM)
    user_prompt = f"""
    --- Statement ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏ß‡∏£‡∏°‡∏µ) ---
    {statement}

    --- ‡πÄ‡∏Å‡∏ì‡∏ë‡πå (Standard/Rubric) ---
    {standard}

    --- ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏£‡∏¥‡∏á (Context ‡∏à‡∏≤‡∏Å Semantic Search) ---
    {context if context else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á"}

    --- ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ---
    ‡πÇ‡∏õ‡∏£‡∏î‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏ö‡∏ó‡∏ö‡∏≤‡∏ó Se-AM Consultant ‡∏ß‡πà‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏û‡∏ö (Context) ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á 
    ‡∏Å‡∏±‡∏ö Statement ‡πÅ‡∏•‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    
    ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö JSON ‡∏ó‡∏µ‡πà‡∏°‡∏µ key: 'score' (0 ‡∏´‡∏£‡∏∑‡∏≠ 1) ‡πÅ‡∏•‡∏∞ 'reason' ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô!
    ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á: {{"score": 1, "reason": "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô X ‡πÉ‡∏ô Context ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô Statement Y..."}}
    """
    
    try:
        response = llm_instance.invoke([
            SystemMessage(content=SYSTEM_ASSESSMENT_PROMPT),
            HumanMessage(content=user_prompt)
        ])
        
        llm_response_content = response.content if hasattr(response, 'content') else str(response)

        # 2. Parse JSON string ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å LLM (Robust Parsing)
        if llm_response_content.strip().startswith("```json"):
            llm_response_content = llm_response_content.strip().replace("```json", "").replace("```", "")
            
        llm_output = json.loads(llm_response_content.strip())
        
        score = int(llm_output.get("score", 0)) 
        reason = llm_output.get("reason", "No reason provided by LLM.")
        
        return {"score": score, "reason": reason}

    except Exception as e:
        logger.error(f"‚ùå LLM Evaluation failed. Using RANDOM SCORE as fallback. Error: {e}")
        score = random.choice([0, 1])
        reason = f"LLM Call Failed (Fallback to Random Score {score}): {str(e)}"
        return {"score": score, "reason": reason}