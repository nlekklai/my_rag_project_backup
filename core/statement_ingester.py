# core/statement_ingester.py

import os
import sys
import json
import logging
from typing import List, Dict, Any

# --- PATH SETUP (Must be executed first for imports to work) ---
try:
    # project_root ‡∏Ñ‡∏∑‡∏≠ my_rag_project/
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    if project_root not in sys.path:
        sys.path.append(project_root)
    
    # Import Core Functions (‡πÉ‡∏ä‡πâ Relative Import)
    from .vectorstore import save_to_vectorstore, vectorstore_exists, VECTORSTORE_DIR 
    from .ingest import clean_text # ‡∏™‡∏±‡∏ô‡∏ô‡∏¥‡∏©‡∏ê‡∏≤‡∏ô‡∏ß‡πà‡∏≤ clean_text ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô core/ingest.py
    
except ImportError as e:
    print(f"FATAL ERROR: Failed to import required modules. Check sys.path and file structure. Error: {e}", file=sys.stderr)
    sys.exit(1)

# --- CONFIGURATION ---
# 1. Source File Path (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÉ‡∏´‡πâ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà my_rag_project/evidence_checklist)
EVIDENCE_CHECKLIST_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), "..", "evidence_checklist"))
SOURCE_FILE_NAME = "km_evidence_statements_checklist.json"
SOURCE_FILE_PATH = os.path.join(EVIDENCE_CHECKLIST_DIR, SOURCE_FILE_NAME)

# 2. Target Vectorstore Config 
TARGET_DOC_TYPE = "statement"       # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå/doc_type ‡∏ó‡∏µ‡πà run_mapping_generator.py ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
TARGET_DOC_ID = "km_statements"     # ID ‡∏ó‡∏µ‡πà run_mapping_generator.py ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
TARGET_VECTORSTORE_PATH = os.path.join(VECTORSTORE_DIR, TARGET_DOC_TYPE, TARGET_DOC_ID)

# --- LOGGING SETUP ---
logging.basicConfig(level=logging.INFO, format='%(asctime)s | %(levelname)s | %(message)s')
logger = logging.getLogger(__name__)

# --- MAIN INGESTION FUNCTION ---

def ingest_km_statements(force_recreate: bool = False):
    """
    ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå km_evidence_statements_checklist.json, 
    ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• (Flatten), ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡πÉ‡∏ô Vector Store
    ‡∏ó‡∏µ‡πà vectorstore/statement/km_statements
    """
    
    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏ó‡∏≤‡∏á
    if not os.path.exists(SOURCE_FILE_PATH):
        logger.error(f"Source file not found: {SOURCE_FILE_PATH}")
        print(f"‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Statement Checklist ‡∏ó‡∏µ‡πà‡∏û‡∏≤‡∏ò: {SOURCE_FILE_PATH}")
        return

    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Vectorstore ‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á
    if vectorstore_exists(TARGET_DOC_ID, doc_type=TARGET_DOC_TYPE) and not force_recreate:
        logger.warning(f"Vectorstore already exists at {TARGET_VECTORSTORE_PATH}. Skipping ingestion.")
        print(f"‚ÑπÔ∏è Vectorstore ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {TARGET_DOC_ID} ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß. (‡πÉ‡∏ä‡πâ --force ‡πÄ‡∏û‡∏∑‡πà‡∏≠ re-index)")
        return

    logger.info(f"Loading statements from {SOURCE_FILE_PATH}...")
    try:
        with open(SOURCE_FILE_PATH, 'r', encoding='utf-8') as f:
            all_criteria = json.load(f)
    except Exception as e:
        logger.error(f"Failed to read or parse JSON file: {e}")
        return

    # 3. Flatten Data
    all_statement_texts: List[str] = []
    all_metadata: List[Dict[str, Any]] = []

    logger.info("Flattening JSON data and creating metadata...")
    for criteria in all_criteria:
        enabler_id = criteria.get("KM_Enabler_ID") # ‡πÄ‡∏ä‡πà‡∏ô 1
        sub_id = criteria.get("Sub_Criteria_ID")   # ‡πÄ‡∏ä‡πà‡∏ô 1.1
        sub_name = criteria.get("Sub_Criteria_Name_TH")
        criteria_weight = criteria.get("Weight") 

        for level in range(1, 6): # ‡∏ß‡∏ô Level 1-5
            level_key = f"Level_{level}_Statements"
            statements = criteria.get(level_key, [])
            
            for i, statement_text in enumerate(statements):
                if not statement_text or not statement_text.strip():
                    continue

                statement_num = i + 1
                cleaned_text = clean_text(statement_text) 
                
                # üö® ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠ Key ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö RAG/Generator Logic
                metadata = {
                    # --- Keys ‡∏ó‡∏µ‡πà run_mapping_generator.py ‡πÅ‡∏•‡∏∞ RAG ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á ---
                    "statement_key": f"{sub_id}_L{level}_{statement_num}", # e.g., 1.1_L1_1
                    "sub_id": sub_id,                                      # e.g., 1.1
                    "sub_name": sub_name,                                  # (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Justification)
                    "level": level,
                    "statement_number": statement_num,
                    
                    # --- RAG Standard Keys ---
                    "doc_type": TARGET_DOC_TYPE, 
                    "doc_id": TARGET_DOC_ID,     
                    "source": SOURCE_FILE_NAME,  
                    "enabler_id": f"KM-{enabler_id}",
                    "criteria_weight": criteria_weight, 
                    # --------------------------------------------------------
                }
                
                all_statement_texts.append(cleaned_text)
                all_metadata.append(metadata)

    if not all_statement_texts:
        logger.warning("No statements were extracted from the JSON.")
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö Statement ‡∏ó‡∏µ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON")
        return

    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á Vector Store
    try:
        logger.info(f"Extracted {len(all_statement_texts)} statements. Saving to vectorstore at {TARGET_VECTORSTORE_PATH}...")
        
        # üõë ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç: ‡∏•‡∏ö base_path ‡∏≠‡∏≠‡∏Å
        save_to_vectorstore(
            doc_id=TARGET_DOC_ID,
            texts=all_statement_texts,
            metadatas=all_metadata, 
            doc_type=TARGET_DOC_TYPE # 'statement'
        )
        
        logger.info(f"‚úÖ Successfully ingested statements into {TARGET_VECTORSTORE_PATH}")
        print(f"‚úÖ ‡∏™‡∏£‡πâ‡∏≤‡∏á Vector Store ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ({len(all_statement_texts)} statements)")

    except Exception as e:
        logger.error(f"Failed to save vectorstore for {TARGET_DOC_ID}: {e}", exc_info=True)
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Vector Store: {e}")

# -------------------- CLI Entry Point --------------------
if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="Ingest KM Statements Checklist into Vector Store.")
    parser.add_argument("--force", action="store_true", help="Force re-ingestion, overwriting existing vectorstore.")
    args = parser.parse_args()
    
    ingest_km_statements(force_recreate=args.force)