# core/json_extractor.py
# Ultimate Robust JSON Extractor for SEAM Assessment (Final CLEAN Version - NO UNICODE ARROWS)

import json
import logging
import re
from typing import Dict, Any, Optional, List

# pip install json5
import json5

# ‡πÉ‡∏ä‡πâ json_repair ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡∏Ñ‡∏∏‡∏ì‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏•‡πâ‡∏ß)
try:
    from json_repair import repair_json
except ImportError:
    repair_json = None


logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")


# ===================================================================
# 1. Safe integer parser
# ===================================================================
def _safe_int_parse(value: Any, default: int = 0) -> int:
    if value is None:
        return default
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏£‡∏á‡πÜ
    if isinstance(value, (int, float)):
        return int(round(value))

    if isinstance(value, str):
        value = value.strip()
        if not value or value.lower() in {"null", "none", "n/a", "-", "‡πÑ‡∏°‡πà‡∏û‡∏ö", "‡πÑ‡∏°‡πà‡∏°‡∏µ"}:
            return default
        
        # ‡∏•‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float ‡∏Å‡πà‡∏≠‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö "8", "8.0", " 8.5 ")
        try:
            return int(round(float(value)))
        except ValueError:
            # ‡∏ñ‡πâ‡∏≤‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏£‡∏á‡πÜ ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Regex ‡∏ä‡πà‡∏ß‡∏¢
            # ‡∏õ‡∏£‡∏±‡∏ö regex ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ó‡∏®‡∏ô‡∏¥‡∏¢‡∏°‡πÑ‡∏î‡πâ (‡πÄ‡∏ä‡πà‡∏ô 8.5)
            match = re.search(r'[-+]?\d*\.\d+|\d+', value)
            if match:
                try:
                    return int(round(float(match.group(0))))
                except ValueError:
                    return default
    
    return default

def _extract_first_json_object(text: str) -> Optional[str]:
    if not text:
        return None

    # 1. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î Control Characters
    text = re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', text)
    
    # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á { ‡πÅ‡∏•‡∏∞ [)
    start_brace = text.find("{")
    start_bracket = text.find("[")
    
    if start_brace == -1 and start_bracket == -1: return None
    
    if start_brace == -1: start = start_bracket
    elif start_bracket == -1: start = start_brace
    else: start = min(start_brace, start_bracket)
    
    opening_char = text[start]
    closing_char = "}" if opening_char == "{" else "]"

    # 3. ‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ Balanced Braces
    depth = 0
    in_string = False
    escape_char = False

    for i in range(start, len(text)):
        char = text[i]

        if escape_char:
            escape_char = False
            continue
        if char == "\\":
            escape_char = True
            continue

        if char == '"':
            in_string = not in_string
            continue

        if not in_string:
            if char == opening_char:   # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
                depth += 1
            elif char == closing_char: # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
                depth -= 1
                if depth == 0:
                    return text[start:i + 1]

    return None

# ===================================================================
# 3. Normalize keys to SEAM standard
# ===================================================================
def _normalize_keys(data: Any) -> Any:
    mapping = {
        # Score
        "score": "score", "llm_score": "score", "total_score": "score", "final_score": "score",
        "assessment_score": "score", "evaluation_score": "score",

        # Reason
        "reason": "reason", "explanation": "reason", "reasoning": "reason",
        "comment": "reason", "rationale": "reason", "analysis": "reason",

        # Pass/Fail
        "is_passed": "is_passed", "passed": "is_passed", "pass": "is_passed",
        "result": "is_passed", "status": "is_passed",

        # PDCA
        "p_plan_score": "P_Plan_Score", "p_score": "P_Plan_Score", "plan_score": "P_Plan_Score",
        "p": "P_Plan_Score", "plan": "P_Plan_Score",
        "d_do_score": "D_Do_Score", "do_score": "D_Do_Score", "d": "D_Do_Score", "do": "D_Do_Score",
        "c_check_score": "C_Check_Score", "c_score": "C_Check_Score", "check_score": "C_Check_Score",
        "c": "C_Check_Score", "check": "C_Check_Score",
        "a_act_score": "A_Act_Score", "a_score": "A_Act_Score", "act_score": "A_Act_Score",
        "a": "A_Act_Score", "act": "A_Act_Score",

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô _normalize_keys mapping
        "summary": "summary",
        "summarization": "summary",
        "suggestion_for_next_level": "suggestion_for_next_level",
        "suggestion": "suggestion_for_next_level",
        "next_step": "suggestion_for_next_level",
    }

    if isinstance(data, dict):
        normalized = {}
        for k, v in data.items():
            key_clean = k.strip().lower() if isinstance(k, str) else str(k)
            normalized_key = mapping.get(key_clean, k)
            normalized[normalized_key] = _normalize_keys(v)
        return normalized
    elif isinstance(data, list):
        return [_normalize_keys(item) for item in data]
    else:
        return data


# ===================================================================
# 4. Extract + parse + normalize
# ===================================================================
def _extract_normalized_dict(raw_response: Any) -> Optional[Dict[str, Any]]:
    """
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á String, AIMessage ‡πÅ‡∏•‡∏∞ LLMResult 
    ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ JSON ‡πÅ‡∏•‡∏∞ Normalize Keys
    """
    # 1. Input Guard: ‡πÅ‡∏õ‡∏•‡∏á Object ‡∏ó‡∏∏‡∏Å‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô String ‡∏Å‡πà‡∏≠‡∏ô
    raw = ""
    if raw_response is None:
        return None
    
    try:
        if isinstance(raw_response, str):
            raw = raw_response.strip()
        elif hasattr(raw_response, 'content'): # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô AIMessage ‡∏à‡∏≤‡∏Å LangChain
            raw = str(raw_response.content).strip()
        elif hasattr(raw_response, 'generations'): # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô LLMResult ‡∏à‡∏≤‡∏Å LangChain
            raw = str(raw_response.generations[0][0].text).strip()
        else:
            raw = str(raw_response).strip()
    except Exception as e:
        logger.error(f"Error converting LLM response to string: {e}")
        return None

    if not raw:
        return None

    # 2. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á JSON ‡∏Å‡πâ‡∏≠‡∏ô‡πÅ‡∏£‡∏Å‡∏î‡πâ‡∏ß‡∏¢ Balanced Braces
    json_str = _extract_first_json_object(raw)
    
    # 3. Fallback: ‡∏ñ‡πâ‡∏≤‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏• ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ Regex ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Å‡πâ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    if not json_str:
        matches = re.findall(r"\{[\s\S]*?\}", raw, re.DOTALL)
        if matches:
            json_str = max(matches, key=len)

    if not json_str:
        return None

    # 4. Parsing ‡∏î‡πâ‡∏ß‡∏¢ json5 (‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Å‡∏ß‡πà‡∏≤ json ‡∏õ‡∏Å‡∏ï‡∏¥)
    data = None
    try:
        data = json5.loads(json_str)
    except Exception:
        try:
            # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ standard json ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÄ‡∏ú‡∏∑‡πà‡∏≠ json5 ‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤
            data = json.loads(json_str)
        except Exception as e:
            logger.warning(f"Failed to parse JSON string: {json_str[:100]}... Error: {e}")
            return None

    # 5. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà LLM ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô List ‡∏Ç‡∏≠‡∏á Dict (‡πÄ‡∏ä‡πà‡∏ô [{...}])
    if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
        data = data[0]

    if not isinstance(data, dict):
        return None

    # 6. Normalize Keys ‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô SE-AM
    return _normalize_keys(data)


# ===================================================================
# 5. MAIN FUNCTION ‡∏´‡∏•‡∏±‡∏Å ‚Äì ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ó‡∏µ‡πà
# ===================================================================
def _robust_extract_json(llm_response: str) -> Dict[str, Any]:
    """
    [ULTIMATE ROBUST REVISE - v2026.1.23]
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Nested Braces (‡∏ß‡∏á‡πÄ‡∏•‡πá‡∏ö‡∏õ‡∏µ‡∏Å‡∏Å‡∏≤‡∏ã‡πâ‡∏≠‡∏ô) ‡∏î‡πâ‡∏ß‡∏¢ Recursive Regex
    - ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ JSON Syntax Error ‡∏à‡∏≤‡∏Å‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏´‡∏°‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏û‡∏π‡∏î (Quotes)
    - ‡∏£‡∏∞‡∏ö‡∏ö Multi-Key Aliasing ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏î‡∏∂‡∏á Reason/Score
    """
    logger = logging.getLogger(__name__)
    
    # 1. üõ°Ô∏è Default Safe Structure
    safe_result = {
        "score": 0.0,
        "reason": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå JSON ‡πÑ‡∏î‡πâ (System Fallback)",
        "is_passed": False,
        "summary_thai": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏£‡∏∏‡∏õ",
        "coaching_insight": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
        "P_Plan_Score": 0.0, "D_Do_Score": 0.0, "C_Check_Score": 0.0, "A_Act_Score": 0.0,
        "atomic_action_plan": []
    }

    if not llm_response:
        return safe_result

    raw_text = getattr(llm_response, 'content', str(llm_response)).strip()
    
    # Pre-Sanitize: ‡∏•‡πâ‡∏≤‡∏á Smart Quotes ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©
    processed_text = raw_text.replace('‚Äú', '"').replace('‚Äù', '"').replace('‚Äò', "'").replace('‚Äô', "'")
    processed_text = processed_text.replace('```json', '').replace('```', '').strip()

    # 2. üß© Extraction Strategy: ‡∏´‡∏≤ { ... } ‡∏Å‡πâ‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    data = {}
    try:
        # ‡πÉ‡∏ä‡πâ Greedy Match ‡∏´‡∏≤‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà { ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á } ‡∏ï‡∏±‡∏ß‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        match = re.search(r'(\{.*\})', processed_text, re.DOTALL)
        if match:
            json_str = match.group(1)
            # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏° Parse (‡πÉ‡∏ä‡πâ json5 ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏à‡∏∞‡∏î‡∏µ‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏ä‡πâ json ‡∏õ‡∏Å‡∏ï‡∏¥)
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                # ‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏° Common Issues ‡πÄ‡∏ä‡πà‡∏ô ‡∏•‡∏∑‡∏°‡πÉ‡∏™‡πà‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠ Quote ‡∏ã‡πâ‡∏≠‡∏ô
                # (‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ç‡∏≠‡∏á Regex ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô)
                clean_json_str = re.sub(r',\s*\}', '}', json_str) # ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤‡πÄ‡∏Å‡∏¥‡∏ô‡∏´‡∏ô‡πâ‡∏≤ }
                data = json.loads(clean_json_str)
    except Exception:
        # 3. üìâ Regex Fallback Layer: ‡∏ñ‡πâ‡∏≤ JSON ‡∏û‡∏±‡∏á 100% ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡∏•‡∏∞ Key
        logger.warning("‚ö†Ô∏è JSON Parse failed. Engaging Regex Key-Value scavenging.")
        # ‡∏´‡∏≤ Score
        score_m = re.search(r'"score"\s*:\s*([\d\.]+)', processed_text)
        if score_m: data["score"] = float(score_m.group(1))
        
        # ‡∏´‡∏≤ is_passed
        pass_m = re.search(r'"is_passed"\s*:\s*(true|false)', processed_text, re.I)
        if pass_m: data["is_passed"] = pass_m.group(1).lower() == "true"
        
        # ‡∏´‡∏≤ Reason
        reason_m = re.search(r'"reason"\s*:\s*"([^"]+)"', processed_text)
        if reason_m: data["reason"] = reason_m.group(1)

    # 4. üèóÔ∏è Normalization & Mapping (‡πÅ‡∏°‡∏ï‡∏ä‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤ UI Engine)
    result = {}
    
    # üí° Key-Aliasing Logic: ‡∏î‡∏±‡∏Å‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà AI ‡∏ä‡∏≠‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
    result["reason"] = (data.get("reason") or data.get("summary_thai") or data.get("explanation") or safe_result["reason"])
    result["coaching_insight"] = (data.get("coaching_insight") or data.get("insight") or result["reason"])
    result["summary_thai"] = (data.get("summary_thai") or result["reason"][:100])

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô PDCA (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô Float ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î)
    for k in ["P_Plan_Score", "D_Do_Score", "C_Check_Score", "A_Act_Score"]:
        val = data.get(k, 0.0)
        try:
            result[k] = float(val)
        except:
            result[k] = 0.0

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Score ‡∏£‡∏ß‡∏°
    try:
        if "score" in data:
            result["score"] = float(data["score"])
        else:
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ Score ‡∏£‡∏ß‡∏° ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å PDCA ‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢ (Max 2.0 per phase = 8.0)
            result["score"] = sum([result[k] for k in ["P_Plan_Score", "D_Do_Score", "C_Check_Score", "A_Act_Score"]])
    except:
        result["score"] = 0.0

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ is_passed (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô >= 1.0 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1-L2)
    isp = data.get("is_passed")
    if isp is not None:
        result["is_passed"] = bool(isp) if not isinstance(isp, str) else isp.lower() == "true"
    else:
        result["is_passed"] = result["score"] >= 1.0

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Atomic Action Plan
    raw_actions = data.get("atomic_action_plan") or data.get("action_plan") or []
    result["atomic_action_plan"] = raw_actions if isinstance(raw_actions, list) else []

    # 5. üìé ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå (Merge with Safe Defaults)
    final_output = {**safe_result, **result}
    
    return final_output

def _robust_extract_json_list(raw_text: str) -> List[Dict[str, Any]]:
    """
    [HELPER - FULL REVISED v2026.1.25]
    ‡∏™‡∏Å‡∏±‡∏î List ‡∏Ç‡∏≠‡∏á JSON ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    - ‡∏•‡∏≠‡∏á parse ‡∏ï‡∏£‡∏á ‡πÜ ‡∏Å‡πà‡∏≠‡∏ô
    - ‡πÉ‡∏ä‡πâ json_repair ‡∏Å‡∏π‡πâ‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á
    - Regex ‡∏´‡∏≤ block JSON + manual clean-up
    - Log error ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
    - ‡∏Ñ‡∏∑‡∏ô [] ‡∏ñ‡πâ‡∏≤‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    """
    if not raw_text or len(raw_text.strip()) < 2:
        return []

    original_text = raw_text  # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ log

    # Stage 1: ‡∏•‡∏ö markdown/code fences ‡∏Å‡πà‡∏≠‡∏ô
    raw_text = re.sub(r'```(?:json)?\s*|\s*```', '', raw_text).strip()

    # Stage 2: ‡∏•‡∏ö whitespace ‡πÄ‡∏Å‡∏¥‡∏ô + trailing comma
    raw_text = re.sub(r',\s*([}\]])', r'\1', raw_text)
    raw_text = re.sub(r'\s+', ' ', raw_text).strip()

    # Stage 3: ‡∏•‡∏≠‡∏á parse ‡∏ï‡∏£‡∏á ‡πÜ
    try:
        data = json.loads(raw_text)
        if isinstance(data, list):
            return data
        if isinstance(data, dict):
            return [data]  # ‡∏´‡∏∏‡πâ‡∏°‡πÄ‡∏õ‡πá‡∏ô list ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ object ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    except json.JSONDecodeError as e:
        pass  # ‡πÑ‡∏õ stage ‡∏ñ‡∏±‡∏î‡πÑ‡∏õ

    # Stage 4: ‡πÉ‡∏ä‡πâ json_repair ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ (‡∏î‡∏µ‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM output ‡∏û‡∏±‡∏á)
    if repair_json:
        try:
            repaired = repair_json(raw_text)
            data = json.loads(repaired)
            if isinstance(data, list):
                return data
            if isinstance(data, dict):
                return [data]
        except Exception as repair_err:
            pass  # ‡∏ñ‡πâ‡∏≤ repair ‡∏û‡∏±‡∏á ‡πÑ‡∏õ manual

    # Stage 5: Manual regex + clean-up
    try:
        # ‡∏´‡∏≤ [ ... ] ‡∏Å‡πâ‡∏≠‡∏ô‡πÉ‡∏´‡∏ç‡πà‡∏™‡∏∏‡∏î
        list_match = re.search(r'(\[[\s\S]*?\])', raw_text, re.DOTALL)
        if list_match:
            block = list_match.group(1)
            # ‡∏•‡∏ö control chars + unbalanced
            block = re.sub(r'[\x00-\x1F\x7F]', '', block)
            data = json.loads(block)
            if isinstance(data, list):
                return data

        # ‡∏´‡∏≤ { ... } ‡πÅ‡∏•‡πâ‡∏ß‡∏´‡∏∏‡πâ‡∏°‡πÄ‡∏õ‡πá‡∏ô list
        dict_match = re.search(r'(\{[\s\S]*?\})', raw_text, re.DOTALL)
        if dict_match:
            block = dict_match.group(1)
            block = re.sub(r'[\x00-\x1F\x7F]', '', block)
            data = json.loads(block)
            if isinstance(data, dict):
                return [data]

    except json.JSONDecodeError as je:
        # Log error ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        logger.warning(f"[ROBUST-EXTRACT-FAIL] Failed to parse JSON block: {str(je)}")
        logger.debug(f"[RAW-TEXT-SAMPLE] {original_text[:300]}...")

    # Ultimate fallback
    return []