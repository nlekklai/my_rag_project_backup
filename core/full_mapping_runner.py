# üöÄ Full Code: core/full_mapping_runner.py (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Import ‡πÅ‡∏•‡∏∞ Path)

import os
import json
import logging
import argparse
import datetime
from typing import Dict, List, Any, Set

# ----------------------------------------------------------------------
# [IMPORT FIX] - ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÉ‡∏ä‡πâ Relative Import ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡∏∞ Fallback ‡πÑ‡∏õ‡∏´‡∏≤ Absolute Import
# ----------------------------------------------------------------------
try:
    # 1. ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Relative Import (‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ python -m)
    from .evidence_mapping_generator import EvidenceMappingGenerator
except ImportError:
    # 2. ‡∏´‡∏≤‡∏Å‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß (‡∏°‡∏±‡∏Å‡∏à‡∏∞‡πÄ‡∏Å‡∏¥‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢ python core/full_mapping_runner.py)
    # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö Absolute Import ‡πÇ‡∏î‡∏¢‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤ core/ ‡∏ñ‡∏π‡∏Å‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô PYTHONPATH ‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏π‡∏Å‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    try:
        from core.evidence_mapping_generator import EvidenceMappingGenerator
    except ImportError:
        # 3. ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á Import ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á Error ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
        print("‚ùå Error: ‡πÑ‡∏°‡πà‡∏û‡∏ö evidence_mapping_generator. ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Project ‡πÅ‡∏•‡∏∞ core/__init__.py")
        print("üí° TIP: ‡∏•‡∏≠‡∏á‡∏£‡∏±‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á 'python -m core.full_mapping_runner' ‡πÅ‡∏ó‡∏ô")
        exit(1) # ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡πÄ‡∏Å‡∏¥‡∏î NameError

logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', datefmt='%Y-%m-%d %H:%M:%S')

# ----------------------------------------------------------------------
# [CONFIGURATION & PATHS]
# ----------------------------------------------------------------------
# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î PROJECT_ROOT ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≠‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ 1 ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå core/ 
# ‡πÉ‡∏ä‡πâ os.path.abspath(os.path.dirname(__file__)) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤ path ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(__file__)), ".."))

DEFAULT_EVIDENCE_DIR = "data/evidence"
INPUT_MASTER_FILE_FORMAT = "{enabler}_evidence_mapping.json" 
OUTPUT_MAPPING_FOLDER = "results"
OUTPUT_MAPPING_FORMAT = "{enabler}_mapping_output_{suffix}.json" 
OUTPUT_MAPPING_SUFFIX = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
DEFAULT_THRESHOLD = 0.5 
TOP_K_STATEMENTS = 3 

# ----------------------------------------------------------------------
# [Utility Functions]
# ----------------------------------------------------------------------

def load_master_list(enabler_id: str, file_path: str) -> List[str]:
    """
    ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Input Master JSON ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î List ‡πÑ‡∏ü‡∏•‡πå
    ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ RAG Mapping
    """
    
    file_name_to_use = file_path
    if file_path == "": 
         # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏°‡∏≤ ‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠ default ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô PROJECT_ROOT
         file_name_to_use = INPUT_MASTER_FILE_FORMAT.format(enabler=enabler_id.lower())
         full_path = os.path.join(PROJECT_ROOT, file_name_to_use)
    else:
         # ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏∏ path ‡∏°‡∏≤ (‡∏ã‡∏∂‡πà‡∏á‡∏Ñ‡∏ß‡∏£‡πÄ‡∏õ‡πá‡∏ô path ‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ó‡∏ò‡πå‡∏à‡∏≤‡∏Å Project Root)
         full_path = os.path.join(PROJECT_ROOT, file_path)
    
    if not os.path.exists(full_path):
        # ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏ó‡∏µ‡πà‡πÅ‡∏à‡πâ‡∏á ERROR
        logger.error(f"‚ùå Input Master File not found at {full_path}") 
        return [] 
        
    all_evidence_files = set()
    try:
        with open(full_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        for key_id, info in data.items():
            files = info.get("filter_ids", []) 
            all_evidence_files.update(files)
            
        logger.info(f"‚úÖ ‡πÇ‡∏´‡∏•‡∏î {len(data)} SubCriteria_Levels ‡πÅ‡∏•‡∏∞‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô {len(all_evidence_files)} ‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å {full_path}")
        return sorted(list(all_evidence_files))
        
    except Exception as e:
        logger.error(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏¢‡∏Å‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå Master List: {e}")
        return []


def generate_full_mapping(enabler_id: str, 
                          evidence_dir: str, 
                          master_list_path: str,
                          threshold: float, 
                          top_k: int) -> Dict[str, Any]:
    """
    ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ú‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ RAG Mapping
    """
    
    # 1. ‡πÇ‡∏´‡∏•‡∏î Master List 
    all_evidence_files = load_master_list(enabler_id, master_list_path)
    if not all_evidence_files:
        return {}

    # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Generator 
    try:
        # NOTE: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏ô‡∏°‡∏≤‡∏ñ‡∏∂‡∏á‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ EvidenceMappingGenerator ‡∏à‡∏∞‡∏ï‡πâ‡∏≠‡∏á‡∏ñ‡∏π‡∏Å Import ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß
        generator = EvidenceMappingGenerator(enabler_id=enabler_id) 
    except FileNotFoundError as e:
         logger.critical(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á: Statement checklist ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
         return {}
    except Exception as e:
        logger.critical(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡πâ‡∏≤‡∏¢‡πÅ‡∏£‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Generator: {e}")
        return {}
        
    # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Output ‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö SubCriteria_Level (1.1_L1)
    
    # 3.1 ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏à‡∏≤‡∏Å statement_key (1.1_L1_1) ‡πÑ‡∏õ SubCriteria_Level (1.1_L1)
    statement_to_level_map: Dict[str, str] = {}
    
    # 3.2 ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå SubCriteria_Level ‡πÅ‡∏•‡∏∞‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Statement ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Level
    output_mapping_result: Dict[str, Any] = {}
    
    for block in generator.statement_data: 
        sub_criteria_id = block.get("Sub_Criteria_ID") # e.g., '1.1'
        for i in range(1, 6):
            level_key = f"Level_{i}_Statements"
            statements_list = block.get(level_key, [])
            sub_level_key = f"{sub_criteria_id}_L{i}" # e.g., '1.1_L1'
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Output
            if sub_level_key not in output_mapping_result:
                 output_mapping_result[sub_level_key] = {
                    "enabler": enabler_id.upper(),
                    "filter_ids": set(), 
                    "notes": f"Auto-matched files/folders with prefix '{sub_level_key}'.",
                    "statements_count": len(statements_list)
                 }

            # ‡∏™‡∏£‡πâ‡∏≤‡∏á mapping ‡∏à‡∏≤‡∏Å statement_key ‡πÑ‡∏õ SubCriteria_Level
            for j in range(len(statements_list)):
                 statement_key = f"{sub_criteria_id}_L{i}_{j + 1}"
                 statement_to_level_map[statement_key] = sub_level_key
                 
    logger.info(f"üíæ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Output ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {len(output_mapping_result)} SubCriteria_Levels")
    
    # 4. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÅ‡∏•‡∏∞ Process ‡πÑ‡∏ü‡∏•‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡∏•‡∏∞‡πÑ‡∏ü‡∏•‡πå
    processed_count = 0
    # ‡πÉ‡∏ä‡πâ os.path.join ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏° PROJECT_ROOT ‡∏Å‡∏±‡∏ö evidence_dir (‡∏ã‡∏∂‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô data/evidence)
    absolute_evidence_dir = os.path.join(PROJECT_ROOT, evidence_dir) 
    
    for doc_id in all_evidence_files:
        # ‡∏£‡∏ß‡∏° absolute_evidence_dir ‡∏Å‡∏±‡∏ö doc_id (‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå)
        file_path = os.path.join(absolute_evidence_dir, doc_id) 

        if not os.path.exists(file_path):
             logger.warning(f"‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå (‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏õ): {doc_id} ‡∏ó‡∏µ‡πà {file_path}")
             continue
        
        logger.info(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ({processed_count + 1}/{len(all_evidence_files)}): {doc_id}")
        
        # 4.1. ‡∏£‡∏±‡∏ô RAG Mapping
        # NOTE: generator.process_and_suggest_mapping ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á path ‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå
        suggested_mappings = generator.process_and_suggest_mapping(
            file_path=file_path,
            doc_id=doc_id,
            top_k_statements=top_k,
            similarity_threshold=threshold
        )
        
        # 4.2. ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (‡∏Å‡∏£‡∏∏‡πä‡∏õ‡∏ï‡∏≤‡∏° SubCriteria_Level)
        if suggested_mappings:
            mapped_levels: Set[str] = set() 
            for mapping in suggested_mappings:
                statement_key = mapping["statement_key"]
                
                if statement_key in statement_to_level_map:
                    sub_level_key = statement_to_level_map[statement_key]
                    
                    if sub_level_key in output_mapping_result and sub_level_key not in mapped_levels:
                        output_mapping_result[sub_level_key]["filter_ids"].add(doc_id)
                        mapped_levels.add(sub_level_key)
                        
        processed_count += 1
        
    # 5. ‡πÅ‡∏õ‡∏•‡∏á Set ‡∏Ç‡∏≠‡∏á filter_ids ‡πÄ‡∏õ‡πá‡∏ô List ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á
    final_output: Dict[str, Any] = {}
    for sub_level_key, data in output_mapping_result.items():
        data["filter_ids"] = sorted(list(data["filter_ids"]))
        final_output[sub_level_key] = data
        
    return final_output

# ----------------------------------------------------------------------
# [Main Function]
# ----------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="Run the full evidence-to-statement mapping process for all evidence files.")
    parser.add_argument("--enabler", type=str, required=True, help="Enabler ID (e.g., KM)")
    parser.add_argument(
        "--evidence_dir", 
        type=str, 
        default=DEFAULT_EVIDENCE_DIR, 
        help="Path to the directory containing all evidence PDF files (Relative to Project Root). Default: data/evidence"
    ) 
    parser.add_argument(
        "--master_list", 
        type=str, 
        default="", 
        help=f"Path to the master JSON list of evidence files (Relative to Project Root). Default: {{enabler}}_evidence_mapping.json (at Project Root)"
    )
    parser.add_argument("--output_file", type=str, default="", help="Output file path for the final JSON mapping (Relative to Project Root). Default: results/{enabler}_mapping_output_<timestamp>.json")
    parser.add_argument("--threshold", type=float, default=DEFAULT_THRESHOLD, help=f"Minimum relevance score threshold for suggestion (Default: {DEFAULT_THRESHOLD})")
    parser.add_argument("--top_k", type=int, default=TOP_K_STATEMENTS, help=f"Maximum number of top statements to map per evidence file (Default: {TOP_K_STATEMENTS})")
    
    args = parser.parse_args()

    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠ Output File ‡πÅ‡∏ö‡∏ö Dynamic
    output_file_name = args.output_file
    if args.output_file == "":
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ä‡∏∑‡πà‡∏≠ Output File ‡πÉ‡∏ô results/ folder
        output_file_name = os.path.join(
            OUTPUT_MAPPING_FOLDER,
            OUTPUT_MAPPING_FORMAT.format(
                enabler=args.enabler.lower(),
                suffix=OUTPUT_MAPPING_SUFFIX
            )
        )
        logger.info(f"‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÅ‡∏ö‡∏ö dynamic: {output_file_name}")

    logger.info(f"--- üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô Full Evidence Mapping ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enabler: {args.enabler.upper()} ---")
    logger.warning("‚ö†Ô∏è ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Output ‡∏ñ‡∏π‡∏Å‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö SubCriteria_Level (e.g., 1.1_L1) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö run_assessmnent.py ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì")

    final_mapping_result = generate_full_mapping(
        enabler_id=args.enabler,
        evidence_dir=args.evidence_dir,
        master_list_path=args.master_list,
        threshold=args.threshold,
        top_k=args.top_k
    )

    if final_mapping_result:
        try:
            full_output_path = os.path.join(PROJECT_ROOT, output_file_name)
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Folder results/ ‡∏´‡∏≤‡∏Å‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
            os.makedirs(os.path.dirname(full_output_path), exist_ok=True) 
            
            with open(full_output_path, 'w', encoding='utf-8') as f:
                json.dump(final_mapping_result, f, ensure_ascii=False, indent=4) 
            logger.info(f"\n‚úÖ ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à! ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Mapping ‡∏â‡∏ö‡∏±‡∏ö‡πÄ‡∏ï‡πá‡∏°‡πÑ‡∏õ‡∏¢‡∏±‡∏á {full_output_path}")
            logger.info(f"‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• SubCriteria Levels ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(final_mapping_result)}")
        except Exception as e:
            logger.error(f"‚ùå ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à‡πÑ‡∏õ‡∏¢‡∏±‡∏á {full_output_path}: {e}")
    else:
        logger.error("‚ùå ‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå Mapping")

if __name__ == "__main__":
    main()