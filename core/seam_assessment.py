# core/seam_assessment.py

import sys
import json
import logging
import time
from datetime import datetime, date
import os
from typing import List, Dict, Any, Optional, Union, Tuple, Set, Final, Literal
from collections import defaultdict, OrderedDict
from dataclasses import dataclass, field
import multiprocessing # NEW: Import for parallel execution
from functools import partial
import pathlib, uuid
from langchain_core.documents import Document as LcDocument
from core.retry_policy import RetryPolicy, RetryResult
from copy import deepcopy
import tempfile
import shutil
from .json_extractor import _robust_extract_json
from filelock import FileLock  # ‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á: pip install filelock
import re
import hashlib
import copy
from database import init_db
from database import db_update_task_status as update_db_core
from pydantic import BaseModel
import random  # Added for shuffle
import psutil
import time
import unicodedata # ‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô Standard Library ‡∏Ç‡∏≠‡∏á Python ‡πÄ‡∏•‡∏¢

# -------------------- PATH SETUP & IMPORTS --------------------
try:
    PROJECT_ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    if PROJECT_ROOT not in sys.path:
        sys.path.insert(0, PROJECT_ROOT)

    # 1. Import Constants ‡∏à‡∏≤‡∏Å global_vars
    from config.global_vars import (
        MAX_LEVEL,
        EVIDENCE_DOC_TYPES,
        RERANK_THRESHOLD,
        MAX_EVI_STR_CAP,
        DEFAULT_LLM_MODEL_NAME,
        LLM_TEMPERATURE,
        MIN_RETRY_SCORE,
        MAX_PARALLEL_WORKERS,
        PDCA_PRIORITY_ORDER,
        TARGET_DEVICE,
        PDCA_PHASE_MAP,
        INITIAL_TOP_K,
        FINAL_K_RERANKED,
        MAX_CHUNKS_PER_FILE,
        MAX_CHUNKS_PER_BLOCK,
        MATURITY_LEVEL_GOALS,
        SEAM_ENABLER_FULL_NAME_TH,
        SEAM_ENABLER_FULL_NAME_EN,
        SCORING_MODE,
        MAX_CHUNKS_LOW, 
        MAX_CHUNKS_HIGH
    )
    
    # 2. Import Logic Functions
    from core.llm_data_utils import ( 
        create_structured_action_plan, evaluate_with_llm,
        retrieve_context_with_filter, retrieve_context_for_low_levels,
        evaluate_with_llm_low_level, LOW_LEVEL_K, 
        set_mock_control_mode as set_llm_data_mock_mode,
        create_context_summary_llm,
        retrieve_context_by_doc_ids,
        _fetch_llm_response,
        _get_emergency_fallback_plan,
        _check_and_handle_empty_context
    )
    from core.vectorstore import VectorStoreManager, load_all_vectorstores, get_global_reranker 
    from core.action_plan_schema import ActionPlanActions, ActionPlanResult

    # 3. üéØ Import Path Utilities
    from utils.path_utils import (
        get_mapping_file_path, 
        get_evidence_mapping_file_path, 
        get_contextual_rules_file_path,
        get_doc_type_collection_key,
        get_assessment_export_file_path,
        get_export_dir,
        get_rubric_file_path,
        _n
    )

    import assessments.seam_mocking as seam_mocking 
    
except ImportError as e:
    # -------------------- Modernized Fallback Code --------------------
    print(f"‚ö†Ô∏è WARNING: Import failed, using dynamic fallback for Mac. Error: {e}", file=sys.stderr)
    
    # Fallback Constants
    EXPORTS_DIR = "exports"
    MAX_LEVEL = 5
    INITIAL_LEVEL = 1
    QA_FINAL_K = 3
    RUBRIC_FILENAME_PATTERN = "{tenant}_{enabler}_rubric.json"
    DEFAULT_ENABLER = "KM"
    EVIDENCE_DOC_TYPES = "evidence"
    INITIAL_TOP_K = 10

    # üìå Placeholder functions for path_utils (‡∏ä‡∏µ‡πâ‡πÄ‡∏Ç‡πâ‡∏≤ data_store ‡∏ï‡∏£‡∏á‡πÜ)
    def _n(s): return str(s).lower().strip()

    def get_mapping_file_path(doc_type, tenant, year=None, enabler=None):
        t = _n(tenant)
        if _n(doc_type) == "evidence":
            return f"data_store/{t}/mapping/{year}/{t}_{year}_{_n(enabler)}_doc_id_mapping.json"
        return f"data_store/{t}/mapping/{t}_{_n(doc_type)}_doc_id_mapping.json"

    def get_evidence_mapping_file_path(tenant, year, enabler):
        t = _n(tenant)
        return f"data_store/{t}/mapping/{year}/{t}_{year}_{_n(enabler)}_evidence_mapping.json"

    def get_contextual_rules_file_path(tenant, enabler):
        t = _n(tenant)
        return f"data_store/{t}/config/{t}_{_n(enabler)}_contextual_rules.json"

    def get_rubric_file_path(tenant, enabler):
        t = _n(tenant)
        return f"data_store/{t}/config/{t}_{_n(enabler)}_rubric.json"

    # Mock Logic Functions
    def create_structured_action_plan(*args, **kwargs): return []
    def evaluate_with_llm(*args, **kwargs): return {"score": 0, "reason": "Import Error Fallback", "is_passed": False}
    def retrieve_context_with_filter(*args, **kwargs): return {"top_evidences": [], "aggregated_context": ""}
    def retrieve_context_for_low_levels(*args, **kwargs): return {"top_evidences": [], "aggregated_context": ""}
    def evaluate_with_llm_low_level(*args, **kwargs): return {"score": 0, "is_passed": False}
    def set_llm_data_mock_mode(mode): pass
    
    class VectorStoreManager: pass
    def load_all_vectorstores(*args, **kwargs): return None
    
    class ActionPlanActions:
        @staticmethod
        def generate(*args, **kwargs): return []
    
    class ActionPlanResult:
        def __init__(self): self.success = False

    PDCA_PHASE_MAP = {
        1: "Plan (‡∏Å‡∏≤‡∏£‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢)",
        2: "Do (‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÅ‡∏ú‡∏ô‡πÑ‡∏õ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô)",
        3: "Check (‡∏Å‡∏≤‡∏£‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•)",
        4: "Act (‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°)",
        5: "Sustainability (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡πÅ‡∏•‡∏∞‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏î‡∏µ)"
    }

    MATURITY_LEVEL_GOALS = {
        1: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô ‡∏°‡∏µ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô",
        2: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏ö‡∏ö ‡∏°‡∏µ‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
        3: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡πá‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô",
        4: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ä‡∏¥‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥ ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°",
        5: "‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö (Role Model)"
    }

    def _get_emergency_fallback_plan(sub_id, name, level, *args, **kwargs):
        return {"summary": f"Fallback plan for {sub_id}", "steps": []}
    
    class seam_mocking:
        @staticmethod
        def set_mock_control_mode(mode): pass
    
    def create_context_summary_llm(*args, **kwargs): 
        return {"summary": "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÑ‡∏î‡πâ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏ö‡πÇ‡∏´‡∏•‡∏î Module ‡∏û‡∏±‡∏á", "coaching": "‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ Import"}
    
    def _fetch_llm_response(*args, **kwargs): 
        return "{}"

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏´‡∏•‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÉ‡∏ô _run_single_assessment ‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ
    MAX_EVI_STR_CAP = 10.0
    RERANK_THRESHOLD = 0.35

    if "FATAL ERROR" in str(e):
        pass 
# ----------------------------------------------------------------------

logger = logging.getLogger(__name__)
if not logger.handlers:
    logging.basicConfig(level=logging.DEBUG, format="%(asctime)s - %(levelname)s - %(message)s")


def get_enabler_full_name(enabler_code: str, lang: str = "th") -> str:
    """
    ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏°‡∏Ç‡∏≠‡∏á Enabler ‡∏ï‡∏≤‡∏°‡∏£‡∏´‡∏±‡∏™ (‡πÄ‡∏ä‡πà‡∏ô "KM" ‚Üí "‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")
    
    Args:
        enabler_code (str): ‡∏£‡∏´‡∏±‡∏™ enabler ‡πÄ‡∏ä‡πà‡∏ô "KM", "CG", "SP"
        lang (str): "th" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢, "en" ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏© (default: "th")
    
    Returns:
        str: ‡∏ä‡∏∑‡πà‡∏≠‡πÄ‡∏ï‡πá‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∑‡∏ô‡∏£‡∏´‡∏±‡∏™‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
    
    Example:
        get_enabler_full_name("KM") ‚Üí "‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ"
        get_enabler_full_name("CG", "en") ‚Üí "Corporate Governance"
    """
    code = str(enabler_code).upper().strip()
    if lang.lower() == "th":
        return SEAM_ENABLER_FULL_NAME_TH.get(code, code)
    return SEAM_ENABLER_FULL_NAME_EN.get(code, code)


def get_pdca_goal_for_level(level: int) -> str:
    """
    ‡∏î‡∏∂‡∏á‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏Ç‡∏≠‡∏á Maturity Level ‡∏ô‡∏±‡πâ‡∏ô ‡πÜ
    
    Args:
        level (int): ‡∏£‡∏∞‡∏î‡∏±‡∏ö 1-5
    
    Returns:
        str: ‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠ "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢" ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏û‡∏ö
    
    Example:
        get_pdca_goal_for_level(5) ‚Üí "‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏±‡πà‡∏á‡∏¢‡∏∑‡∏ô ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏ä‡∏¥‡∏á‡∏£‡∏∏‡∏Å...‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÅ‡∏ö‡∏ö (Role Model)"
    """
    return MATURITY_LEVEL_GOALS.get(int(level), "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢")
    
def _static_worker_process(worker_input_tuple: Tuple) -> Any:
    """
    [ULTIMATE WORKER v2026.3] Isolated Execution for Parallel Assessment
    ---------------------------------------------------------------------
    - ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏†‡∏≤‡∏û‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏°‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ Process (Zero Memory Leak)
    - ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ Context ‡∏à‡∏≤‡∏Å‡πÅ‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏±‡∏á‡∏î‡πâ‡∏ß‡∏¢ Fallback Dictionary
    """

    # 1. üìÇ PATH SETUP
    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏≠‡∏á‡πÄ‡∏´‡πá‡∏ô‡πÇ‡∏°‡∏î‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Import AssessmentConfig ‡πÅ‡∏•‡∏∞ Engine ‡πÑ‡∏î‡πâ
    project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
    if project_root not in sys.path:
        sys.path.append(project_root)
        
    worker_logger = logging.getLogger(f"Worker_{os.getpid()}")

    # 2. üì¶ ROBUST UNPACKING
    try:
        (
            sub_criteria_data, enabler, target_level, mock_mode, 
            evidence_map_path, model_name, temperature,
            min_retry_score, max_retrieval_attempts, document_map, 
            action_plan_model, year, tenant
        ) = worker_input_tuple
        
        sub_id = sub_criteria_data.get('sub_id', 'UNKNOWN')
        worker_logger.info(f"‚öôÔ∏è PID:{os.getpid()} | Starting: {sub_id} ({tenant}/{year})")
        
    except Exception as e:
        return {"error": f"Worker unpacking failed: {str(e)}", "status": "critical_failure"}
        
    # 3. üèóÔ∏è RECONSTRUCT ISOLATED ENGINE
    try:
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Config ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Worker ‡∏ï‡∏±‡∏ß‡∏ô‡∏µ‡πâ
        worker_config = AssessmentConfig(
            enabler=enabler,
            tenant=tenant,
            year=int(year) if year else None,     
            target_level=target_level,
            mock_mode=mock_mode,
            model_name=model_name, 
            temperature=temperature,
            min_retry_score=min_retry_score,            
            max_retrieval_attempts=max_retrieval_attempts 
        )

        # ‡∏Ñ‡∏∑‡∏ô‡∏ä‡∏µ‡∏û Engine (‡∏à‡∏∞‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà __init__ ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÄ‡∏û‡∏¥‡πà‡∏á Patch ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÑ‡∏õ)
        worker_instance = SEAMPDCAEngine(
            config=worker_config, 
            evidence_map_path=evidence_map_path, 
            llm_instance=None,              
            vectorstore_manager=None,       
            logger_instance=worker_logger,
            document_map=document_map,      
            ActionPlanActions=action_plan_model
        )
    except Exception as e:
        worker_logger.error(f"‚ùå Worker initialization failed for {sub_id}: {e}")
        return {"sub_id": sub_id, "error": f"Init Error: {str(e)}", "status": "failed"}

    # 4. ‚ö° EXECUTE & TIME TRACKING
    try:
        start_time = time.time()
        
        # ‡∏£‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠ (Core Logic)
        result = worker_instance._run_sub_criteria_assessment_worker(sub_criteria_data)
        
        elapsed = time.time() - start_time
        worker_logger.info(f"‚úÖ PID:{os.getpid()} | Finished: {sub_id} in {elapsed:.2f}s")
        
        return result
        
    except Exception as e:
        worker_logger.error(f"‚ùå Execution error for {sub_id}: {str(e)}")
        return {
            "sub_id": sub_id,
            "error": str(e),
            "status": "failed",
            "execution_time": 0
        }
    
# =================================================================
# Configuration Class
# =================================================================
@dataclass
class AssessmentConfig:
    """Configuration for the SEAM PDCA Assessment Run."""
    
    # ------------------ 1. Assessment Context ------------------
    enabler: str = None
    tenant: str = None
    year: int = None  # üëà ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å DEFAULT_YEAR ‡πÄ‡∏õ‡πá‡∏ô None
    target_level: int = MAX_LEVEL
    mock_mode: str = "none" # 'none', 'random', 'control'
    force_sequential: bool = field(default=False) # Flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏£‡∏±‡∏ô‡πÅ‡∏ö‡∏ö Sequential

    # ------------------ 2. LLM Configuration (Configurable) ------------------
    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default ‡∏à‡∏≤‡∏Å global_vars.py
    model_name: str = DEFAULT_LLM_MODEL_NAME 
    temperature: float = LLM_TEMPERATURE

    # ------------------ 3. Adaptive RAG Retrieval Configuration ------------------
    # üü¢ NEW: ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Rerank ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ Adaptive Loop (MIN_RETRY_SCORE)
    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default 0.65 ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏û‡∏ö‡πÉ‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î Logic
    min_retry_score: float = MIN_RETRY_SCORE
    # üü¢ NEW: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏£‡∏≠‡∏ö‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á Adaptive RAG Loop (MAX_RETRIEVAL_ATTEMPTS)
    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ Default 3
    max_retrieval_attempts: int = 3
    
    # ------------------ 4. Export Configuration ------------------
    export_output: bool = field(default=False) # Flag ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡∏¥‡∏î/‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£ Export ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    export_path: str = "" # Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå Export (‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å)


# =================================================================
# SEAM Assessment Engine (PDCA Focused) - Full Revise v2026
# =================================================================
class SEAMPDCAEngine:
    
    def __init__(
        self, 
        config: AssessmentConfig,
        llm_instance: Any = None, 
        logger_instance: logging.Logger = None,
        rag_retriever_instance: Any = None,
        doc_type: str = None, 
        vectorstore_manager: Optional['VectorStoreManager'] = None,
        evidence_map_path: Optional[str] = None,
        document_map: Optional[Dict[str, str]] = None,
        is_parallel_all_mode: bool = False,
        sub_id: str = 'all',
        record_id: Optional[str] = None, # üëà ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ
        **kwargs  
    ):
        """
        [ULTIMATE REVISE v2026.3] SEAM Assessment Engine Constructor
        ‡πÄ‡∏ô‡πâ‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô (Resilience), ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢ (Sanity Check) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        """
        # -------------------------------------------------------
        # 1. Logger Setup (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö 1 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£ Trace Error)
        # -------------------------------------------------------
        self.doc_type = doc_type or getattr(config, 'doc_type', EVIDENCE_DOC_TYPES)
        clean_dt = str(self.doc_type).strip().lower()
        log_year = config.year if clean_dt == EVIDENCE_DOC_TYPES.lower() else "general"

        if logger_instance is not None:
            self.logger = logger_instance
        else:
            self.logger = logging.getLogger(__name__).getChild(
                f"Engine|{config.enabler}|{config.tenant}/{log_year}"
            )

        self.logger.info(f"üöÄ Initializing SEAMPDCAEngine: {config.enabler} ({config.tenant}/{log_year})")

        # -------------------------------------------------------
        # 2. Patch: Sanity Check & Core Configuration
        # -------------------------------------------------------
        self.config = config
        
        # [CRITICAL PATCH] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏á‡∏≤‡∏ô
        if not self.config.enabler or not self.config.tenant:
            self.logger.critical("‚ùå Mandatory Config Missing: enabler and tenant must be provided!")
            raise ValueError("Enabler and Tenant are required for SEAMPDCAEngine.")

        self.enabler = config.enabler
        self.tenant_id = config.tenant  # üëà ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ _get_semantic_tag ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
        self.year = config.year        # üëà ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ô‡∏µ‡πâ: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
        self.target_level = config.target_level
        self.sub_id = sub_id
        self.llm = llm_instance
        self.vectorstore_manager = vectorstore_manager
        self.is_parallel_all_mode = is_parallel_all_mode
        self.is_sequential = getattr(config, 'force_sequential', True)
        self.results = {}

        # -------------------------------------------------------
        # 3. Database & System Warm-up
        # -------------------------------------------------------
        try:
            init_db()  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô 'no such table' ‡∏´‡∏£‡∏∑‡∏≠ Schema mismatch
            self.logger.info("üìÇ Database Schema verified/initialized.")
        except Exception as e:
            self.logger.error(f"‚ö†Ô∏è DB Init Warning: {e} (Check if tables already exist)")

        self.record_id = record_id # üëà ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ß‡πâ‡πÉ‡∏ô instance

        # -------------------------------------------------------
        # 4. Data Loading (Rubric, Rules & Policies)
        # -------------------------------------------------------
        # ‡πÇ‡∏´‡∏•‡∏î Rubric ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô AttributeError ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
        self.rubric = self._load_rubric()
        
        # ‡πÇ‡∏´‡∏•‡∏î‡∏Å‡∏é Contextual Rules ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDCA Logic
        self.contextual_rules_map = self._load_contextual_rules_map()
        
        self.retry_policy = RetryPolicy(
            max_attempts=3,
            base_delay=2.0,
            jitter=True,
            exponential_backoff=True,
        )

        # ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (Global Constants)
        self.RERANK_THRESHOLD = RERANK_THRESHOLD
        self.MAX_EVI_STR_CAP = MAX_EVI_STR_CAP

        # -------------------------------------------------------
        # 5. Mapping & Evidence Persistence Setup
        # -------------------------------------------------------
        # 5.1 Evidence Mapping (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏∑‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á)
        self.evidence_map = {}
        if clean_dt == EVIDENCE_DOC_TYPES.lower():
            self.evidence_map_path = evidence_map_path or get_evidence_mapping_file_path(
                tenant=self.config.tenant, 
                year=self.config.year, 
                enabler=self.enabler
            )
            self.evidence_map = self._load_evidence_map()
            self.logger.info(f"üìä Evidence Mapping: Loaded {len(self.evidence_map)} keys.")

        # 5.2 Document Mapping (ID -> Filename ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥ Report/Audit)
        loaded_map = document_map or {}
        if not loaded_map:
            is_evi_mode = (clean_dt == EVIDENCE_DOC_TYPES.lower())
            mapping_path = get_mapping_file_path(
                self.doc_type, 
                tenant=self.config.tenant, 
                year=self.config.year if is_evi_mode else None,
                enabler=self.enabler if is_evi_mode else None
            )

            if os.path.exists(mapping_path):
                try:
                    with open(mapping_path, 'r', encoding='utf-8') as f:
                        raw_data = json.load(f)
                    loaded_map = {k: v.get("file_name", k) for k, v in raw_data.items()}
                    self.logger.info(f"üéØ Document Mapping: Loaded {len(loaded_map)} entries.")
                except Exception as e:
                    self.logger.error(f"‚ùå Error parsing mapping file: {e}")

        self.doc_id_to_filename_map = loaded_map
        self.document_map = loaded_map
        self.temp_map_for_save = {}

        # -------------------------------------------------------
        # 6. Lazy Engine Initialization (VSM & LLM)
        # -------------------------------------------------------
        if self.llm is None: self._initialize_llm_if_none()
        if self.vectorstore_manager is None: self._initialize_vsm_if_none()

        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ ID Mapping ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô VectorStore (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô)
        if self.vectorstore_manager:
            try:
                self.vectorstore_manager._load_doc_id_mapping()
            except: pass

        # -------------------------------------------------------
        # 7. Function Registry (Pointers)
        # -------------------------------------------------------
        self.llm_evaluator = evaluate_with_llm
        self.rag_retriever = retrieve_context_with_filter
        self.create_structured_action_plan = create_structured_action_plan
        self.ActionPlanActions = ActionPlanActions
        self.action_plan_model = ActionPlanResult

        # --- [PATCH v2026.1.17] State Management Initialization ---
        self.final_subcriteria_results = []
        self.total_stats = {}
        self.raw_llm_results = []
        self.level_details_map = {} # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ L1-L5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Gap Analysis

        # --- [CRITICAL PATCH v2026.2.20] Core Assessment States ---
        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏ô‡∏µ‡πâ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ _is_previous_level_passed ‡∏à‡∏∞‡∏°‡∏≤‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà
        self.assessment_results_map = {} 
        
        # ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏∞‡∏™‡∏° ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Step 2: Baseline Hydration
        self.previous_levels_evidence = [] 
        
        # ‡πÄ‡∏Å‡πá‡∏ö Mapping ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Level ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏° Sub-ID
        self.level_evidence_cache = {}

        self.logger.info(f"‚úÖ Engine Initialized: Ready for Assessment (Sub-ID: {self.sub_id})")
    

    # =================================================================
    # DB Proxy Methods (Enhanced v2026)
    # =================================================================
    def db_update_task_status(self, message: str, progress: Optional[int] = None, status: str = "RUNNING"):
        """
        Enhanced Wrapper ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞
        - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á record_id ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡πÉ‡∏ä‡πâ self.current_record_id ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
        - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á progress ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÄ‡∏â‡∏û‡∏≤‡∏∞ message (‡∏Ñ‡∏á‡∏Ñ‡πà‡∏≤ % ‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏ß‡πâ)
        """
        # 1. ‡∏î‡∏∂‡∏á record_id ‡∏à‡∏≤‡∏Å instance ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°
        rid = getattr(self, 'current_record_id', None) or getattr(self, 'record_id', None)
        if not rid: 
            return

        try:
            # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
            # ‡πÉ‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà progress ‡πÄ‡∏õ‡πá‡∏ô None ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å memory ‡∏´‡∏£‡∏∑‡∏≠ database 
            # ‡πÅ‡∏ï‡πà‡πÇ‡∏î‡∏¢‡∏õ‡∏Å‡∏ï‡∏¥ database.db_update_task_status ‡∏Ñ‡∏ß‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô None ‡πÉ‡∏´‡πâ‡πÄ‡∏≠
            
            # 3. ‡∏™‡πà‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï
            update_db_core(
                record_id=rid, 
                progress=progress, 
                message=message, 
                status=status
            )
            
            self.logger.debug(f"[DB-PROGRESS] {rid}: {progress if progress is not None else 'KEEP'}% - {message}")
            
        except Exception as e:
            self.logger.error(f"‚ùå DB Update Error for {rid}: {e}")

    def _initialize_llm_if_none(self):
        """Initializes LLM instance if self.llm is None."""
        if self.llm is None:
            self.logger.warning("‚ö†Ô∏è Initializing LLM: model=%s, temperature=%s", 
                                self.config.model_name, self.config.temperature)
            try:
                # üü¢ FIX: Import ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ create_llm_instance
                from models.llm import create_llm_instance 
                self.llm = create_llm_instance( 
                    model_name=self.config.model_name,
                    temperature=self.config.temperature
                )
                self.logger.info("‚úÖ LLM Instance created successfully: %s (Temp: %s)", 
                                 self.config.model_name, self.config.temperature)
            except Exception as e:
                self.logger.error(f"FATAL: Could not initialize LLM: {e}")
                raise

    def _initialize_vsm_if_none(self):
        """
        Initializes VectorStoreManager with Smart Year Selection.
        - If Evidence: Priority 1 = Specific Year, Priority 2 = Root Fallback.
        - If Document: Priority 1 = Root (General), Priority 2 = Specific Year Fallback.
        """
        if self.vectorstore_manager is not None:
            return

        # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á DocType
        clean_dt = str(self.doc_type or getattr(self.config, 'doc_type', EVIDENCE_DOC_TYPES)).strip().lower()
        is_evidence = (clean_dt == EVIDENCE_DOC_TYPES.lower())
        
        self.logger.info(f"üöÄ Loading vectorstore(s) for DocType: '{clean_dt}' (Mode: {'Evidence' if is_evidence else 'General'})")

        try:
            target_enabler = str(self.enabler).lower() if self.enabler else None
            
            # üéØ [SMART SELECTION] ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
            # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô evidence ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏ï‡∏≤‡∏°‡∏õ‡∏µ (2568) ‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô document ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏ó‡∏µ‡πà Root (None) ‡∏Å‡πà‡∏≠‡∏ô
            primary_year = self.config.year if is_evidence else None
            secondary_year = None if is_evidence else self.config.year

            # 2. First Attempt: ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç
            self.vectorstore_manager = load_all_vectorstores(
                doc_types=[clean_dt], 
                enabler_filter=target_enabler, 
                tenant=self.config.tenant, 
                year=primary_year       
            )
            
            def count_retrievers(vsm):
                if vsm and hasattr(vsm, '_multi_doc_retriever') and vsm._multi_doc_retriever:
                    return len(vsm._multi_doc_retriever._all_retrievers)
                return 0

            len_retrievers = count_retrievers(self.vectorstore_manager)
            
            # 3. Second Attempt (Fallback): ‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ ‡πÉ‡∏´‡πâ‡∏™‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏´‡∏≤‡∏≠‡∏µ‡∏Å‡πÅ‡∏ö‡∏ö
            if len_retrievers == 0:
                lookup_label = f"year {secondary_year}" if secondary_year else "tenant root"
                self.logger.info(f"‚ö†Ô∏è No collections found in primary path, searching in {lookup_label}...")
                
                self.vectorstore_manager = load_all_vectorstores(
                    doc_types=[clean_dt], 
                    enabler_filter=target_enabler, 
                    tenant=self.config.tenant, 
                    year=secondary_year       
                )
                len_retrievers = count_retrievers(self.vectorstore_manager)

            # 4. Post-Load Process
            if self.vectorstore_manager and len_retrievers > 0:
                self.vectorstore_manager._load_doc_id_mapping() 
                self.logger.info(f"‚úÖ MultiDocRetriever loaded with {len_retrievers} collections.") 
            else:
                # 5. Final Error Handling
                expected_p = f"data_store/{self.config.tenant}/vectorstore/{primary_year or 'root'}"
                self.logger.error(f"‚ùå FATAL: 0 vector store collections loaded. Please check folder: {expected_p}")
                raise ValueError(f"No vector collections found for '{target_enabler}' in {self.config.tenant}")

        except Exception as e:
            self.logger.error(f"‚ùå FATAL: Could not initialize VectorStoreManager: {str(e)}")
            raise

    # -------------------- Contextual Rules Handlers (FIXED) --------------------
    def _load_contextual_rules_map(self) -> Dict[str, Any]:
        """
        [FINAL REVISED v2026.5] ‡πÇ‡∏´‡∏•‡∏î Contextual Rules ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö multi-tenant ‡πÅ‡∏•‡∏∞ multi-enabler ‡πÄ‡∏ï‡πá‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö
        - ‡∏°‡∏µ fallback ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Maturity (L1-L5) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î
        - Logging ‡∏ó‡∏µ‡πà‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢ debug
        - ‡πÑ‡∏°‡πà raise exception (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ engine ‡∏•‡πâ‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏∞‡∏ö‡∏ö)
        """
        # 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á path ‡∏ï‡∏≤‡∏° tenant + enabler
        try:
            filepath = get_contextual_rules_file_path(
                tenant=self.config.tenant,
                enabler=self.enabler
            )
            self.logger.debug(f"üîç Attempting to load contextual rules from: {filepath}")
        except Exception as e:
            self.logger.error(f"‚ùå FATAL: Failed to generate rules file path: {e}")
            return {"_enabler_defaults": {}}

        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if not os.path.exists(filepath):
            self.logger.warning(
                f"‚ö†Ô∏è Contextual Rules file not found: {filepath}\n"
                f"   ‚Üí Using only global defaults (if available from fallback)."
            )
            return {"_enabler_defaults": {}}

        # 3. ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞ parse JSON
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
        except json.JSONDecodeError as e:
            self.logger.error(f"‚ùå JSON Decode Error in {filepath}: {e} (line {e.lineno}, col {e.colno})")
            return {"_enabler_defaults": {}}
        except Exception as e:
            self.logger.error(f"‚ùå Unexpected error reading {filepath}: {e}")
            return {"_enabler_defaults": {}}

        # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        if not isinstance(data, dict):
            self.logger.error(f"‚ùå Invalid rules format in {filepath}: Expected dict, got {type(data)}")
            return {"_enabler_defaults": {}}

        # 5. ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô criteria ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Maturity Structure
        sub_criteria_keys = [k for k in data.keys() if not k.startswith("_")]
        num_criteria = len(sub_criteria_keys)

        if num_criteria == 0:
            self.logger.warning(f"‚ö†Ô∏è No sub-criteria found in {filepath} (only defaults).")
        else:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Maturity Levels (L1, L2, ...) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            sample_sub = sub_criteria_keys[0]
            sub_data = data[sample_sub]
            level_keys = [k for k in sub_data.keys() if k.startswith("L") and len(k) >= 2]
            
            if level_keys:
                detected_levels = sorted(level_keys)
                self.logger.info(
                    f"‚úÖ Maturity-Based Rules loaded successfully!\n"
                    f"   File: {filepath}\n"
                    f"   Criteria: {num_criteria} (e.g., {sample_sub})\n"
                    f"   Levels detected: {', '.join(detected_levels)}"
                )
            else:
                self.logger.warning(
                    f"‚ö†Ô∏è Rules for '{sample_sub}' in {filepath} do not contain Maturity Levels (L1-L5).\n"
                    f"   Falling back to flat structure or defaults."
                )

        # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö _enabler_defaults
        if "_enabler_defaults" in data:
            defaults = data["_enabler_defaults"]
            if isinstance(defaults, dict) and any(k.endswith("_keywords") for k in defaults.keys()):
                self.logger.info("‚úÖ Global PDCA Keywords (_enabler_defaults) loaded.")
            else:
                self.logger.warning("‚ö†Ô∏è _enabler_defaults exists but has invalid structure.")
        else:
            self.logger.info("‚ÑπÔ∏è No _enabler_defaults section found. Using empty defaults.")

        # 7. ‡∏™‡πà‡∏á‡∏Ñ‡∏∑‡∏ô data ‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
        self.logger.info(f"‚úÖ Contextual Rules fully loaded from {filepath} ({num_criteria} criteria).")
        return data
    
    def get_rule_content(self, sub_id: str, level: int, key_type: str):
        """
        ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏à‡∏≤‡∏Å Contextual Rules ‡πÅ‡∏ö‡∏ö‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ä‡∏±‡πâ‡∏ô
        Priority: Specific Level > Sub-ID Root > Global Defaults > Fallback
        """
        rule = self.contextual_rules_map.get(sub_id, {})
        level_key = f"L{level}"

        # 1. Specific Level (e.g., 1.2 -> L1 -> query_synonyms)
        if key_type in rule.get(level_key, {}):
            return rule[level_key][key_type]

        # 2. Sub-ID Root (e.g., 1.2 -> query_synonyms)
        if key_type in rule:
            return rule[key_type]

        # 3. Global Defaults (e.g., _enabler_defaults -> plan_keywords)
        defaults = self.contextual_rules_map.get("_enabler_defaults", {})
        if key_type in defaults:
            return defaults[key_type]

        # 4. Fallback (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠ Key)
        fallbacks = {
            "require_phase": ["P", "D"], # Default ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
            "must_include_keywords": [],
            "plan_keywords": [],
            "do_keywords": [],
            "check_keywords": [],
            "act_keywords": [],
            "query_synonyms": ""
        }
        return fallbacks.get(key_type, "")

    def get_cumulative_rules(self, sub_id: str, current_level: int) -> Dict[str, Any]:
        """
        [FINAL REVISED v2026.1.20] - SMART ACCUMULATION & ROBUST MAPPING
        ------------------------------------------------------------------
        - ‡∏™‡∏∞‡∏™‡∏° Keywords (PDCA) ‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏à‡∏≤‡∏Å L1 ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        - **Robust Synonym Split**: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏î‡πâ‡∏ß‡∏¢ ‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á, ‡∏Ñ‡∏≠‡∏°‡∏°‡πà‡∏≤, ‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏°‡∏¥‡πÇ‡∏Ñ‡∏•‡∏≠‡∏ô
        - **Auto-Fallback Phases**: ‡πÄ‡∏ï‡∏¥‡∏° Required Phases ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏´‡∏≤‡∏Å Config ‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏
        - **Case-Insensitive**: ‡∏õ‡∏£‡∏±‡∏ö Keywords ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏•‡πá‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ Match
        """
        defaults = self.contextual_rules_map.get('_enabler_defaults', {})
        sub_rules = self.contextual_rules_map.get(sub_id, {})
        
        # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° OrderedDict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏Ñ‡∏≥‡∏ã‡πâ‡∏≥
        cum_keywords = {
            "plan": OrderedDict((k.lower(), None) for k in defaults.get('plan_keywords', [])),
            "do":   OrderedDict((k.lower(), None) for k in defaults.get('do_keywords', [])),
            "check": OrderedDict((k.lower(), None) for k in defaults.get('check_keywords', [])),
            "act":  OrderedDict((k.lower(), None) for k in defaults.get('act_keywords', []))
        }
        
        cum_must_include = OrderedDict()
        required_phases = set()
        level_specific_instructions = {}
        source_levels = []

        # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡∏∞‡∏™‡∏°‡∏Å‡∏é‡∏à‡∏≤‡∏Å L1 ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        for lv in range(1, current_level + 1):
            lv_key = f"L{lv}"
            level_rule = sub_rules.get(lv_key, {})
            
            if not level_rule:
                continue
            
            source_levels.append(lv)

            # A) ‡∏î‡∏∂‡∏á query_synonyms ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô must_include (Robust Split)
            synonyms_str = level_rule.get('query_synonyms', "")
            if synonyms_str:
                # ‡πÉ‡∏ä‡πâ Regex ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á "‡∏Ñ‡∏≥1 ‡∏Ñ‡∏≥2" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ñ‡∏≥1,‡∏Ñ‡∏≥2" ‡∏´‡∏£‡∏∑‡∏≠ "‡∏Ñ‡∏≥1;‡∏Ñ‡∏≥2"
                words = re.split(r'[,\s;|]+', synonyms_str)
                for word in words:
                    clean_word = word.strip().lower()
                    if clean_word:
                        cum_must_include[clean_word] = None

            # B) ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï PDCA Keywords (‡∏™‡∏∞‡∏™‡∏°‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
            for phase, key_name in [("plan", "plan_keywords"), ("do", "do_keywords"),
                                ("check", "check_keywords"), ("act", "act_keywords")]:
                new_kws = level_rule.get(key_name, [])
                for kw in new_kws:
                    cum_keywords[phase][kw.lower()] = None
            
            # C) ‡∏™‡∏∞‡∏™‡∏° Required Phases
            if 'require_phase' in level_rule:
                # ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ó‡∏±‡πâ‡∏á List ["P", "D"] ‡∏´‡∏£‡∏∑‡∏≠ String "P,D"
                phases = level_rule['require_phase']
                if isinstance(phases, str):
                    phases = re.split(r'[,\s]+', phases)
                required_phases.update([p.upper() for p in phases if p])
            
            # D) ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞ (Specific Instructions)
            specific = level_rule.get('specific_contextual_rule')
            if specific:
                level_specific_instructions[lv] = specific.strip()

        # 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å (Finalize & Fallback)
        result_keywords = {phase: list(cum_keywords[phase].keys()) for phase in cum_keywords}
        
        # Smart Fallback ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Required Phases (‡∏ñ‡πâ‡∏≤‡πÉ‡∏ô Config ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡∏¢)
        final_phases = sorted(list(required_phases))
        if not final_phases:
            if current_level <= 3: final_phases = ["P", "D"]
            elif current_level == 4: final_phases = ["P", "D", "C"]
            else: final_phases = ["P", "D", "C", "A"]

        # ‡∏™‡∏£‡πâ‡∏≤‡∏á Instructions String ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Prompt
        instructions_lines = [f"‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {sub_id} ‡∏£‡∏∞‡∏î‡∏±‡∏ö Maturity L{current_level}:"]
        for lv in sorted(level_specific_instructions.keys()):
            icon = "üéØ" if lv == current_level else "‚úÖ"
            instructions_lines.append(f"{icon} [Level {lv}]: {level_specific_instructions[lv]}")

        # 4. Logging & Return
        self.logger.info(
            f"üöÄ [RULE_CUMULATIVE] {sub_id} L{current_level} | "
            f"Must-Include: {len(cum_must_include)} words | "
            f"Phases: {final_phases}"
        )

        return {
            "plan_keywords": result_keywords["plan"],
            "do_keywords": result_keywords["do"],
            "check_keywords": result_keywords["check"],
            "act_keywords": result_keywords["act"],
            "required_phases": final_phases,
            "must_include_keywords": list(cum_must_include.keys()),
            "level_specific_instructions": level_specific_instructions,
            "all_instructions": "\n".join(instructions_lines),
            "source_summary": f"Accumulated from levels: {source_levels}"
        }

    def _check_contextual_rule_condition(
        self, 
        condition: Dict[str, Any], 
        sub_id: str, 
        level: int, 
        top_evidences: List[Dict[str, Any]]
    ) -> bool:
        """
        [SIMPLIFIED v2026] ‡πÅ‡∏Ñ‡πà log ‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô continuity + min evidence
        ‡πÑ‡∏°‡πà block ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (return True ‡πÄ‡∏™‡∏°‡∏≠)
        """
        if level > 1:
            prev_level = level - 1
            is_prev_passed = False
            if hasattr(self, 'level_details_map') and str(prev_level) in self.level_details_map:
                is_prev_passed = self.level_details_map[str(prev_level)].get('is_passed', False)
            
            if not is_prev_passed:
                self.logger.warning(f"‚ö†Ô∏è [GAP DETECTED] L{prev_level} not passed for {sub_id} L{level} - may affect validity")

        min_docs = condition.get('min_evidences', 1)
        if len(top_evidences) < min_docs:
            self.logger.warning(f"‚ö†Ô∏è [LOW EVIDENCE] {sub_id} L{level}: {len(top_evidences)} docs (required: {min_docs})")

        return True  # ‡πÑ‡∏°‡πà block

    def post_process_llm_result(
        self,
        llm_output: Any,
        level: int,
        sub_id: str = None,
        contextual_config: Dict = {},
        top_evidences: List[Dict[str, Any]] = []
    ) -> Dict[str, Any]:
        """
        [POST-PROCESS v2026.1.20 ‚Äî Enhanced with Synonym Rescue]
        - JSON Repair: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Markdown, Trailing Comma ‡πÅ‡∏•‡∏∞ Encoding
        - Smart Rescue: ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏∑‡∏ô‡∏´‡∏≤‡∏Å‡∏û‡∏ö Keywords ‡∏´‡∏£‡∏∑‡∏≠ Synonyms ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÉ‡∏ô‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
        - Rerank Safety Net: ‡πÉ‡∏ä‡πâ‡∏Å‡∏£‡∏ì‡∏µ Rerank ‡∏™‡∏π‡∏á‡πÅ‡∏ï‡πà AI ‡πÉ‡∏´‡πâ‡∏ï‡∏Å (Conflict Resolution)
        - PDCA Normalization: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡∏≤‡∏° Required Phases ‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Level
        """
        log_prefix = f"{sub_id or 'Unknown'} L{level}"

        # 1. JSON Repair & Unpacking
        if isinstance(llm_output, tuple):
            llm_output = llm_output[0] if len(llm_output) > 0 else {}
        
        if isinstance(llm_output, str):
            try:
                # ‡∏•‡πâ‡∏≤‡∏á Markdown ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô
                cleaned = re.sub(r'```json\s*|\s*```', '', llm_output)
                # ‡∏•‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏∏‡∏î‡∏°‡∏≤ (‡πÄ‡∏ä‡πà‡∏ô 1+1=2)
                cleaned = re.sub(r'(\d+\.?\d*)\s*[\+\-]\s*(\d+\.?\d*)\s*=\s*(\d+\.?\d*)', r'\3', cleaned)
                cleaned = cleaned.strip().replace(",\n}", "\n}").replace(",}", "}")
                cleaned = re.sub(r',\s*([}\]])', r'\1', cleaned) # ‡∏•‡∏ö trailing comma
                cleaned = cleaned.encode('utf-8', 'ignore').decode('utf-8')
                llm_output = json.loads(cleaned)
            except Exception as e:
                self.logger.error(f"‚ùå [JSON REPAIR FAILED] {log_prefix}: {str(e)}")
                return {"is_passed": False, "score": 0.0, "reason": "JSON Parsing Error"}

        if not isinstance(llm_output, dict):
            return {"is_passed": False, "score": 0.0, "reason": "Invalid LLM Output Format"}

        # 2. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à (Required Phases & Must-include)
        # ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å config ‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏°‡∏≤‡∏à‡∏≤‡∏Å get_cumulative_rules
        required_phases = contextual_config.get("required_phases", [])
        if not required_phases:
            # Fallback ‡∏ï‡∏≤‡∏° Maturity Level ‡∏õ‡∏Å‡∏ï‡∏¥
            if level <= 3: required_phases = ["P", "D"]
            elif level == 4: required_phases = ["P", "D", "C"]
            else: required_phases = ["P", "D", "C", "A"]

        must_include_list = contextual_config.get("must_include_keywords", [])
        
        # 3. PDCA Score Extraction + Smart Rescue (Keyword + Synonym Match)
        pdca_results = {"P": 0.0, "D": 0.0, "C": 0.0, "A": 0.0}
        reason_raw = str(llm_output.get('reason', '')).lower()
        
        for phase in ["P", "D", "C", "A"]:
            # ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢ Possible Keys
            val = float(llm_output.get(f"{phase}_Plan_Score") or 
                        llm_output.get(f"Extraction_{phase}_Score") or 
                        llm_output.get(f"score_{phase.lower()}") or 0.0)
            score = min(val, 2.0)

            # --- [SMART RESCUE LOGIC] ---
            # ‡∏Å‡∏π‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πâ‡∏≤ AI ‡πÉ‡∏´‡πâ‡∏ï‡πà‡∏≥ ‡πÅ‡∏ï‡πà‡∏û‡∏ö‡∏Ñ‡∏≥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (Keywords ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ü‡∏™‡∏ô‡∏±‡πâ‡∏ô + Synonyms ‡∏Ç‡∏≠‡∏á Level ‡∏ô‡∏±‡πâ‡∏ô)
            phase_kws = contextual_config.get(f"{phase.lower()}_keywords", [])
            # ‡∏£‡∏ß‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à (Must-include + Phase Keywords)
            critical_words = list(set(phase_kws + must_include_list))
            
            extraction_text = str(llm_output.get(f"Extraction_{phase}", "")).lower()
            combined_text = reason_raw + " " + extraction_text

            if score < 1.0 and any(kw.lower() in combined_text for kw in critical_words):
                score = 1.5  # Boost ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ú‡πà‡∏≤‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
                self.logger.info(f"üõ°Ô∏è [RESCUE: {phase}] {log_prefix} boosted by Keywords/Synonyms")

            pdca_results[phase] = score

        # 4. Adaptive Normalization (‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏ï‡∏≤‡∏°‡πÄ‡∏ü‡∏™‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö)
        raw_total_required = sum(pdca_results[p] for p in required_phases)
        max_possible_required = len(required_phases) * 2.0
        normalized_score = (raw_total_required / max_possible_required) * 2.0 if max_possible_required > 0 else 0.0
        normalized_score = round(normalized_score, 2)

        # 5. Rerank Safety Net (‡∏Å‡∏£‡∏ì‡∏µ Rerank Score ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å‡πÅ‡∏ï‡πà AI ‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)
        max_rerank = max([ev.get('relevance_score', 0.0) for ev in top_evidences]) if top_evidences else 0.0
        is_conflict = (normalized_score < 1.2) and (max_rerank > 0.88) # ‡∏õ‡∏£‡∏±‡∏ö threshold ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢

        if is_conflict:
            normalized_score = 1.2  # Force Pass
            llm_output["is_force_pass"] = True
            self.logger.warning(f"üõ°Ô∏è [RERANK-SAFETY] {log_prefix} Force Passed | Rerank: {max_rerank:.2f}")

            # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏≤‡∏¢‡πÄ‡∏ü‡∏™‡πÉ‡∏´‡πâ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Force Pass
            min_score = 1.2 / len(required_phases)
            for phase in required_phases:
                if pdca_results[phase] < min_score:
                    pdca_results[phase] = round(min_score + 0.1, 2)

        # 6. Final Decision
        is_passed = normalized_score >= 1.2
        
        # 7. Enhanced Coaching & Missing Phases
        missing_phases = [p for p in required_phases if pdca_results[p] < 1.0]
        coaching = llm_output.get("coaching_insight", "").strip()
        
        if missing_phases:
            m_str = ", ".join(missing_phases)
            coaching = f"‚ö†Ô∏è ‡∏Ç‡∏≤‡∏î‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô: {m_str}. {coaching}"
        if is_conflict:
            coaching += " (‡∏ú‡πà‡∏≤‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ã‡πâ‡∏≥)"

        # 8. Final Packaging
        final_result = {
            "score": normalized_score,
            "is_passed": is_passed,
            "pdca_breakdown": pdca_results,
            "reason": llm_output.get("reason", ""),
            "summary_thai": llm_output.get("summary_thai", ""),
            "coaching_insight": coaching,
            "required_phases": required_phases,
            "missing_phases": missing_phases,
            "needs_human_review": is_conflict or llm_output.get("consistency_check") == False
        }
        
        return final_result

    def _expand_context_with_neighbor_pages(self, top_evidences: List[Any], collection_name: str) -> List[Dict[str, Any]]:
        """
        [REVISED v2026.3.5] - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Type Mismatch & Standardize Output
        - ‡πÅ‡∏õ‡∏•‡∏á‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á (‡∏ó‡∏±‡πâ‡∏á‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡∏Ç‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà) ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Dictionary ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
        - ‡∏£‡∏±‡∏Å‡∏©‡∏≤ PDCA Rescue Tagging ‡πÉ‡∏´‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÉ‡∏´‡πâ _get_pdca_blocks_from_evidences
        """
        if not self.vectorstore_manager or not top_evidences:
            return top_evidences

        # üõ°Ô∏è STEP A: Standardize ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏±‡πâ‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Dict ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡πà‡∏≠‡∏ô
        standardized_evidences = []
        for d in top_evidences:
            if hasattr(d, 'page_content'):
                standardized_evidences.append({
                    "text": d.page_content,
                    "page_content": d.page_content,
                    "metadata": getattr(d, 'metadata', {}),
                    "rerank_score": getattr(d, 'metadata', {}).get('rerank_score', 0.5) # Fallback score
                })
            elif isinstance(d, dict):
                standardized_evidences.append(deepcopy(d))
            else:
                continue

        expanded_evidences = list(standardized_evidences)
        seen_keys = set()
        added_pages = 0
        MAX_PAGES_PER_SUB = 12
        
        # Triggers... (‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°)
        strategic_triggers = ["‡∏ß‡∏¥‡∏™‡∏±‡∏¢‡∏ó‡∏±‡∏®‡∏ô‡πå", "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á", "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å", "‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å", "‡∏Ñ‡∏≥‡∏ô‡∏≥"]
        check_triggers = ["‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏∂‡∏á‡∏û‡∏≠‡πÉ‡∏à", "‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô", "‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•", "‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", "‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "kpi", "score", "‡∏™‡∏£‡∏∏‡∏õ‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô"]
        action_triggers = ["‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£", "‡∏à‡∏±‡∏î‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", "‡∏≠‡∏ö‡∏£‡∏°", "‡∏à‡∏±‡∏î‡∏ó‡∏≥", "‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà", "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà", "‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡∏â‡∏ö‡∏±‡∏ö‡∏ó‡∏µ‡πà"]

        for doc in standardized_evidences: # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏à‡∏≤‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà Standardized ‡πÅ‡∏•‡πâ‡∏ß
            if added_pages >= MAX_PAGES_PER_SUB: break

            meta = doc.get('metadata', {})
            text = (doc.get('text', '') or "").lower()
            
            filename = meta.get("source") or meta.get("source_filename") or "Unknown File"
            doc_uuid = meta.get("stable_doc_uuid") or meta.get("doc_id")
            if not doc_uuid: continue

            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤ (‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°)
            try:
                current_page_str = str(meta.get("page_label", meta.get("page", "1")))
                current_page = int("".join(filter(str.isdigit, current_page_str)))
            except: continue

            # Advanced Offset Strategy... (‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏°)
            offsets = []
            if any(k in text for k in strategic_triggers): offsets.extend([-1, 1, 2])
            if any(k in text for k in check_triggers): offsets.extend([-2, -1, 1, 2, 3])
            if any(k in text for k in action_triggers): offsets.extend([-1, 1])
            if not offsets: offsets = [1]

            for offset in sorted(list(set(offsets))):
                target_page = current_page + offset
                if target_page < 1 or target_page == current_page: continue
                
                cache_key = f"{doc_uuid}_{target_page}"
                if cache_key in seen_keys: continue
                seen_keys.add(cache_key)

                neighbor_chunks = self.vectorstore_manager.get_chunks_by_page(
                    collection_name=collection_name,
                    stable_doc_uuid=doc_uuid,
                    page_label=str(target_page)
                )

                if neighbor_chunks:
                    for nc in neighbor_chunks:
                        nc_text = nc.page_content.lower()
                        assigned_tag = "Support" if offset < 0 else "Detail"
                        
                        # üè∑Ô∏è Smart PDCA Rescue Tagging
                        if any(k in nc_text for k in check_triggers): assigned_tag = "Check" # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô Act/Check ‡πÄ‡∏õ‡πá‡∏ô Check ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
                        elif any(k in nc_text for k in action_triggers): assigned_tag = "Do"
                        elif any(k in nc_text for k in strategic_triggers): assigned_tag = "Plan"

                        # üõ°Ô∏è ‡∏™‡∏£‡πâ‡∏≤‡∏á Dict ‡∏ó‡∏µ‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö
                        fixed_metadata = nc.metadata.copy() if hasattr(nc, 'metadata') else {}
                        fixed_metadata.update({
                            "stable_doc_uuid": doc_uuid,
                            "page_label": str(target_page),
                            "source": filename,
                            "is_supplemental": True,
                            "pdca_tag": assigned_tag 
                        })

                        expanded_evidences.append({
                            "text": nc.page_content, # ‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ (‡πÑ‡∏°‡πà‡πÄ‡∏ï‡∏¥‡∏° Prefix ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢)
                            "page_content": nc.page_content,
                            "metadata": fixed_metadata,
                            "pdca_tag": assigned_tag,
                            "is_supplemental": True,
                            "rerank_score": float(doc.get('rerank_score', 0.5)) * 0.9,
                            "source": filename # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏µ‡∏¢‡πå source ‡∏ï‡∏£‡∏á‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏ß
                        })
                    added_pages += 1

        return expanded_evidences
    
    def _resolve_evidence_filenames(self, evidence_entries: List[Any]) -> List[Dict[str, Any]]:
        """
        [ULTIMATE SAFE v2026.3] - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error 'str' has no attribute 'get'
        - ‡∏Å‡∏≤‡∏£‡∏±‡∏ô‡∏ï‡∏µ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ List of Dictionary ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
        - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô String ‡∏´‡∏£‡∏∑‡∏≠ None
        """
        resolved_entries = []
        if not evidence_entries:
            return []

        for entry in evidence_entries:
            # üõ°Ô∏è GUARD 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Dictionary ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if not isinstance(entry, dict):
                # ‡∏ñ‡πâ‡∏≤‡∏´‡∏•‡∏∏‡∏î‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô String ‡∏´‡∏£‡∏∑‡∏≠ Langchain Document ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡πâ‡∏≤‡∏°
                if hasattr(entry, 'page_content'): # ‡∏Å‡∏£‡∏ì‡∏µ‡πÄ‡∏õ‡πá‡∏ô Document Object
                    entry = {
                        "content": entry.page_content,
                        "metadata": getattr(entry, 'metadata', {}),
                        "doc_id": getattr(entry, 'metadata', {}).get('doc_id', str(hash(entry.page_content)))
                    }
                else:
                    self.logger.warning(f"‚ö†Ô∏è Skipping non-dict evidence: {type(entry)}")
                    continue

            resolved_entry = deepcopy(entry)
            doc_id = resolved_entry.get("doc_id", "")
            
            # üõ°Ô∏è GUARD 2: Metadata Check
            meta = resolved_entry.get("metadata", {})
            if not isinstance(meta, dict): meta = {}
            
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏´‡∏•‡πà‡∏á
            meta_filename = meta.get("source") or meta.get("source_filename") or meta.get("filename")
            content_raw = resolved_entry.get('content') or resolved_entry.get('text', '')
            page_label = str(meta.get("page_label") or meta.get("page") or meta.get("page_number") or "N/A")

            # 1. AI Generated / Missing Content Case
            if not content_raw:
                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ ‡πÅ‡∏ï‡πà‡∏°‡∏µ ID ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Reference ‡∏ß‡πà‡∏≤‡∏á
                resolved_entry["filename"] = "MISSING-CONTENT"
                resolved_entry["display_source"] = f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (ID: {doc_id})"
            
            # 2. Match ‡πÉ‡∏ô Map
            elif doc_id in self.doc_id_to_filename_map:
                mapped_name = self.doc_id_to_filename_map[doc_id]
                resolved_entry["filename"] = mapped_name
                resolved_entry["display_source"] = f"{os.path.basename(mapped_name)} (‡∏´‡∏ô‡πâ‡∏≤ {page_label})"
            
            # 3. Match ‡πÉ‡∏ô Metadata
            elif meta_filename:
                clean_name = os.path.basename(str(meta_filename))
                resolved_entry["filename"] = clean_name
                resolved_entry["display_source"] = f"{clean_name} (‡∏´‡∏ô‡πâ‡∏≤ {page_label})"

            # 4. Fallback ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
            else:
                short_id = str(doc_id)[:8] if doc_id else "UNKNOWN"
                resolved_entry["filename"] = f"DOC-{short_id}"
                resolved_entry["display_source"] = f"‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á {short_id} (‡∏´‡∏ô‡πâ‡∏≤ {page_label})"

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ Key ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Ñ‡∏£‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°
            if 'content' not in resolved_entry and content_raw:
                resolved_entry['content'] = content_raw

            resolved_entries.append(resolved_entry)
            
        return resolved_entries

    # ----------------------------------------------------------------------
    # üéØ FINAL FIX 2.3: Manual Map Reload Function (inside SEAMPDCAEngine)
    # ----------------------------------------------------------------------
    def _collect_previous_level_evidences(self, sub_id: str, current_level: int) -> Dict[str, List[Dict]]:
        """
        [REVISED v2026.1.18] - Robust Context Hydration
        - ‡∏î‡∏∂‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≤‡∏Å VectorStore ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô Baseline ‡πÉ‡∏´‡πâ‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£ Match UUID ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å Format (Strip dashes)
        """
        if getattr(self, 'is_parallel_all_mode', False):
            return {}

        collected = {}
        for key, ev_list in self.evidence_map.items():
            # ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÉ‡∏ô Sub-Criteria ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
            if key.startswith(f"{sub_id}.L"):
                try:
                    level_num = int(key.split(".L")[-1])
                    if level_num < current_level:
                        collected[key] = ev_list
                except: continue

        if not collected: return {}

        # 1. ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏° Unique IDs (‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡∏¢‡∏∞)
        stable_ids = set()
        for ev_list in collected.values():
            for ev in ev_list:
                sid = ev.get("stable_doc_uuid") or ev.get("doc_id")
                if sid and str(sid).lower() not in ["n/a", "none", ""]:
                    stable_ids.add(str(sid))

        if not stable_ids: return collected

        # 2. Bulk Hydration (Query ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡∏†‡∏≤‡∏û)
        vsm = self.vectorstore_manager
        chunk_map = {}
        try:
            full_chunks = vsm.get_documents_by_id(list(stable_ids), self.doc_type, self.enabler)
            for chunk in full_chunks:
                m = chunk.metadata
                # ‡πÄ‡∏Å‡πá‡∏ö Map ‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏µ‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
                keys = [str(m.get(k)) for k in ["stable_doc_uuid", "doc_id", "chunk_uuid"] if m.get(k)]
                for k in keys:
                    chunk_map[k] = {"text": chunk.page_content, "metadata": m}
                    chunk_map[k.replace("-", "")] = {"text": chunk.page_content, "metadata": m}
        except Exception as e:
            self.logger.error(f"‚ùå Hydration VSM Error: {e}")
            return collected

        # 3. Restoration Loop
        restored_count = 0
        for key, ev_list in collected.items():
            for ev in ev_list:
                sid = str(ev.get("stable_doc_uuid") or ev.get("doc_id") or "")
                data = chunk_map.get(sid) or chunk_map.get(sid.replace("-", ""))

                if data:
                    ev.update({
                        "text": data["text"],
                        "metadata": data["metadata"],
                        "is_baseline": True
                    })
                    restored_count += 1
                else:
                    ev["is_baseline"] = False
                
        self.logger.info(f"‚úÖ Hydrated {restored_count} baseline chunks for {sub_id} L{current_level}")
        return collected

    def _get_contextual_rules_prompt(self, sub_id: str, level: int) -> str:
        """
        Retrieves the specific Contextual Rule prompt for a given Sub-Criteria and Level,
        ‡∏£‡∏ß‡∏°‡∏ñ‡∏∂‡∏á‡∏Å‡∏≤‡∏£ Inject ‡∏Å‡∏é L5 ‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡∏´‡∏≤‡∏Å Level == 5
        """
        sub_id_rules = self.contextual_rules_map.get(sub_id)
        rule_text = ""
        
        # 1. ‡∏î‡∏∂‡∏á‡∏Å‡∏é‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
        if sub_id_rules:
            level_key = f"L{level}"
            specific_rule = sub_id_rules.get(level_key)
            if specific_rule:
                rule_text += f"\n--- ‡∏Å‡∏é‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ ({sub_id} L{level}) ---\n‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏Ñ‡∏ß‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏ô‡∏µ‡πâ: {specific_rule}\n"
        
        # 2. **INJECT L5 SPECIAL RULE (Safe Injection)**
        # ‡πÉ‡∏™‡πà‡∏Å‡∏é Bonus 2.0 ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô L5 ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏ö‡∏Å‡∏ß‡∏ô L3/L4
        if level == 5:
            l5_bonus_rule = """
            \n--- L5 SPECIAL RULE (Innovation & Sustainability) ---
            * **L5 PASS Condition (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö):** ‡∏´‡∏≤‡∏Å Level ‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠ **L5** ‡∏ó‡πà‡∏≤‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏° PDCA (P+D+C+A) ‡∏ï‡∏≤‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô L3/L4 ‡∏ó‡∏µ‡πà‡∏Ñ‡πâ‡∏ô‡∏û‡∏ö‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 8.0)
            * **‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç Bonus 2.0:** ‡∏´‡∏≤‡∏Å‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏° PDCA ‡πÑ‡∏î‡πâ **‚â• 7.0** **‡πÅ‡∏•‡∏∞** ‡∏ó‡πà‡∏≤‡∏ô‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠ **‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 ‡∏ä‡∏¥‡πâ‡∏ô** ‡πÉ‡∏ô Context ‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á:
                * (a) ‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏• KM / ‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏° (Innovation Award)
                * (b) ‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏ä‡∏¥‡∏á‡∏ò‡∏∏‡∏£‡∏Å‡∏¥‡∏à‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡πÑ‡∏î‡πâ (ROI, Productivity, Cost Saving)
                * (c) ‡∏Å‡∏≤‡∏£‡πÄ‡∏ú‡∏¢‡πÅ‡∏û‡∏£‡πà/‡∏Å‡∏≤‡∏£‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏¢‡∏ô‡∏≠‡∏Å (External Recognition/Publication)
            * **‡πÉ‡∏´‡πâ‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡πÉ‡∏´‡πâ Bonus Score 2.0 ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ **Score ‚â• 9.0** ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡πâ‡∏á **is_passed=true** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏¥‡∏® (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£ Reset ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô)
            """
            rule_text += l5_bonus_rule
            
        return rule_text

    def _load_rubric(self) -> Dict[str, Any]:
        """ Loads the SEAM rubric JSON file using path_utils. """
        
        # üéØ FIX: ‡πÉ‡∏ä‡πâ get_rubric_file_path ‡∏à‡∏≤‡∏Å path_utils ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Path ‡πÄ‡∏≠‡∏á
        filepath = None # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô UnboundLocalError
        
        try:
            # 1. ‡∏£‡∏±‡∏ö Path ‡∏à‡∏≤‡∏Å path_utils ‡∏ã‡∏∂‡πà‡∏á‡∏ï‡∏≠‡∏ô‡∏ô‡∏µ‡πâ‡∏ä‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏µ‡πà 'config/' ‡πÅ‡∏•‡πâ‡∏ß
            filepath = get_rubric_file_path(
                tenant=self.config.tenant,
                enabler=self.enabler
            )
        except Exception as e:
            # ‡∏î‡∏±‡∏Å‡∏à‡∏±‡∏ö Exception ‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô path_utils
            self.logger.error(f"‚ùå FATAL: Error calling get_rubric_file_path: {e}")
            return {} 

        # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if filepath is None or not os.path.exists(filepath):
            self.logger.error(f"‚ö†Ô∏è Rubric file not found at expected path: {filepath}")
            return {}

        # 3. ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå JSON
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            self.logger.info(f"‚úÖ Rubric loaded successfully from: {filepath}")
            return data
        except json.JSONDecodeError:
            self.logger.error(f"‚ùå Error decoding Rubric JSON. File might be corrupted: {filepath}")
            return {}
        except Exception as e:
            self.logger.error(f"‚ùå Error loading Rubric file from {filepath}: {e}")
            return {}
    
    # -------------------- Helper Function for Map Processing --------------------
    def _get_level_order_value(self, level_str: str) -> int:
        """Converts Level string ('L1', 'L5') to an integer for comparison."""
        try:
            return int(level_str.upper().replace('L', ''))
        except:
            return 0

    def _clean_temp_entries(self, evidence_map: Dict[str, List[Any]]) -> Dict[str, List[Dict]]:
        """
        ‡∏Å‡∏£‡∏≠‡∏á TEMP-, HASH-, ‡πÅ‡∏•‡∏∞ Unknown ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å evidence map ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô 'str' object has no attribute 'get' ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏ã‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        """
        if not evidence_map or not isinstance(evidence_map, dict):
            return {}

        cleaned_map = {}
        total_removed = 0
        total_unknown_fixed = 0
        total_invalid_type = 0

        for key, entries in evidence_map.items():
            if not isinstance(entries, list):
                continue
                
            valid_entries = []
            for entry in entries:
                # üõ°Ô∏è Defense: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                if not isinstance(entry, dict):
                    if isinstance(entry, str) and entry.strip():
                        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Å‡∏π‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô string
                        entry = {"doc_id": entry, "filename": "Unknown", "relevance_score": 0.0}
                    else:
                        total_invalid_type += 1
                        continue

                doc_id = entry.get("doc_id")
                if doc_id is None:
                    total_removed += 1
                    continue
                
                doc_id_str = str(doc_id)

                # 1. ‡∏Å‡∏£‡∏≠‡∏á TEMP- ‡πÅ‡∏•‡∏∞ HASH-
                if doc_id_str.startswith("TEMP-") or doc_id_str.startswith("HASH-"):
                    total_removed += 1
                    continue

                # 2. ‡∏Å‡∏£‡∏≠‡∏á Unknown
                if not doc_id_str or doc_id_str.lower() == "unknown":
                    total_removed += 1
                    continue

                # 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Filename
                filename = str(entry.get("filename", "")).strip()
                if not filename or filename.lower() in ["unknown", "none", "unknown_file.pdf", "n/a"]:
                    short_id = doc_id_str[:8]
                    entry["filename"] = f"‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á_{short_id}.pdf"
                    total_unknown_fixed += 1
                else:
                    try:
                        entry["filename"] = os.path.basename(filename)
                    except:
                        entry["filename"] = filename

                valid_entries.append(entry)

            if valid_entries:
                cleaned_map[key] = valid_entries

        return cleaned_map

    
    def _clean_map_for_json(self, data: Union[Dict, List, Set, Any]) -> Union[Dict, List, Any]:
        """Recursively converts objects that cannot be serialized (like sets) into lists."""
        if isinstance(data, dict):
            return {k: self._clean_map_for_json(v) for k, v in data.items()}
        elif isinstance(data, list):
            return [self._clean_map_for_json(v) for v in data]
        elif isinstance(data, set):
            return [self._clean_map_for_json(v) for v in data]
        return data

    def _save_evidence_map(self, map_to_save: Optional[Dict[str, Any]] = None):
        """
        [IRONCLAD FINAL v2026.1.18 ‚Äî Ultra Safe Edition]
        - Load-Merge-Save Pattern (‡πÑ‡∏°‡πà overwrite ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î)
        - Atomic Write + FileLock + Tempfile
        - Backup (.bak) ‡∏Å‡πà‡∏≠‡∏ô save ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        - Validate + Clean ID ‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡∏¢‡∏∞
        - Log ‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (‡∏à‡∏≥‡∏ô‡∏ß‡∏ô merge/‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï)
        - Skip ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ
        """
        try:
            map_file_path = get_evidence_mapping_file_path(
                tenant=self.config.tenant,
                year=self.config.year,
                enabler=self.enabler
            )
        except Exception as e:
            self.logger.critical(f"[EVIDENCE] FATAL: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡πÑ‡∏î‡πâ: {e}")
            raise

        lock_path = map_file_path + ".lock"
        tmp_path = None
        backup_path = map_file_path + ".bak"  # Backup ‡∏Å‡πà‡∏≠‡∏ô save

        self.logger.info(f"[EVIDENCE] Preparing atomic save ‚Üí {map_file_path}")

        try:
            os.makedirs(os.path.dirname(map_file_path), exist_ok=True)

            # Backup ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡∏Å‡πà‡∏≠‡∏ô (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å!)
            if os.path.exists(map_file_path):
                try:
                    shutil.copy2(map_file_path, backup_path)
                    self.logger.debug(f"[EVIDENCE] Backup created: {backup_path}")
                except Exception as be:
                    self.logger.warning(f"[EVIDENCE] Backup failed (non-critical): {be}")

            with FileLock(lock_path, timeout=60):
                # STEP 1: ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤‡∏à‡∏≤‡∏Å Disk (Base) ‚Äî ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡πÄ‡∏™‡∏°‡∏≠
                final_map = self._load_evidence_map(is_for_merge=True) or {}
                self.logger.debug(f"[EVIDENCE] Loaded existing map: {len(final_map)} keys")

                # STEP 2: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà (Incoming)
                incoming = {}
                if map_to_save is not None:
                    # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Payload {"evidence_map": ...} ‡πÅ‡∏•‡∏∞ Dict ‡∏ï‡∏£‡∏á ‡πÜ
                    if isinstance(map_to_save, dict) and "evidence_map" in map_to_save:
                        incoming = map_to_save["evidence_map"]
                    else:
                        incoming = map_to_save
                else:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‚Üí ‡πÉ‡∏ä‡πâ‡∏à‡∏≤‡∏Å memory ‡∏Ç‡∏≠‡∏á Engine
                    incoming = getattr(self, 'evidence_map', {}) or {}

                # Skip ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏à‡∏£‡∏¥‡∏á ‡πÜ
                if not incoming:
                    self.logger.info("[EVIDENCE] No new data incoming. Skipping write.")
                    return

                # STEP 3: Merge + Validate + Clean
                merged_new = 0
                updated_existing = 0

                for key, new_entries in incoming.items():
                    if not isinstance(new_entries, list) or not new_entries:
                        continue

                    # ‡∏î‡∏∂‡∏á entries ‡πÄ‡∏î‡∏¥‡∏° (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà)
                    current = final_map.setdefault(key, [])

                    # Index ‡πÄ‡∏î‡∏¥‡∏°‡∏î‡πâ‡∏ß‡∏¢ Clean ID
                    entry_index = {}
                    for e in current:
                        if not isinstance(e, dict):
                            continue
                        raw_id = e.get("chunk_uuid") or e.get("doc_id") or "N/A"
                        clean_id = str(raw_id).replace("-", "").lower()
                        if clean_id not in ["na", "n/a", "fallback", "none", ""]:
                            entry_index[clean_id] = e

                    # ‡∏ô‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤ Merge
                    for new_e in new_entries:
                        if not isinstance(new_e, dict):
                            continue

                        raw_new_id = new_e.get("chunk_uuid") or new_e.get("doc_id") or "N/A"
                        clean_new_id = str(raw_new_id).replace("-", "").lower()

                        # Skip ‡∏Ç‡∏¢‡∏∞
                        if clean_new_id in ["na", "n/a", "fallback", "none", ""]:
                            continue

                        new_score = new_e.get("relevance_score", 0.0)

                        if clean_new_id not in entry_index:
                            entry_index[clean_new_id] = new_e
                            merged_new += 1
                        else:
                            old_e = entry_index[clean_new_id]
                            old_score = old_e.get("relevance_score", 0.0)

                            # ‡∏£‡∏±‡∏Å‡∏©‡∏≤ metadata ‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡∏Ç‡∏≤‡∏î
                            if "page" not in new_e or new_e["page"] in ["N/A", None]:
                                new_e["page"] = old_e.get("page")
                            if "page_label" not in new_e:
                                new_e["page_label"] = old_e.get("page_label")

                            if new_score >= old_score:
                                entry_index[clean_new_id] = new_e
                                updated_existing += 1

                    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏•‡∏±‡∏ö
                    final_map[key] = list(entry_index.values())

                # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£ merge ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‚Üí skip
                if merged_new == 0 and updated_existing == 0:
                    self.logger.info("[EVIDENCE] No unique new/updated entries. Skipping write.")
                    return

                # STEP 4: Clean + Sort
                final_map = self._clean_temp_entries(final_map)
                for key, entries in final_map.items():
                    entries.sort(key=lambda x: x.get("relevance_score", 0.0), reverse=True)

                # STEP 5: Atomic Write
                with tempfile.NamedTemporaryFile(
                    mode='w', delete=False, encoding="utf-8", dir=os.path.dirname(map_file_path)
                ) as tmp_file:
                    cleaned_data = self._clean_map_for_json(final_map)
                    json.dump(cleaned_data, tmp_file, indent=4, ensure_ascii=False)
                    tmp_path = tmp_file.name

                shutil.move(tmp_path, map_file_path)
                tmp_path = None

                total_keys = len(final_map)
                total_items = sum(len(v) for v in final_map.values())
                self.logger.info(
                    f"‚úÖ [EVIDENCE] SAVED SUCCESSFULLY! "
                    f"Keys: {total_keys} | Items: {total_items} | "
                    f"New: {merged_new} | Updated: {updated_existing}"
                )

        except Exception as e:
            self.logger.critical("[EVIDENCE] FATAL ERROR DURING ATOMIC SAVE")
            self.logger.exception(e)
            raise
        finally:
            # Cleanup
            if os.path.exists(lock_path):
                try:
                    os.unlink(lock_path)
                except:
                    pass
            if tmp_path and os.path.exists(tmp_path):
                try:
                    os.unlink(tmp_path)
                except:
                    pass

    def merge_evidence_mappings(self, results_list: List[Any]) -> Dict[str, List[Dict]]:
        """
        [ULTIMATE STABLE v2026.1.18 ‚Äî Key Mismatch Fix]
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Ñ‡∏µ‡∏¢‡πå 'evidence_sources' ‡∏à‡∏≤‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà
        - ‡∏ó‡∏≥ Deduplication ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ chunk_uuid/doc_id
        """
        merged_mapping = {}
        
        self.logger.info(f"üß¨ Starting to merge evidence mappings from {len(results_list)} levels...")

        for item in results_list:
            if not item: continue
            
            temp_map = {}
            
            # 1. ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Mapping ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡πà‡∏≤‡∏á‡πÜ
            if isinstance(item, tuple) and len(item) == 2:
                temp_map = item[1]
            elif isinstance(item, dict):
                # [FIX] ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ 'evidence_sources' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å _run_single_assessment ‡πÑ‡∏î‡πâ
                if 'evidence_sources' in item:
                    level_key = f"{item.get('sub_id', 'Unknown')}_L{item.get('level', 0)}"
                    temp_map = {level_key: item['evidence_sources']}
                elif 'temp_map_for_level' in item:
                    level_key = f"{item.get('sub_id', 'Unknown')}_L{item.get('level', 0)}"
                    data = item.get('temp_map_for_level', [])
                    temp_map = {level_key: data} if isinstance(data, list) else {}
                elif 'evidence_mapping' in item:
                    temp_map = item['evidence_mapping']
                else:
                    # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏µ‡∏¢‡πå‡∏û‡∏¥‡πÄ‡∏®‡∏© ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô dict ‡∏Ç‡∏≠‡∏á mapping ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
                    temp_map = item

            if not temp_map or not isinstance(temp_map, dict):
                continue

            # 2. ‡∏ß‡∏ô Loop ‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏±‡∏ö‡∏Å‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏Å
            for level_key, evidence_list in temp_map.items():
                actual_list = []
                if isinstance(evidence_list, list):
                    actual_list = evidence_list
                elif isinstance(evidence_list, dict) and 'evidences' in evidence_list:
                    actual_list = evidence_list['evidences']
                else:
                    continue 
                
                if level_key not in merged_mapping:
                    merged_mapping[level_key] = []
                
                # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Set ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ã‡πâ‡∏≥ (Deduplication)
                existing_ids = set()
                for e in merged_mapping[level_key]:
                    eid = str(e.get('chunk_uuid') or e.get('doc_id') or "N/A").replace("-", "").lower()
                    existing_ids.add(eid)
                
                for new_ev in actual_list:
                    if not isinstance(new_ev, dict): continue
                    
                    raw_new_id = new_ev.get('chunk_uuid') or new_ev.get('doc_id') or "N/A"
                    clean_new_id = str(raw_new_id).replace("-", "").lower()

                    if clean_new_id in ["na", "n/a", "fallback", "none", "", "unknown"]:
                        continue

                    if clean_new_id not in existing_ids:
                        merged_mapping[level_key].append(new_ev)
                        existing_ids.add(clean_new_id)
        
        total_items = sum(len(v) for v in merged_mapping.values())
        self.logger.info(f"‚úÖ Merging completed. Levels: {len(merged_mapping)} | Total items: {total_items}")
        
        return merged_mapping

    def _load_evidence_map(self, is_for_merge: bool = False) -> Dict[str, List[Dict[str, Any]]]:
        """
        [REVISED v2026.1.16]
        - ‡πÄ‡∏û‡∏¥‡πà‡∏° cache ‡πÉ‡∏ô memory ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î I/O
        - Clean ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤ (‡∏•‡∏ö fallback/na)
        """
        if hasattr(self, '_evidence_cache') and self._evidence_cache is not None:
            return deepcopy(self._evidence_cache)

        try:
            path = get_evidence_mapping_file_path(
                tenant=self.config.tenant,
                year=self.config.year,
                enabler=self.enabler
            )
        except Exception as e:
            self.logger.error(f"[EVIDENCE] FATAL: ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏î‡πâ: {e}")
            return {}

        if not os.path.exists(path):
            if not is_for_merge:
                self.logger.info("[EVIDENCE] No existing evidence map found ‚Äì starting fresh.")
            return {}

        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)

            # Clean ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÇ‡∏´‡∏•‡∏î‡∏°‡∏≤
            for key in list(data.keys()):
                entries = data[key]
                cleaned = []
                for e in entries:
                    raw_id = e.get("chunk_uuid") or e.get("doc_id") or "N/A"
                    clean_id = str(raw_id).replace("-", "").lower()
                    if clean_id not in ["na", "n/a", "fallback", "none", ""]:
                        cleaned.append(e)
                data[key] = cleaned

            # Cache ‡πÉ‡∏ô memory
            self._evidence_cache = deepcopy(data)

            if not is_for_merge:
                total_items = sum(len(v) for v in data.values())
                self.logger.info(f"[EVIDENCE] Loaded evidence map: {len(data)} keys, {total_items} items from {path}")

            return data
        except Exception as e:
            self.logger.error(f"[EVIDENCE] Failed to load evidence map from {path}: {e}")
            return {}


    def _set_mock_handlers(self, mode: str):
        """Replaces real LLM/RAG functions with mock versions."""
        if mode == "control" or mode == "random":
            if hasattr(seam_mocking, 'evaluate_with_llm_CONTROLLED_MOCK'):
                self.llm_evaluator = seam_mocking.evaluate_with_llm_CONTROLLED_MOCK
            if hasattr(seam_mocking, 'retrieve_context_with_filter_MOCK'):
                self.rag_retriever = seam_mocking.retrieve_context_with_filter_MOCK
            if hasattr(seam_mocking, 'create_structured_action_plan_MOCK'):
                self.action_plan_generator = seam_mocking.create_structured_action_plan_MOCK
            if hasattr(seam_mocking, 'set_mock_control_mode'):
                seam_mocking.set_mock_control_mode(mode == "control") 

        logger.warning(f"Engine is running in MOCK mode: {mode}")


    # -------------------- Statement Preparation & Filtering Helpers --------------------
    def _flatten_rubric_to_statements(self) -> List[Dict[str, Any]]:
        """
        Transforms the hierarchical rubric structure loaded in self.rubric
        into a flat list of statements ready for assessment.
        """
        if not self.rubric:
            self.logger.warning("Cannot flatten rubric: self.rubric is empty.")
            return []
            
        data = deepcopy(self.rubric)
        extracted_list = []
        
        if not isinstance(data, dict):
             self.logger.error("Rubric data structure is invalid (expected dict of criteria).")
             return []
             
        # for criteria_id, criteria_data in data.items():
        for criteria_id, criteria_data in data.get('criteria', {}).items():
            # üéØ FIX 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Criteria Data
            if not isinstance(criteria_data, dict):
                self.logger.warning(f"Skipping malformed criteria entry: {criteria_id} (not a dict).")
                continue
                
            sub_criteria_map = criteria_data.get('subcriteria', {})
            criteria_name = criteria_data.get('name')
            
            # üéØ FIX 2: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Sub-criteria Map
            if not isinstance(sub_criteria_map, dict):
                 self.logger.warning(f"Skipping criteria {criteria_id}: 'subcriteria' is not a dictionary.")
                 continue

            for sub_id, sub_data in sub_criteria_map.items():
                
                # üéØ FIX 3: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ sub_data ‡πÄ‡∏õ‡πá‡∏ô Dictionary ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô TypeError)
                if not isinstance(sub_data, dict):
                    self.logger.warning(
                        f"Skipping malformed sub-criteria entry: {criteria_id}.{sub_id} "
                        f"is not a dictionary (found type: {type(sub_data).__name__})."
                    )
                    continue
                
                # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤ Metadata ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
                sub_data['criteria_id'] = criteria_id
                sub_data['criteria_name'] = criteria_name
                sub_data['sub_id'] = sub_id 
                sub_data['sub_criteria_name'] = sub_data.get('name', criteria_name + ' sub')
                if 'weight' not in sub_data:
                    sub_data['weight'] = criteria_data.get('weight', 0)
                extracted_list.append(sub_data)

        # Re-check and re-sort levels
        final_list = []
        for sub_criteria in extracted_list: 
            
            # üéØ FIX 4: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á Level ‡∏à‡∏≤‡∏Å Dict ‡∏ó‡∏µ‡πà‡∏°‡∏µ Key ‡πÄ‡∏õ‡πá‡∏ô String ‡πÄ‡∏õ‡πá‡∏ô List
            if "levels" in sub_criteria and isinstance(sub_criteria["levels"], dict):
                levels_list = []
                for level_str, statement in sub_criteria["levels"].items():
                    try:
                        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÅ‡∏õ‡∏•‡∏á Level Key ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Integer
                        level_int = int(level_str)
                        if isinstance(statement, str):
                            levels_list.append({"level": level_int, "statement": statement})
                        else:
                            self.logger.warning(f"Level {level_str} statement in {sub_criteria.get('sub_id')} is not a string.")
                    except ValueError:
                        self.logger.error(f"Invalid level key '{level_str}' found in {sub_criteria.get('sub_id', 'UNKNOWN_ID')}. Skipping.")
                        continue
                        
                sub_criteria["levels"] = levels_list
            
            # ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö
            if "levels" in sub_criteria and isinstance(sub_criteria["levels"], list):
                 sub_criteria["levels"].sort(key=lambda x: x.get("level", 0))
                 final_list.append(sub_criteria)
            else:
                 self.logger.warning(f"Sub-criteria {sub_criteria.get('sub_id', 'UNKNOWN_ID')} missing 'levels' list.")


        return final_list

    
    # -------------------- Evidence Classification Helper (Robust 2026) --------------------
    def _get_mapped_uuids_and_priority_chunks(
        self,
        sub_id: str,
        level: int,
        statement_text: str = "",
        level_constraint: Optional[Any] = None, # üü¢ ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô Optional ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error Missing Argument
        vectorstore_manager: Optional['VectorStoreManager'] = None,
        evidence_map: Optional[Dict] = None 
    ) -> Tuple[List[str], List[Dict]]:
        """
        [DYNAMIC CONTINUITY v2026.6.2] - ROBUST SIGNATURE
        ----------------------------------------------
        - Fix: ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Error 'missing 1 required positional argument'
        - Logic: ‡∏î‡∏∂‡∏á Baseline ‡∏à‡∏≤‡∏Å Memory/Map ‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Inheritance)
        """
        from copy import deepcopy
        priority_chunks = []
        mapped_stable_ids = []

        # 1. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÉ‡∏ä‡πâ Evidence Map (‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: 1. Argument ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ -> 2. Class Attribute -> 3. Empty Dict)
        target_map = evidence_map if evidence_map is not None else getattr(self, 'evidence_map', {})

        # 2. üß† [AUTO-HISTORY & INHERITANCE]
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏ú‡πà‡∏≤‡∏ô‡πÉ‡∏ô Level ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡∏≥‡∏°‡∏≤‡πÉ‡∏ä‡πâ‡πÉ‡∏ô Level ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
        for key, evidences in target_map.items():
            if key.startswith(f"{sub_id}.L") and isinstance(evidences, list):
                try:
                    lvl_in_key = int(key.split(".L")[-1])
                    # ‡∏Å‡∏é Inheritance: ‡πÉ‡∏ä‡πâ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å Level ‡∏ó‡∏µ‡πà <= ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
                    if lvl_in_key <= level:
                        history_items = deepcopy(evidences)
                        for item in history_items:
                            item["is_baseline"] = True
                            # ‡∏ö‡∏π‡∏™‡∏ï‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á‡∏Ç‡∏≠‡∏á RAG
                            item["rerank_score"] = max(item.get("rerank_score", 0.0), 0.85)
                        priority_chunks.extend(history_items)
                except (ValueError, IndexError):
                    continue

        # 3. üîç [SEMANTIC HINTING] ‡∏Å‡∏£‡∏ì‡∏µ L1 ‡∏´‡∏£‡∏∑‡∏≠‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÉ‡∏ô Map
        if not priority_chunks and level == 1:
            rule_config = getattr(self, 'contextual_rules_map', {}).get(sub_id, {}).get(str(level), {})
            hints = rule_config.get("plan_keywords", [])[:2]
            if hints and vectorstore_manager:
                self.logger.info(f"üîé L1 Discovery: Searching using hints: {hints}")
                try:
                    discovery_result = vectorstore_manager.quick_search(
                        query=f"{sub_id} {' '.join(hints)}",
                        top_k=5
                    )
                    for chunk in discovery_result:
                        chunk["rerank_score"] = 0.85 # ‡∏ö‡∏π‡∏™‡∏ï‡πå‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏≤‡∏Å Keyword Rule
                        priority_chunks.append(chunk)
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Quick search failed: {e}")

        if not priority_chunks:
            return [], []

        # 4. üíß [ROBUST HYDRATION] ‡πÄ‡∏ï‡∏¥‡∏°‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ Full Text ‡∏à‡∏≤‡∏Å Vector DB
        try:
            priority_chunks = self._robust_hydrate_documents_for_priority_chunks(
                chunks_to_hydrate=priority_chunks,
                vsm=vectorstore_manager
            )
        except Exception as e:
            self.logger.error(f"‚ùå Hydration failed in priority module: {e}")

        # 5. üéØ [ID SYNC] ‡∏™‡∏Å‡∏±‡∏î UUID ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ Filter ‡∏Ç‡∏≠‡∏á Main Retriever
        seen_ids = set()
        for chunk in priority_chunks:
            sid = chunk.get("stable_doc_uuid") or chunk.get("doc_id")
            if sid and isinstance(sid, str):
                if sid not in seen_ids and len(sid) >= 32:
                    mapped_stable_ids.append(sid)
                    seen_ids.add(sid)

        self.logger.info(f"‚úÖ Continuity Ready: {len(priority_chunks)} priority chunks | Sub:{sub_id} L{level}")
        return mapped_stable_ids, priority_chunks

    def _save_level_evidences_and_calculate_strength(
        self,
        level_temp_map: List[Dict[str, Any]],
        sub_id: str,
        level: int,
        llm_result: Dict[str, Any],
        highest_rerank_score: float = 0.0
    ) -> float:
        """ 
        [IRONCLAD REVISE v2026.01.18] - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô (Strength)
        - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö Deduplication ‡∏î‡πâ‡∏ß‡∏¢ unique_key (Doc UUID + Chunk UUID)
        - ‡∏£‡∏∞‡∏ö‡∏ö Normalize PDCA Tag ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (Plan -> P, Detail -> D)
        - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Strength Score ‡πÇ‡∏î‡∏¢‡πÉ‡∏´‡πâ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å Rerank Score (60%) ‡πÅ‡∏•‡∏∞ PDCA Coverage (40%)
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Retagging ‡∏Å‡∏£‡∏ì‡∏µ Tag ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô (Semantic Fallback)
        """

        map_key = f"{sub_id}.L{level}"
        new_evidence_list: List[Dict[str, Any]] = []
        seen_ids = set()

        self.logger.info(f"üíæ [EVI SAVE] Starting persist for {map_key} | Incoming: {len(level_temp_map)}")

        # üö© Configuration
        STANDARD_TAGS = {"P", "D", "C", "A"}
        PASS_STATUS = "PASS" if llm_result.get("is_passed", False) else "FAIL"

        for chunk in level_temp_map:
            if not chunk: continue

            # 1. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Dictionary ‡πÅ‡∏•‡∏∞ LangChain Document)
            meta = chunk.get("metadata", {}) if isinstance(chunk, dict) else getattr(chunk, "metadata", {})
            text = chunk.get("text") or chunk.get("page_content") if isinstance(chunk, dict) else getattr(chunk, "page_content", "")
            
            if not text or not str(text).strip():
                continue

            # 2. Stable ID Generation (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Duplicate Chunks)
            # ‡πÉ‡∏ä‡πâ SHA-256 ‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏°‡∏µ ID ‡∏õ‡∏£‡∏∞‡∏à‡∏≥‡∏ï‡∏±‡∏ß ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô
            c_uuid = str(chunk.get("chunk_uuid") or meta.get("chunk_uuid") or hashlib.sha256(text.encode()).hexdigest()[:16])
            d_uuid = str(chunk.get("stable_doc_uuid") or meta.get("stable_doc_uuid") or "doc-unknown")
            unique_key = f"{d_uuid}:{c_uuid}"
            
            if unique_key in seen_ids:
                continue
            seen_ids.add(unique_key)

            # 3. ‚ú® PDCA TAG NORMALIZATION & GUARD
            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏ï‡πá‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡πÄ‡∏™‡∏£‡∏¥‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô P, D, C, A ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
            raw_tag = chunk.get("pdca_tag") or meta.get("pdca_tag") or "Other"
            
            if isinstance(raw_tag, str):
                u_tag = raw_tag.strip().upper()
                if u_tag.startswith("P") or "PLAN" in u_tag: pdca_tag = "P"
                elif u_tag.startswith("D") or "DETAIL" in u_tag or "SUPPORT" in u_tag: pdca_tag = "D"
                elif u_tag.startswith("C") or "CHECK" in u_tag: pdca_tag = "C"
                elif u_tag.startswith("A") or "ACT" in u_tag: pdca_tag = "A"
                else: pdca_tag = "Other"
            else:
                pdca_tag = "Other"

            # Semantic Fallback: ‡∏ñ‡πâ‡∏≤ Tag ‡∏¢‡∏±‡∏á‡πÄ‡∏õ‡πá‡∏ô Other ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ Logic ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
            if pdca_tag == "Other" and hasattr(self, '_get_semantic_tag'):
                pdca_tag = self._get_semantic_tag(text, sub_id, level)

            # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Evidence Entry)
            source_raw = meta.get("source") or meta.get("source_filename") or "Unknown"
            entry = {
                "sub_id": sub_id,
                "level": level,
                "relevance_score": float(chunk.get("rerank_score") or chunk.get("score") or 0.5),
                "doc_id": d_uuid,
                "stable_doc_uuid": d_uuid,
                "chunk_uuid": c_uuid,
                "source": source_raw,
                "source_filename": os.path.basename(str(source_raw)),
                "page": str(meta.get("page_label") or meta.get("page") or "N/A"),
                "pdca_tag": pdca_tag,
                "text_preview": str(text)[:300].replace("\n", " ") + "...",
                "status": PASS_STATUS,
                "timestamp": datetime.now().isoformat(),
            }
            new_evidence_list.append(entry)

        # 5. ‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≥‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á (Strength)
        if new_evidence_list:
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï Memory Map (‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏™‡∏∞‡∏™‡∏°)
            if not hasattr(self, 'evidence_map'): self.evidence_map = {}
            self.evidence_map.setdefault(map_key, []).extend(deepcopy(new_evidence_list))
            
            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏•‡∏á‡πÉ‡∏ô Map (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Level ‡∏≠‡∏∑‡πà‡∏ô‡πÜ ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ)
            if not hasattr(self, 'assessment_results_map'): self.assessment_results_map = {}
            self.assessment_results_map[map_key] = {
                "is_passed": llm_result.get("is_passed", False),
                "score": llm_result.get("score", 0.0),
                "strength": 0.0 # ‡∏à‡∏∞‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á
            }

            # üìä STRENGTH CALCULATION LOGIC
            # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏° (Coverage): ‡∏û‡∏ö‡∏Å‡∏µ‡πà‡∏´‡∏°‡∏ß‡∏î‡πÉ‡∏ô P, D, C, A
            found_tags = {ev['pdca_tag'] for ev in new_evidence_list if ev['pdca_tag'] in STANDARD_TAGS}
            coverage_score = len(found_tags) / 4.0  # (0.0 - 1.0)
            
            # 2. ‡∏ú‡∏™‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô: Rerank Max (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏à‡∏≤‡∏Å Vector) 60% + PDCA Coverage (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô) 40%
            final_strength = round((float(highest_rerank_score) * 0.6) + (coverage_score * 0.4), 2)
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏Å‡∏£‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏•‡∏á‡πÉ‡∏ô Result Map
            self.assessment_results_map[map_key]["strength"] = final_strength

            # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏ó‡∏≤‡∏á Log
            counts = {t: sum(1 for e in new_evidence_list if e['pdca_tag'] == t) for t in (list(STANDARD_TAGS) + ["Other"])}
            self.logger.info(
                f"‚úÖ [SAVED] {map_key}: {len(new_evidence_list)} items | "
                f"P:{counts['P']} D:{counts['D']} C:{counts['C']} A:{counts['A']} | "
                f"Final Strength: {final_strength:.2f}"
            )
            return final_strength
            
        return 0.0
    
    def get_actual_score(self, ev: Any) -> float:
        """
        [v2026.1 - ROBUST SCORING EXTRACTOR]
        ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô ‡πÑ‡∏°‡πà‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö Dict ‡∏´‡∏£‡∏∑‡∏≠ Object
        ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô 0.0 ‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ã‡πà‡∏≠‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô Metadata
        """
        if not ev:
            return 0.0

        # 1. ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡∏µ‡∏¢‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö (‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç)
        score_keys = ["rerank_score", "score", "relevance_score"]
        
        # 2. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö Top-level ‡∏Å‡πà‡∏≠‡∏ô
        for key in score_keys:
            # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á dict.get() ‡πÅ‡∏•‡∏∞ getattr() ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Document Object
            val = ev.get(key) if isinstance(ev, dict) else getattr(ev, key, None)
            if val is not None:
                try:
                    return float(val)
                except (ValueError, TypeError):
                    continue

        # 3. Fallback: ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏†‡∏≤‡∏¢‡πÉ‡∏ô Metadata
        meta = ev.get("metadata", {}) if isinstance(ev, dict) else getattr(ev, "metadata", {})
        if isinstance(meta, dict):
            for key in score_keys:
                val = meta.get(key)
                if val is not None:
                    try:
                        return float(val)
                    except (ValueError, TypeError):
                        continue

        return 0.0
    
    def _calculate_evidence_strength_cap(
        self,
        top_evidences: List[Any],
        level: int,
        highest_rerank_score: Optional[float] = None
    ) -> Dict[str, Any]:
        """
        [PROTECTED v2026.1.17 - REVISED]
        - ‡πÉ‡∏ä‡πâ get_actual_score ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô
        - ‡πÅ‡∏¢‡∏Å Logic ‡∏Å‡∏≤‡∏£‡∏´‡∏≤ '‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•' ‡πÉ‡∏´‡πâ‡∏â‡∏•‡∏≤‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
        - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö Logging ‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Audit
        """
        try:
            # ‚öôÔ∏è Load Configuration
            threshold = getattr(self, "RERANK_THRESHOLD", 0.35)
            cap_value = getattr(self, "MAX_EVI_STR_CAP", 5.0)
            
            # 1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ (Baseline)
            max_score_found = 0.0
            try:
                if highest_rerank_score is not None:
                    max_score_found = float(highest_rerank_score)
            except (ValueError, TypeError):
                max_score_found = 0.0

            max_score_source = "Adaptive_RAG_Loop"
            
            if not isinstance(top_evidences, list):
                top_evidences = []

            # 2. Iterate ‡∏´‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ
            for idx, doc in enumerate(top_evidences, 1):
                # ‡πÉ‡∏ä‡πâ‡∏ß‡∏¥‡∏ò‡∏µ‡∏î‡∏∂‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö
                current_score = self.get_actual_score(doc)

                # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ß‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤
                if current_score > max_score_found:
                    max_score_found = current_score
                    
                    # --- ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Robust ---
                    meta = doc.get("metadata", {}) if isinstance(doc, dict) else getattr(doc, "metadata", {})
                    if not isinstance(meta, dict): meta = {}
                    
                    max_score_source = (
                        meta.get("source_filename") or 
                        meta.get("file_name") or 
                        meta.get("source") or 
                        f"Doc_{idx}"
                    )

            # 3. Decision Logic (Gated Check)
            # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏¢‡∏±‡∏á‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ Threshold (0.35) -> ‡∏™‡∏±‡πà‡∏á Capped
            is_capped = max_score_found < threshold
            # ‡∏Ñ‡πà‡∏≤‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ Prompt: 5.0 (‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô) ‡∏´‡∏£‡∏∑‡∏≠ 10.0 (‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏ú‡πà‡∏≤‡∏ô)
            max_evi_str_for_prompt = float(cap_value) if is_capped else 10.0

            # üìä Internal Audit Log
            status_icon = "üö® [CAPPED]" if is_capped else "‚úÖ [FULL-STRENGTH]"
            self.logger.info(
                f"{status_icon} L{level} | Best Score: {max_score_found:.4f} "
                f"from: '{os.path.basename(str(max_score_source))}' | Threshold: {threshold}"
            )

            return {
                "is_capped": bool(is_capped),
                "max_evi_str_for_prompt": float(max_evi_str_for_prompt),
                "top_score": round(float(max_score_found), 4),
                "max_score_source": str(max_score_source),
                "threshold_used": threshold
            }

        except Exception as e:
            self.logger.error(f"‚ùå [CRITICAL-CAP-ERROR] {e}", exc_info=True)
            # ‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡πÑ‡∏ß‡πâ‡∏Å‡πà‡∏≠‡∏ô: ‡∏ñ‡πâ‡∏≤ Error ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á Cap ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
            return {
                "is_capped": False, 
                "max_evi_str_for_prompt": 10.0, 
                "top_score": 0.0, 
                "max_score_source": "Fallback-Error"
            }
       
    
    def _extract_strategic_gaps(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        [HELPER] ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏≤‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á (Gaps) ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏Å‡∏±‡∏ö‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢
        ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÄ‡∏™‡∏ô‡∏≠ Coaching Insight ‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°
        """
        gaps = []
        # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏∏‡∏ô‡πÅ‡∏£‡∏á‡∏Ç‡∏≠‡∏á Gap (‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ô‡πâ‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô)
        sorted_results = sorted(results, key=lambda x: x.get('score', 0.0))
        
        for res in sorted_results:
            sub_id = res.get('sub_id', 'Unknown')
            current_score = res.get('score', 0.0)
            passed = res.get('is_passed', False)
            
            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 0.8 ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Gap
            if not passed or current_score < 0.8:
                gap_info = {
                    "sub_id": sub_id,
                    "level": res.get('level'),
                    "current_score": current_score,
                    "impact": "High" if current_score < 0.5 else "Medium",
                    "reason": res.get('reason', '‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏µ‡πâ'),
                    "suggestion": res.get('coaching_insight', '‡∏Ñ‡∏ß‡∏£‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡∏ï‡∏≤‡∏° PDCA')
                }
                gaps.append(gap_info)
        
        # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ Gap ‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
        return gaps[:5]

    def calculate_audit_confidence(
        self,
        matched_chunks: List[Any],
        sub_id: str = "unknown",
        level: int = 1
    ) -> Dict[str, Any]:
        """
        [ULTIMATE AUDIT CONFIDENCE v2026.3.10 ‚Äì Real-Count Enabled]
        - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏•‡∏Ç (1) ‡πÇ‡∏î‡∏¢‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á Raw Tags ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏ô‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà (Frequency Counting)
        - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö PDCA ‡∏ú‡πà‡∏≤‡∏ô 3 ‡∏ä‡∏±‡πâ‡∏ô: Metadata -> Tagging -> Keyword Fallback
        - ‡∏õ‡∏£‡∏±‡∏ö Decision Matrix ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏î‡∏∏‡∏•‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á
        """
        if not matched_chunks:
            return {
                "level": "NONE", "reason": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö", "source_count": 0,
                "coverage_ratio": 0.0, "pdca_found": [], "valid_chunks_count": 0,
                "traceability_score": 0.0, "recency_bonus": 0.0
            }

        # 1. Quality Gate: ‡∏Ñ‡∏±‡∏î‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Chunk ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÄ‡∏ô‡πâ‡∏ô‡πÜ (Relevance >= 0.40)
        valid_chunks = [doc for doc in matched_chunks if self.get_actual_score(doc) >= 0.40]
        valid_count = len(valid_chunks)

        if valid_count == 0:
            return {
                "level": "LOW", "reason": "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û",
                "source_count": 0, "coverage_ratio": 0.0, "pdca_found": [], "valid_chunks_count": 0
            }

        # 2. Independence Check: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        unique_sources = set()
        for doc in valid_chunks:
            meta = getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else doc.get('metadata', {})
            src = next((meta.get(k) for k in ['source_filename', 'filename', 'source'] if meta.get(k)), None)
            if src:
                unique_sources.add(os.path.basename(str(src).strip()))
        
        independence_score = len(unique_sources)

        # 3. PDCA Detection (Revised: Multi-Tag Frequency Collection)
        all_detected_tags = [] # ‡πÄ‡∏Å‡πá‡∏ö List ‡∏Ç‡∏≠‡∏á Tag ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å Chunks (‡∏´‡πâ‡∏≤‡∏°‡∏ó‡∏≥ Unique)
        
        # ‡∏î‡∏∂‡∏á Keyword rules ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Fallback
        cum_rules = self.get_cumulative_rules(sub_id, level) if hasattr(self, 'get_cumulative_rules') else {}
        kw_map = {
            "P": [k.lower() for k in cum_rules.get('plan_keywords', [])],
            "D": [k.lower() for k in cum_rules.get('do_keywords', [])],
            "C": [k.lower() for k in cum_rules.get('check_keywords', [])],
            "A": [k.lower() for k in cum_rules.get('act_keywords', [])]
        }

        for doc in valid_chunks:
            meta = getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else doc.get('metadata', {})
            tag = (getattr(doc, 'pdca_tag', None) or meta.get('pdca_tag') or meta.get('tag') or "").strip().upper()
            
            chunk_detected_phases = []
            
            # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏≤‡∏Å Tag ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
            if tag in ["P", "D", "C", "A"]:
                chunk_detected_phases.append(tag)
            
            # ‡∏ä‡∏±‡πâ‡∏ô‡∏ó‡∏µ‡πà 2: Fallback Keyword Detection (‡∏ñ‡πâ‡∏≤ Tag ‡∏ß‡πà‡∏≤‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á)
            text = (doc.get('text') or doc.get('page_content') or '').lower()
            for phase, kws in kw_map.items():
                if any(k in text for k in kws):
                    if phase not in chunk_detected_phases: # 1 chunk ‡∏ô‡∏±‡∏ö 1 ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏ï‡πà‡∏≠ 1 ‡πÄ‡∏ü‡∏™
                        chunk_detected_phases.append(phase)
            
            # ‡∏ô‡∏≥ Tags ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô Chunk ‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏™‡∏∞‡∏™‡∏°‡∏£‡∏ß‡∏° (‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô Log)
            all_detected_tags.extend(chunk_detected_phases)

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Coverage Ratio (‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠ / 4)
        unique_found_phases = set(all_detected_tags)
        coverage_ratio = len(unique_found_phases) / 4.0

        # 4. Traceability & Recency Check
        traceable_count = 0
        recent_count = 0
        current_year = 2568 
        
        for doc in valid_chunks:
            meta = getattr(doc, 'metadata', {}) if hasattr(doc, 'metadata') else doc.get('metadata', {})
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤)
            if any(meta.get(k) for k in ['page', 'page_label']) and any(meta.get(k) for k in ['source', 'filename']):
                traceable_count += 1
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà (Bonus 2-3 ‡∏õ‡∏µ‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á)
            year_val = str(meta.get('year') or meta.get('doc_year') or "")
            if not year_val: # Fallback search in filename
                year_match = re.search(r'(25[67]\d)', str(meta.get('source', '')))
                if year_match: year_val = year_match.group(1)
            
            if year_val.isdigit() and int(year_val) >= current_year - 2:
                recent_count += 1

        trace_score = traceable_count / valid_count if valid_count > 0 else 0
        recency_score = recent_count / valid_count if valid_count > 0 else 0

        # 5. Decision Matrix: ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô (Confidence Level)
        if independence_score >= 8 and coverage_ratio >= 0.75:
            conf_level = "HIGH"
            reason = "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ PDCA ‡∏à‡∏≤‡∏Å‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô"
        elif independence_score >= 4 and coverage_ratio >= 0.50:
            conf_level = "MEDIUM"
            reason = "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏°‡∏¥‡∏ï‡∏¥‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"
        else:
            conf_level = "LOW"
            reason = "‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Ñ‡∏£‡∏ö‡∏ß‡∏á‡∏à‡∏£ PDCA ‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏û‡∏≠"

        # Penalty: ‡∏•‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏´‡∏≤‡∏Å‡∏£‡∏∞‡∏ö‡∏∏‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
        if trace_score < 0.6 and conf_level != "LOW":
            conf_level = "MEDIUM" if conf_level == "HIGH" else "LOW"
            reason += " (‡∏•‡∏î‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå)"

        return {
            "level": conf_level,
            "reason": reason,
            "source_count": independence_score,
            "coverage_ratio": round(coverage_ratio, 3),
            "traceability_score": round(trace_score, 3),
            "recency_bonus": round(recency_score, 3),
            "valid_chunks_count": valid_count,
            "pdca_found": all_detected_tags  # <--- ‡∏™‡πà‡∏á LIST ‡∏î‡∏¥‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏î‡πâ
        }

    def _get_level_constraint_prompt(self, sub_id: str, level: int, req_phases: list = None, spec_rule: str = None) -> str:
        """
        [ADAPTIVE AUDIT GUIDELINE v2026.1.19 - Concise & Stronger]
        - ‡πÄ‡∏ô‡πâ‡∏ô PDCA ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô + Substance over Form
        - ‡πÉ‡∏ä‡πâ fallback ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ req_phases
        - ‡∏™‡∏±‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LLM
        """
        required_phases = req_phases or self.get_rule_content(sub_id, level, "require_phase") or []
        specific_rule = spec_rule or self.get_rule_content(sub_id, level, "specific_contextual_rule") or ""

        phase_map = {
            "P": "Plan - ‡∏ß‡∏≤‡∏á‡πÅ‡∏ú‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢",
            "D": "Do - ‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡πÅ‡∏•‡∏∞‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏à‡∏£‡∏¥‡∏á",
            "C": "Check - ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ß‡∏±‡∏î‡∏ú‡∏•",
            "A": "Act - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‡∏û‡∏±‡∏í‡∏ô‡∏≤ ‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö"
        }
        req_str = ", ".join(phase_map.get(p, p) for p in required_phases) if required_phases else "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"

        lines = [
            f"\n### ‡πÅ‡∏ô‡∏ß‡∏ó‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô {sub_id} Level {level} ###",
            f"‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢‡∏´‡∏•‡∏±‡∏Å: {MATURITY_LEVEL_GOALS.get(level, '‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°')}",
            f"‡∏°‡∏¥‡∏ï‡∏¥ PDCA ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏£‡∏ö: {req_str}",
            f"‡∏Å‡∏é‡πÄ‡∏â‡∏û‡∏≤‡∏∞: {specific_rule}" if specific_rule else "",
            "\n‡∏Å‡∏é‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç (‡∏ï‡πâ‡∏≠‡∏á‡∏¢‡∏∂‡∏î‡∏ñ‡∏∑‡∏≠):",
            "- Substance over Form: ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á",
            "- Positive First: ‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏∂‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á",
            "- Coaching Mindset: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡∏≤‡∏î‡∏≠‡∏∞‡πÑ‡∏£ + ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á",
            "- Continuity: ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡∏ô ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏)"
        ]

        return "\n".join(filter(None, lines))

    def _calculate_weighted_score(
        self, 
        highest_full_level: int, 
        weight: float, 
        level_details: Dict[str, Any] = None
    ) -> float:
        """
        [FIXED & ROBUST] ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏£‡∏î‡πâ‡∏ß‡∏¢‡∏®‡∏π‡∏ô‡∏¢‡πå‡πÅ‡∏•‡∏∞‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
        """
        # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ MAX_LEVEL ‡∏à‡∏≤‡∏Å config ‡∏´‡∏£‡∏∑‡∏≠‡πÉ‡∏ä‡πâ Default ‡πÄ‡∏õ‡πá‡∏ô 5
        max_lv = getattr(self.config, 'max_level', 5) 
        if max_lv <= 0: max_lv = 5 
        
        # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô weight ‡πÄ‡∏õ‡πá‡∏ô None ‡∏´‡∏£‡∏∑‡∏≠ 0
        safe_weight = float(weight) if weight else 4.0

        # 1. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Base Level
        base_level = float(max(0, min(highest_full_level, max_lv)))
        
        # 2. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Partial Score (‡πÇ‡∏´‡∏°‡∏î‡∏™‡∏∞‡∏™‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å Level ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏≠‡∏¢‡∏π‡πà)
        partial_contribution = 0.0
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å global_vars ‡∏´‡∏£‡∏∑‡∏≠ config
        mode = getattr(self, 'scoring_mode', 'PARTIAL_PDCA') 

        if mode == 'PARTIAL_PDCA' and level_details:
            next_lv_idx = int(base_level + 1)
            if next_lv_idx <= max_lv:
                next_level_str = str(next_lv_idx)
                lv_data = level_details.get(next_level_str, {})
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö pdca_breakdown
                pdca = lv_data.get('pdca_breakdown')
                if isinstance(pdca, dict) and pdca:
                    pdca_values = [float(v) for v in pdca.values() if v is not None]
                    if pdca_values:
                        # (P+D+C+A)/4 -> ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô 1.0 ‡∏£‡∏∞‡∏î‡∏±‡∏ö
                        partial_contribution = sum(pdca_values) / len(pdca_values)
                        self.logger.debug(f"‚ûï [PARTIAL] L{next_level_str} adds {partial_contribution:.2f}")

        # 3. ‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô Maturity (Effective Level)
        effective_level = base_level + partial_contribution
        
        # 4. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Ratio (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ / ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÄ‡∏ï‡πá‡∏°)
        base_ratio = effective_level / max_lv
        
        # 5. ‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å
        scaled_score = base_ratio * safe_weight
        
        # Boost Logic (‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
        if mode == 'STEP_LADDER' and base_level >= max_lv - 1:
            scaled_score = min(scaled_score * 1.1, safe_weight)
        
        final_score = round(scaled_score, 4)
        
        self.logger.info(f"üìä [WEIGHT CALC] Mode: {mode} | Eff: {effective_level:.2f}/{max_lv} | Score: {final_score}/{safe_weight}")
        
        return final_score
    
    def _calculate_overall_stats(self, target_sub_id: str):
        """
        [FULL REVISE v2026.1.23] ‚Äî Flexible Maturity + Weighted Integrity + Force-Max Option
        - ‡πÉ‡∏ä‡πâ min_maturity ‡πÄ‡∏õ‡πá‡∏ô default label (‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô bottleneck ‡∏à‡∏£‡∏¥‡∏á)
        - ‡∏°‡∏µ option ‡πÉ‡∏ä‡πâ max ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass ‡∏´‡∏£‡∏∑‡∏≠ L3+ ‡∏ú‡πà‡∏≤‡∏ô (‡∏õ‡∏¥‡∏î cap)
        - ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì avg_score ‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏à‡∏£‡∏¥‡∏á (‡∏´‡∏≤‡∏£ total_weight)
        - Robust fallback ‡∏ó‡∏∏‡∏Å‡∏à‡∏∏‡∏î + Log ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô + analytics ‡πÄ‡∏û‡∏¥‡πà‡∏° force-pass details
        """
        results = self.final_subcriteria_results
        if not results:
            self.logger.warning("‚ö†Ô∏è [STATS] No results found. Setting default zeros.")
            self.total_stats = {
                "overall_max_level": 0,
                "overall_min_level": 0,
                "overall_level_label": "N/A",
                "overall_avg_score": 0.0,
                "total_weighted_score": 0.0,
                "total_weight": 0.0,
                "force_pass_count": 0,
                "use_max_override": False,
                "analytics": {"sub_details": []}
            }
            return

        passed_levels = []
        sub_details = []
        total_weighted_sum = 0.0
        total_weight = 0.0
        force_pass_count = 0
        use_max_override = False

        for r in results:
            sub_id = r.get('sub_id', 'Unknown')
            
            # 1. Flexible Level Details Access
            details_map = r.get('level_details', {})
            if not details_map and '0' in r:
                details_map = r.get('0', {}).get('level_details', {})

            # 2. Step-Ladder Maturity Scan
            current_maturity_lvl = 0
            for l_idx in range(1, 6):
                lv_data = details_map.get(str(l_idx), {})
                is_passed = lv_data.get('is_passed', False)
                is_force = lv_data.get('is_force_pass', False)
                
                if is_passed or is_force:
                    current_maturity_lvl = l_idx
                    if is_force:
                        force_pass_count += 1
                        use_max_override = True  # Trigger max override ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass
                else:
                    break

            # 3. Weighted Score
            weight = float(r.get('weight', 4.0))
            total_weight += weight
            
            if hasattr(self, '_calculate_weighted_score'):
                sub_score = self._calculate_weighted_score(
                    highest_full_level=current_maturity_lvl,
                    weight=weight,
                    level_details=details_map
                )
            else:
                sub_score = float(current_maturity_lvl) * (weight / 5.0 if weight > 0 else 0)

            total_weighted_sum += sub_score

            # Update back to result
            r['highest_full_level'] = current_maturity_lvl
            r['weighted_score'] = round(sub_score, 2)
            r['is_passed'] = (current_maturity_lvl >= 1)

            passed_levels.append(current_maturity_lvl)
            
            sub_details.append({
                "sub_id": sub_id,
                "maturity": current_maturity_lvl,
                "score": round(sub_score, 2),
                "weight": weight,
                "is_force_pass": any(lv_data.get('is_force_pass', False) for lv_data in details_map.values())
            })

        # 4. Final Aggregation
        num_subs = len(results)
        avg_score = total_weighted_sum / total_weight if total_weight > 0 else 0.0
        
        overall_min_maturity = min(passed_levels) if passed_levels else 0
        overall_max_maturity = max(passed_levels) if passed_levels else 0

        # Decide label: min default, max ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass (‡∏ä‡πà‡∏ß‡∏¢ push overall ‡πÑ‡∏õ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô)
        final_label_level = overall_min_maturity
        if use_max_override or force_pass_count > 0:
            final_label_level = overall_max_maturity
            self.logger.info(f"[STATS OVERRIDE] Using MAX level L{final_label_level} due to force-pass/appeal")

        self.total_stats = {
            "overall_max_level": int(overall_max_maturity),
            "overall_min_level": int(overall_min_maturity),
            "overall_level_label": f"L{int(final_label_level)}",
            "overall_avg_score": round(avg_score, 2),
            "total_weighted_score": round(total_weighted_sum, 2),
            "total_weight": round(total_weight, 2),
            "force_pass_count": force_pass_count,
            "use_max_override": use_max_override,
            
            "total_sub_assessed": num_subs,
            "analytics": {
                "sub_details": sub_details,
                "passed_levels_map": passed_levels,
                "assessed_at": datetime.now().isoformat()
            }
        }

        self.logger.info(
            f"‚úÖ [STATS SUCCESS] Overall: {self.total_stats['overall_level_label']} | "
            f"Avg Score: {self.total_stats['overall_avg_score']} | "
            f"Max/Min: L{overall_max_maturity}/L{overall_min_maturity} | "
            f"Force-Pass Subs: {force_pass_count} | Override: {use_max_override}"
        )

    def _export_results(self, results_data: Any, sub_criteria_id: str, **kwargs) -> str:
        """
        [ULTIMATE EXPORTER v2026.EXPORT.4 - FINAL SYNC]
        - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏≤‡∏Å _calculate_weighted_score ‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á (No re-calc)
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Export ‡∏ó‡∏±‡πâ‡∏á‡∏£‡∏≤‡∏¢ Sub ‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°‡∏ó‡∏±‡πâ‡∏á Enabler
        - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Evidence mapping ‡∏•‡πà‡∏°‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• String ‡∏´‡∏£‡∏∑‡∏≠ List ‡∏ß‡πà‡∏≤‡∏á
        """
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            record_id = kwargs.get("record_id", getattr(self, "current_record_id", f"auto_{timestamp}"))
            tenant = getattr(self.config, 'tenant', 'unknown')
            year = getattr(self.config, 'year', 'unknown')
            enabler = getattr(self, 'enabler', 'unknown').upper()

            # 1. üß© Data Consolidation (‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤)
            if results_data is None:
                results_data = self.final_subcriteria_results if hasattr(self, 'final_subcriteria_results') else []
            
            if isinstance(results_data, dict):
                results_data = [results_data]
            
            if not results_data:
                self.logger.warning(f"‚ö†Ô∏è [EXPORT] No data to write for {sub_criteria_id}")
                return ""

            # 2. üìä Summary Calculation (Sync ‡∏Å‡∏±‡∏ö‡∏ï‡∏±‡∏ß‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏´‡∏•‡∏±‡∏Å)
            valid_results = [r for r in results_data if isinstance(r, dict)]
            
            # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å total_stats (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å‡∏Å‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
            highest_lvl = max([int(r.get('highest_full_level', 0)) for r in valid_results]) if valid_results else 0
            total_weighted = sum([float(r.get('weighted_score', 0.0)) for r in valid_results])

            # 3. üõ°Ô∏è Evidence Mapping (Robust Version)
            master_map = self.evidence_map if hasattr(self, 'evidence_map') else (self._load_evidence_map() or {})
            processed_evidence = {}
            
            for k, v_list in master_map.items():
                if not v_list or not isinstance(v_list, list): 
                    continue
                
                # ‡∏î‡∏∂‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå‡πÉ‡∏ô Report
                sorted_ev = sorted(v_list, key=lambda x: x.get('relevance_score', 0) if isinstance(x, dict) else 0, reverse=True)
                top_ev = sorted_ev[0] if sorted_ev and isinstance(sorted_ev[0], dict) else None
                
                if top_ev:
                    processed_evidence[str(k)] = {
                        "file": top_ev.get("source") or top_ev.get("file_name") or "Source_Not_Found",
                        "page": top_ev.get("page", "N/A"),
                        "tag": top_ev.get("pdca_tag", "Other").upper(),
                        "confidence": round(float(top_ev.get("relevance_score", 0)), 4)
                    }

            # 4. üìù Construct Final Payload (‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô SE-AM JSON Report)
            payload = {
                "metadata": {
                    "record_id": record_id,
                    "tenant": tenant,
                    "year": year,
                    "enabler": enabler,
                    "engine_version": "SEAM-ENGINE-v2026.3.1",
                    "exported_at": datetime.now().isoformat()
                },
                "result_summary": {
                    "maturity_level": f"L{highest_lvl}",
                    "is_passed": highest_lvl >= 1,
                    "total_weighted_score": round(total_weighted, 4),
                    "evidence_count": len(processed_evidence)
                },
                "sub_criteria_details": valid_results,
                "evidence_audit_trail": processed_evidence,
                "improvement_roadmap": getattr(self, 'last_action_plan', {})
            }

            # 5. üíæ Smart Path Persistence
            filename = f"REPORT_{enabler}_{sub_criteria_id}_{timestamp}.json"
            try:
                # ‡∏•‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Path ‡∏Ç‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                export_path = get_assessment_export_file_path(
                    tenant=tenant, year=year, enabler=enabler.lower(),
                    suffix=f"{sub_criteria_id}_{timestamp}", ext="json"
                )
            except:
                # Fallback path
                out_dir = f"exports/{tenant}/{year}/{enabler.lower()}"
                os.makedirs(out_dir, exist_ok=True)
                export_path = f"{out_dir}/{filename}"

            with open(export_path, 'w', encoding='utf-8') as f:
                json.dump(payload, f, indent=2, ensure_ascii=False)

            self.logger.info(f"üíæ [EXPORT SUCCESS] Report generated at: {export_path}")
            return export_path

        except Exception as e:
            self.logger.error(f"‚ùå [EXPORT FAILED] Critical error during report generation: {str(e)}", exc_info=True)
            return ""
    
    def _robust_hydrate_documents_for_priority_chunks(
        self,
        chunks_to_hydrate: List[Dict],
        vsm: Optional['VectorStoreManager'],
        current_sub_id: Optional[str] = None,
        level: Optional[int] = None
    ) -> List[Dict]:
        """
        [ULTIMATE HYDRATION v2026.12]
        - ‡∏î‡∏∂‡∏á Full Text ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Priority Chunks ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ LLM ‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô
        - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÑ‡∏õ‡πÉ‡∏ä‡πâ LLM-based Tagging ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö (L1-L5)
        - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö Boost Score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÉ‡∏´‡πâ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏Å‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ô‡∏µ‡πâ
        """
        from collections import defaultdict
        
        active_sub_id = current_sub_id or getattr(self, 'sub_id', 'unknown')
        if not chunks_to_hydrate:
            self.logger.debug(f"‚ÑπÔ∏è [HYDRATION] No chunks to hydrate for {active_sub_id} L{level}")
            return []

        # 1. üè∑Ô∏è Helper: ‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏î‡πâ‡∏ß‡∏¢ LLM (‡πÉ‡∏ä‡πâ‡∏ï‡∏±‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö Core Assessment)
        def _safe_classify(text: str, filename: str = "") -> str:
            try:
                # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ LLM Tagging ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡πÑ‡∏ß‡πâ (Self-contained within class)
                tag = self._get_semantic_tag(
                    text=text, 
                    sub_id=active_sub_id, 
                    level=level or 1,
                    filename=filename
                )
                return tag if tag in {"P", "D", "C", "A"} else "Other"
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è PDCA classify failed in hydration: {e}")
                return "Other"

        # 2. üìè Helper: ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ Scoring Boost
        def _standardize_chunk(chunk: Dict, score: float):
            chunk.setdefault("is_baseline", True)
            text = chunk.get("text", "").strip()
            meta = chunk.get("metadata", {})
            
            if text:
                fname = os.path.basename(str(meta.get("source") or meta.get("file_name") or "Unknown"))
                # ‚ú® ‡πÉ‡∏ä‡πâ LLM Tagging ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÄ‡∏•‡∏¢
                chunk["pdca_tag"] = _safe_classify(text, filename=fname)
                
                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö Boost ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÉ‡∏´‡πâ‡∏™‡∏π‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏ä‡∏ô‡∏∞ Chunk ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö
                chunk["rerank_score"] = max(float(chunk.get("rerank_score", 0.0)), score)
                chunk["score"] = max(float(chunk.get("score", 0.0)), score)
            return chunk

        # 3. üîë ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏° IDs
        stable_ids = {
            sid for c in chunks_to_hydrate
            if (sid := (c.get("stable_doc_uuid") or c.get("doc_id") or c.get("chunk_uuid")))
        }

        if not stable_ids or not vsm:
            boosted = [_standardize_chunk(c.copy(), 0.9) for c in chunks_to_hydrate]
            return self._guarantee_text_key(boosted)

        # 4. üõ∞Ô∏è Fetch Full Documents (Hydration Process)
        stable_id_map = defaultdict(list)
        try:
            retrieved_docs = vsm.get_documents_by_id(
                list(stable_ids), doc_type=self.doc_type, enabler=self.config.enabler
            )
            for doc in retrieved_docs:
                sid = doc.metadata.get("stable_doc_uuid") or doc.metadata.get("doc_id")
                if sid:
                    stable_id_map[sid].append({"text": doc.page_content, "metadata": doc.metadata})
        except Exception as e:
            self.logger.error(f"‚ùå [HYDRATION] VSM Fetch Error: {e}")
            return self._guarantee_text_key([_standardize_chunk(c.copy(), 0.9) for c in chunks_to_hydrate])

        # 5. üíß Hydrate & Dedup
        hydrated_priority_docs = []
        seen_signatures = set()
        SAFE_META_KEYS = {"source", "file_name", "page", "page_label", "page_number"}

        for chunk in chunks_to_hydrate:
            new_chunk = chunk.copy()
            sid = new_chunk.get("stable_doc_uuid") or new_chunk.get("doc_id")

            hydrated = False
            if sid and sid in stable_id_map:
                # ‡∏î‡∏∂‡∏á Full Text ‡∏°‡∏≤‡∏ó‡∏±‡∏ö Snippet ‡∏™‡∏±‡πâ‡∏ô‡πÜ
                best_match = stable_id_map[sid][0]
                new_chunk["text"] = best_match["text"]
                meta = best_match.get("metadata", {})
                new_chunk.update({k: v for k, v in meta.items() if k in SAFE_META_KEYS})
                hydrated = True

            # ‡∏ó‡∏≥ Standardize + Tagging (Score 1.0 ‡∏ñ‡πâ‡∏≤‡∏î‡∏∂‡∏á‡πÄ‡∏ï‡πá‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à / 0.85 ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°)
            new_chunk = _standardize_chunk(new_chunk, score=1.0 if hydrated else 0.85)

            # Check Signature ‡∏Å‡∏±‡∏ô‡∏ã‡πâ‡∏≥
            sig = (sid, new_chunk.get("chunk_uuid"), new_chunk.get("text", "")[:100])
            if sig not in seen_signatures:
                seen_signatures.add(sig)
                hydrated_priority_docs.append(new_chunk)

        self.logger.info(f"‚úÖ [HYDRATION] Complete: {len(hydrated_priority_docs)} priority chunks ready.")
        return self._guarantee_text_key(hydrated_priority_docs)

    def _guarantee_text_key(
        self,
        chunks: List[Dict],
        total_count: int = 0,
        restored_count: int = 0
    ) -> List[Dict]:
        """
        Guarantee 'text' key exists in every chunk
        """
        final_chunks = []

        for chunk in chunks:
            if "text" not in chunk or not isinstance(chunk["text"], str):
                chunk["text"] = ""
                cid = str(chunk.get("chunk_uuid", "N/A"))
                self.logger.debug(f"Guaranteed 'text' key for chunk (ID: {cid[:8]})")
            final_chunks.append(chunk)

        if total_count > 0:
            baseline_count = sum(1 for c in final_chunks if c.get("is_baseline"))
            self.logger.info(
                f"HYDRATION FINAL: Restored {restored_count}/{total_count} "
                f"(Baseline={baseline_count}, Total final={len(final_chunks)})"
            )

        return final_chunks


    def _normalize_meta(self, c: Dict) -> Tuple[str, str]:
        """
        [REVISED] ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏£‡∏∞‡∏ö‡∏ö Priority Fallback
        - ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤ 0 ‡∏´‡∏≤‡∏¢ (Index-based)
        - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏à‡∏≤‡∏Å Ingest ‡πÉ‡∏´‡∏°‡πà ‡πÅ‡∏•‡∏∞ Reranker Output
        - ‡πÄ‡∏ô‡πâ‡∏ô page_label ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ö‡∏ô UI
        """
        if not isinstance(c, dict):
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÄ‡∏õ‡πá‡∏ô LangChain Document ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á metadata ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤
            if hasattr(c, "metadata"):
                meta = c.metadata
                # ‡∏à‡∏≥‡∏•‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á dict ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÇ‡∏Ñ‡πâ‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
                c = {"metadata": meta}
            else:
                return "Unknown Source", "N/A"

        # ‡∏î‡∏∂‡∏á metadata ‡∏°‡∏≤‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ß‡πâ (‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏Å‡∏£‡∏ì‡∏µ None ‡∏´‡∏£‡∏∑‡∏≠ Dict)
        meta = c.get("metadata") or {}

        # 1. üîç ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (Source Name Priority)
        source_priority = [
            c.get("source_filename"),
            meta.get("source_filename"),
            c.get("filename"),
            meta.get("source"),
            meta.get("file_name"),
            c.get("id") 
        ]
        
        source = "Unknown"
        for s in source_priority:
            if s and str(s).strip():
                source = str(s).strip()
                break

        # 2. üîç ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡πÄ‡∏•‡∏Ç‡∏´‡∏ô‡πâ‡∏≤ (Page Label Priority)
        page_keys = ["page_label", "page", "page_number"]
        found_page = None
        for key in page_keys:
            val_root = c.get(key)
            if val_root is not None and str(val_root).strip().lower() != "n/a":
                found_page = val_root
                break
            val_meta = meta.get(key)
            if val_meta is not None and str(val_meta).strip().lower() != "n/a":
                found_page = val_meta
                break

        # 3. ‚ú® Final Cleaning & UI Formatting
        clean_source = os.path.basename(source) if "/" in source or "\\" in source else source
        if found_page is not None:
            page_str = str(found_page).strip()
            clean_page = page_str if page_str.lower() != "n/a" else "N/A"
        else:
            clean_page = "N/A"

        return clean_source, clean_page
    

    def _get_heuristic_pdca_tag(self, text: str, level: int) -> Optional[str]:
        t = text.lower()
        
        # Do-specific ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1 (‡πÄ‡∏ô‡πâ‡∏ô‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏ó‡∏≥‡∏à‡∏£‡∏¥‡∏á)
        do_keywords = [
            "‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£", "‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥", "‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°", "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", "‡∏≠‡∏ö‡∏£‡∏°", "‡∏à‡∏±‡∏î‡∏ó‡∏≥", "‡∏•‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà", 
            "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•", "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢", "‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£", "‡∏°‡∏∏‡πà‡∏á‡∏°‡∏±‡πà‡∏ô", "‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á", "‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô", 
            "‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô", "‡∏ô‡∏≥‡∏£‡πà‡∏≠‡∏á", "‡∏•‡∏á‡∏°‡∏∑‡∏≠‡∏ó‡∏≥", "‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ"
        ]
        if level <= 2 and any(k in t for k in do_keywords):
            return "D"

        # Check keywords (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å log)
        check_keywords = [
            "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•", "‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", "kpi", "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå", "‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•", 
            "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥", "‡∏™‡∏≥‡∏£‡∏ß‡∏à", "‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö", "‡∏ß‡∏±‡∏î‡∏ú‡∏•"
        ]
        if any(k in t for k in check_keywords):
            return "C"

        # Plan & Act (‡∏Ñ‡∏á‡πÄ‡∏î‡∏¥‡∏° ‡πÅ‡∏ï‡πà‡∏•‡∏î priority)
        if any(k in t for k in ["‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "‡πÅ‡∏ú‡∏ô", "‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏°‡∏ï‡∏¥", "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á", "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢", "‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏£‡∏°‡∏ì‡πå"]):
            return "P"
        if any(k in t for k in ["‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á", "‡∏û‡∏±‡∏í‡∏ô‡∏≤", "‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", "‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "lesson learned", "‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î", "‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°"]):
            return "A"

        return None
    
    def _get_pdca_blocks_from_evidences(
        self, 
        evidences: List[Dict[str, Any]], 
        baseline_evidences: Any, 
        level: int, 
        sub_id: str, 
        contextual_rules_map: Dict[str, Any], 
        record_id: str = None
    ) -> Dict[str, str]:
        """
        [ULTIMATE FIXED v2026.1.19 - Anti-Zero PDCA Full Coverage]
        ‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏´‡∏°‡∏ß‡∏î‡∏´‡∏°‡∏π‡πà‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö SE-AM
        """
        pdca_groups = defaultdict(list)
        seen_texts = set()
        total_chunks = len(evidences or [])
        self.logger.info(f"üè∑Ô∏è [TAGGING START] Processing {total_chunks} chunks for {sub_id} L{level}")

        for idx, chunk in enumerate(evidences or [], start=1):
            txt = chunk.get("text", "").strip().lower()
            if not txt or txt in seen_texts: continue
            seen_texts.add(txt)

            # 1. Metadata Recovery (‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏´‡∏ô‡πâ‡∏≤)
            meta = chunk.get("metadata", {})
            filename = chunk.get("source_filename") or meta.get("source_filename") or "Unknown_File"
            page = meta.get("page_label") or meta.get("page") or "N/A"
            display_name = f"{filename} (P.{page})"

            # 2. Heuristic & Keyword Boost (‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ + ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©)
            heuristic_tag = self._get_heuristic_pdca_tag(txt, level)
            final_tag = heuristic_tag
            tag_source = "Heuristic"

            if not final_tag:
                p_kws = ['‡πÅ‡∏ú‡∏ô', '‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢', '‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', '‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢', 'master plan', 'policy', '‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£']
                d_kws = ['‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£', '‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°', '‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥', '‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°', '‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å', 'implement', '‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô']
                c_kws = ['‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°', '‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ú‡∏•', 'audit', 'kpi', '‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î', 'monitor', '‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•']
                a_kws = ['‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á', '‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô', 'lesson learned', '‡∏û‡∏±‡∏í‡∏ô‡∏≤', '‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°', 'improve', 'review', '‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô']

                if any(kw in txt for kw in p_kws): final_tag, tag_source = "P", "Keyword-P"
                elif any(kw in txt for kw in d_kws): final_tag, tag_source = "D", "Keyword-D"
                elif any(kw in txt for kw in c_kws): final_tag, tag_source = "C", "Keyword-C"
                elif any(kw in txt for kw in a_kws): final_tag, tag_source = "A", "Keyword-A"

            # 3. AI Semantic Tagging (‡∏Å‡∏£‡∏ì‡∏µ Keyword ‡πÑ‡∏°‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô)
            if not final_tag:
                try:
                    tag = self._get_semantic_tag(txt, sub_id, level, filename)
                    final_tag = tag if tag in {"P", "D", "C", "A"} else "Other"
                    tag_source = "AI"
                except:
                    final_tag, tag_source = "Other", "AI-Fail"

            # 4. Level-Based Fallback (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏®‡∏π‡∏ô‡∏¢‡πå)
            if final_tag == "Other":
                if level <= 2: final_tag = "P" if idx % 5 < 3 else "D"
                elif level == 3: final_tag = "C" if idx % 3 == 0 else "D"
                else: final_tag = "A" if idx % 3 == 0 else "C"
                tag_source = "Fallback-Level"

            chunk.update({"pdca_tag": final_tag, "tag_source": tag_source, "source_display": display_name})
            pdca_groups[final_tag].append(chunk)

        # 5. Build Final Blocks for AI
        blocks = {}
        for tag in ["P", "D", "C", "A", "Other"]:
            chunks = pdca_groups[tag][:5]
            if chunks:
                blocks[tag] = "\n\n".join([f"[{c['source_display']} | Tag: {c['tag_source']}]\n{c['text'][:400]}..." for c in chunks])
            else:
                blocks[tag] = f"[‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î {tag}]"

        blocks["sources"] = {tag: [c["source_display"] for c in pdca_groups[tag][:5]] for tag in ["P", "D", "C", "A"]}
        return blocks

    def _prepare_worker_tuple(self, sub_data: Dict, document_map: Optional[Dict]) -> Tuple:
        return (
            sub_data,                          # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏ì‡∏ë‡πå (1.1, 1.2...)
            self.config.enabler,               # KM / IT / ...
            self.config.target_level,          # ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ L5
            self.config.mock_mode,             # none/random
            self.evidence_map_path,            # ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô
            self.config.model_name,            # llama3.1:70b ‡∏´‡∏£‡∏∑‡∏≠ 8b
            self.config.temperature,           # 0.0
            getattr(self.config, 'min_retry_score', 0.65),
            getattr(self.config, 'max_retrieval_attempts', 3),
            document_map or self.document_map, # ‡πÅ‡∏ú‡∏ô‡∏ú‡∏±‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£
            getattr(self, 'ActionPlanActions', None),
            self.config.year,                  # 2567
            self.config.tenant                 # pea
        )
    
    
    def _normalize_evidence_metadata(self, evidence_list: List[Dict[str, Any]]):
        """
        [REVISED v2026] ‡∏õ‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏á Metadata ‡πÉ‡∏´‡πâ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞ Export
        - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏Ñ‡∏µ‡∏¢‡πå‡∏Å‡∏£‡∏∞‡∏à‡∏±‡∏î‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢ (Flattened vs Nested)
        - ‡∏õ‡∏£‡∏∞‡∏Å‡∏±‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡∏ä‡∏ô‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Type Safety)
        """
        for ev in evidence_list:
            if not isinstance(ev, dict):
                continue
                
            # 1. ‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á Metadata (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Langchain Doc ‡πÅ‡∏•‡∏∞ Dict)
            meta = ev.get("metadata", {})
            if not isinstance(meta, dict): meta = {}
            
            # 2. ‡∏õ‡∏£‡∏±‡∏ö Source (‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏•‡∏∂‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡∏Å‡πà‡∏≠‡∏ô)
            raw_source = (
                meta.get("source_filename") or 
                meta.get("file_name") or 
                ev.get("source") or 
                meta.get("source") or 
                "Unknown_File"
            )
            ev["source"] = os.path.basename(str(raw_source))
            ev["source_filename"] = ev["source"] # Sync ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏Ñ‡∏µ‡∏¢‡πå
            
            # 3. ‡∏õ‡∏£‡∏±‡∏ö Page (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏•‡∏Ç 0 ‡∏´‡∏£‡∏∑‡∏≠ None)
            raw_page = (
                meta.get("page_label") or 
                meta.get("page") or 
                meta.get("page_number") or 
                ev.get("page") or 
                "N/A"
            )
            ev["page"] = str(raw_page)
            
            # 4. ‡∏õ‡∏£‡∏±‡∏ö Relevance Score ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
            ev["relevance_score"] = self.get_actual_score(ev)
            
            # 5. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ ID ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Audit Trail
            if not ev.get("stable_doc_uuid"):
                ev["stable_doc_uuid"] = (
                    meta.get("stable_doc_uuid") or 
                    ev.get("doc_id") or 
                    meta.get("doc_id") or 
                    f"id_{uuid.uuid4().hex[:8]}"
                )
            
            # 6. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö PDCA Tag (‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Other)
            if not ev.get("pdca_tag"):
                ev["pdca_tag"] = meta.get("pdca_tag") or "Other"

        return evidence_list
    
    # ------------------------------------------------------------------------------------------
    # [FIXED] üß© Persistence Helper: Update Internal Evidence
    # ------------------------------------------------------------------------------------------
    def _update_internal_evidence_map(self, merged_evidence: Dict[str, Any]):
        """
        ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡πÇ‡∏¢‡∏á‡∏Ç‡∏≠‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà Merge ‡πÅ‡∏•‡πâ‡∏ß
        """
        if not hasattr(self, 'evidence_map'):
            self.evidence_map = {}
            
        self.logger.info("üíæ Syncing merged evidence to internal storage...")
        
        if isinstance(merged_evidence, dict):
            for key, ev_list in merged_evidence.items():
                if not isinstance(ev_list, list): continue
                if key not in self.evidence_map:
                    self.evidence_map[key] = []
                
                # Deduplicate content ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏´‡∏¢‡∏±‡∏î‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏•‡∏∞‡∏•‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô
                existing_hashes = {hash(str(e.get('content'))[:100]) for e in self.evidence_map[key]}
                for ev in ev_list:
                    ev_hash = hash(str(ev.get('content'))[:100])
                    if ev_hash not in existing_hashes:
                        self.evidence_map[key].append(ev)
                        existing_hashes.add(ev_hash)
        
        self.logger.info(f"‚úÖ Evidence mapping persistence ready. Total groups: {len(self.evidence_map)}")

    # ------------------------------------------------------------------------------------------
    # [FULL REVISE v2026.3.2] üß© Merge Worker Results (The "Zero-Score" Antidote)
    # ------------------------------------------------------------------------------------------
    def _merge_worker_results(self, sub_result: Dict[str, Any], temp_map: Dict[str, List[Dict]]):
        """
        ‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å Worker ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏´‡∏•‡∏±‡∏Å ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Maturity Chain 
        ‡∏ó‡∏µ‡πà‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏´‡∏•‡∏∏‡∏î‡πÄ‡∏õ‡πá‡∏ô 0.0 ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ñ‡∏≤‡∏ß‡∏£
        """
        if not sub_result:
            return None

        # 1. üîç Identity & Metadata Setup
        sub_id = str(sub_result.get('sub_id', 'Unknown'))
        # ‡∏î‡∏∂‡∏á Level ‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á single ‡πÅ‡∏•‡∏∞ batch result)
        level_received = int(sub_result.get('level') or sub_result.get('highest_full_level', 0))
            
        # 2. üõ°Ô∏è Evidence Mapping Sync (‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô)
        if temp_map and isinstance(temp_map, dict):
            for level_key, evidence_list in temp_map.items():
                if level_key not in self.evidence_map:
                    self.evidence_map[level_key] = []
                
                def get_safe_id(e):
                    if isinstance(e, dict):
                        return str(e.get('chunk_uuid') or e.get('doc_id') or hash(e.get('content', '')))
                    return str(hash(str(e))) 

                existing_ids = {get_safe_id(e) for e in self.evidence_map[level_key] if e}
                
                for ev in evidence_list:
                    if ev in [None, "na", "n/a", ""]: continue
                    if get_safe_id(ev) not in existing_ids:
                        # Wrap ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏•‡∏∏‡∏î‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô string ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô dict ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
                        if not isinstance(ev, dict):
                            ev = {"content": str(ev), "source": "Unknown Stream", "page": "N/A"}
                        self.evidence_map[level_key].append(ev)

        # 3. üèóÔ∏è Manage Target Container (‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡πâ‡∏≠‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Ç‡∏≠‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏±‡πâ‡∏ô‡πÜ)
        if not hasattr(self, 'final_subcriteria_results'):
            self.final_subcriteria_results = []

        target = next((r for r in self.final_subcriteria_results if str(r.get('sub_id')) == sub_id), None)
        if not target:
            target = {
                "sub_id": sub_id,
                "sub_criteria_name": sub_result.get('sub_criteria_name') or f"Criteria {sub_id}",
                "weight": float(sub_result.get('weight', 4.0)),
                "level_details": {},
                "highest_full_level": 0,
                "weighted_score": 0.0,
                "is_passed": False,
                "audit_stop_reason": "Starting assessment..."
            }
            self.final_subcriteria_results.append(target)

        # 4. üß© Atomic Update (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏´‡∏•‡πà‡∏ô‡∏´‡∏≤‡∏¢)
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ sub_result ‡∏ó‡∏µ‡πà‡∏°‡∏≤ ‡∏°‡∏µ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á level_details ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡πâ‡∏≠‡∏ô Data ‡∏Ç‡∏≠‡∏á Level ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        if 'level_details' in sub_result and isinstance(sub_result['level_details'], dict):
            target['level_details'].update(sub_result['level_details'])
        else:
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô Level ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏î‡∏•‡∏á Map ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ level_received ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå
            target['level_details'][str(level_received)] = sub_result

        # 5. ‚öñÔ∏è Step-Ladder Maturity Calculation (‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Score 0)
        current_highest = 0
        stop_reason = ""
        
        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡πÄ‡∏ä‡πá‡∏Ñ L1 -> L5 ‡∏ï‡∏≤‡∏°‡∏Å‡∏é SE-AM
        for l in range(1, 6):
            l_str = str(l)
            l_data = target['level_details'].get(l_str)
            
            # üîç [CRITICAL FIX] ‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏ö‡∏ö Multi-layered
            # ‡∏ö‡∏≤‡∏á‡∏ó‡∏µ LLM ‡∏•‡∏∑‡∏°‡∏™‡πà‡∏á is_passed ‡πÅ‡∏ï‡πà‡∏™‡πà‡∏á score ‡∏°‡∏≤ > 0.6 ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏ú‡πà‡∏≤‡∏ô
            is_lv_passed = False
            if l_data and isinstance(l_data, dict):
                is_lv_passed = (
                    l_data.get('is_passed') is True or 
                    l_data.get('is_force_pass') is True or
                    float(l_data.get('score', 0)) >= 0.7  # ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ (Adjustable)
                )
            
            if is_lv_passed:
                current_highest = l
                # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡πâ‡∏≠‡∏ô data ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏∑‡πà‡∏ô‡∏£‡∏π‡πâ‡∏î‡πâ‡∏ß‡∏¢‡∏ß‡πà‡∏≤‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏ô‡∏µ‡πâ‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏ô‡πà‡πÜ
                l_data['is_passed'] = True
            else:
                if not l_data:
                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏¢‡∏±‡∏á‡∏°‡∏≤‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô Parallel)
                    stop_reason = f"Waiting for L{l} data..."
                else:
                    # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ï‡∏Å‡πÄ‡∏Å‡∏ì‡∏ë‡πå (Chain Broken)
                    reason_msg = l_data.get('reason', 'Evidence insufficient')
                    stop_reason = f"Broken at L{l}: {str(reason_msg)[:60]}"
                break

        # 6. üí∞ Final Score Integration
        target['highest_full_level'] = current_highest
        target['is_passed'] = (current_highest >= 1)
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ñ‡πà‡∏ß‡∏á‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô Scoring Engine)
        target['weighted_score'] = self._calculate_weighted_score(
            highest_full_level=current_highest,
            weight=target['weight'],
            level_details=target['level_details']
        )
        target['audit_stop_reason'] = stop_reason or "Target achieved"
        
        # üìä Log for Monitoring
        status_icon = "‚úÖ" if target['is_passed'] else "‚ùå"
        self.logger.info(
            f"{status_icon} [MERGE] {sub_id} | Final: L{current_highest} | Score: {target['weighted_score']:.2f} | Reason: {stop_reason}"
        )

        return target

    def enhance_query_for_statement(
        self,
        statement_text: str,
        sub_id: str,
        statement_id: str,
        level: int,
        focus_hint: str = "",
    ) -> List[str]:
        """
        [REVISED STRATEGIC v2026.2.20 ‚Äì Optimized Negative & PDCA Balance]
        - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç Negative Query: ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏à‡∏≤‡∏Å '-‡πÅ‡∏ú‡∏ô -‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢' ‡πÄ‡∏õ‡πá‡∏ô '-‡πÅ‡∏ú‡∏ô‡πÅ‡∏°‡πà‡∏ö‡∏ó -‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå' 
          ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏¢‡∏±‡∏á‡∏Ñ‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ '‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£' ‡∏´‡∏£‡∏∑‡∏≠ '‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á' ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤‡πÅ‡∏ú‡∏ô‡πÑ‡∏î‡πâ
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Å‡∏≤‡∏£‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏ü‡∏™ P/D: ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏µ‡∏¢‡πå‡πÄ‡∏ß‡∏¥‡∏£‡πå‡∏î '‡∏•‡∏á‡∏ô‡∏≤‡∏°', '‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°'
        - ‡∏£‡∏±‡∏Å‡∏©‡∏≤ Priority: query_synonyms > specific_contextual_rule > fallback PDCA
        - ‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏•‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á Query ‡∏î‡πâ‡∏ß‡∏¢ Post-process ‡πÅ‡∏•‡∏∞ Shuffle ‡πÄ‡∏î‡∏¥‡∏°
        """

        logger = logging.getLogger(__name__)

        # 1. Anchors
        enabler_id = getattr(self.config, 'enabler', 'Unknown').upper()
        tenant_name = getattr(self.config, 'tenant', 'Unknown').upper()
        id_anchor = f"{enabler_id} {sub_id}"

        # ‡∏î‡∏∂‡∏á required_phase (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‚Äì ‡πÉ‡∏ä‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á)
        require_phases = self.get_rule_content(sub_id, level, "require_phase") or []
        require_str = ", ".join(require_phases) if require_phases else "P,D"

        # 2. Keywords ‡∏à‡∏≤‡∏Å _enabler_defaults + required_phase
        raw_kws = []
        must_list = self.get_rule_content(sub_id, level, "must_include_keywords")
        if isinstance(must_list, list):
            raw_kws.extend(must_list)

        phase_keywords_map = {
            "P": "plan_keywords",
            "D": "do_keywords",
            "C": "check_keywords",
            "A": "act_keywords"
        }

        for phase in require_phases:
            kw_key = phase_keywords_map.get(phase)
            if kw_key:
                raw_kws.extend(self.get_rule_content(sub_id, level, kw_key) or [])

        if not require_phases:
            if level <= 3:
                raw_kws.extend(self.get_rule_content(sub_id, 1, "plan_keywords") or [])
                raw_kws.extend(self.get_rule_content(sub_id, 2, "do_keywords") or [])
            else:
                raw_kws.extend(self.get_rule_content(sub_id, 2, "do_keywords") or [])
                raw_kws.extend(self.get_rule_content(sub_id, 3, "check_keywords") or [])

        clean_kws = sorted(set(str(k).strip() for k in raw_kws if k))
        keywords_str = " ".join(clean_kws[:5])
        short_keywords = " ".join(clean_kws[:3])

        clean_stmt = statement_text.split("‡πÄ‡∏ä‡πà‡∏ô", 1)[0].strip()
        clean_stmt = re.sub(r'[^\w\s]', '', clean_stmt)[:70]

        queries: List[str] = []

        # 3. Queries ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô (‡∏õ‡∏£‡∏±‡∏ö Negative ‡πÉ‡∏´‡πâ‡πÄ‡∏à‡∏≤‡∏∞‡∏à‡∏á‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô ‡πÑ‡∏°‡πà‡∏Å‡∏ß‡∏≤‡∏î‡∏•‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ '‡πÅ‡∏ú‡∏ô')
        # ‡πÉ‡∏ä‡πâ -‡πÅ‡∏ú‡∏ô‡πÅ‡∏°‡πà‡∏ö‡∏ó -‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ä‡∏≤‡∏ï‡∏¥ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏•‡πà‡∏°‡πÉ‡∏´‡∏ç‡πà‡∏ó‡∏µ‡πà‡∏ã‡πâ‡∏≥‡∏ã‡πâ‡∏≠‡∏ô ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÄ‡∏Å‡πá‡∏ö '‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£' ‡πÑ‡∏ß‡πâ
        neg_strict = "-‡πÅ‡∏ú‡∏ô‡πÅ‡∏°‡πà‡∏ö‡∏ó -‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå‡∏ä‡∏≤‡∏ï‡∏¥ -MasterPlan"
        
        queries.append(f"{id_anchor} {clean_stmt} {keywords_str}")
        queries.append(f"{id_anchor} {clean_stmt}")

        if level <= 3:
            queries.append(f"{tenant_name} ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° {id_anchor} {short_keywords}")
            queries.append(f"{id_anchor} (‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£ OR ‡∏•‡∏á‡∏ô‡∏≤‡∏° OR ‡∏°‡∏∏‡πà‡∏á‡∏°‡∏±‡πà‡∏ô OR ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á OR ‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô) {neg_strict}")
        else:
            queries.append(f"{tenant_name} ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏• KPI ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å ‡∏ú‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à {id_anchor} {short_keywords}")
            queries.append(f"{id_anchor} (‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏• OR ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô OR ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° OR ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á OR ‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°) {neg_strict}")

        # 4. Source Bias (‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö P ‡πÅ‡∏•‡∏∞ D)
        if "P" in require_phases or "D" in require_phases:
            queries.append(f"{id_anchor} ‡∏°‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏® ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á ‡∏•‡∏á‡∏ô‡∏≤‡∏° {short_keywords}")

        # 5. Priority 1: query_synonyms ‡∏à‡∏≤‡∏Å json
        query_syn = self.get_rule_content(sub_id, level, "query_synonyms") or ""
        if query_syn:
            queries.append(f"{id_anchor} {query_syn} {short_keywords}")

        # 6. Priority 2: Rule-based synonyms
        if not query_syn:
            specific_rule = self.get_rule_content(sub_id, level, "specific_contextual_rule") or ""
            if specific_rule:
                rule_words = [w.strip() for w in specific_rule.split() if len(w.strip()) >= 4]
                rule_synonyms = " ".join(list(dict.fromkeys(rule_words))[:8])
                if rule_synonyms:
                    queries.append(f"{id_anchor} {rule_synonyms} {short_keywords}")

        # 7. Priority 3: Fallback PDCA synonyms
        fallback_synonyms = {
            "P": "‡πÅ‡∏ú‡∏ô‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ ‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢ ‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢ ‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏£‡∏°‡∏ì‡πå ‡∏°‡∏∏‡πà‡∏á‡∏°‡∏±‡πà‡∏ô ‡∏•‡∏á‡∏ô‡∏≤‡∏°",
            "D": "‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£ ‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏° ‡∏≠‡∏ö‡∏£‡∏° ‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°",
            "C": "‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏• KPI ‡∏ß‡∏±‡∏î‡∏ú‡∏• ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•",
            "A": "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á ‡∏û‡∏±‡∏í‡∏ô‡∏≤ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç ‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î ‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏° ‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö Best Practice"
        }

        for phase in require_phases:
            fallback = fallback_synonyms.get(phase, "")
            if fallback:
                queries.append(f"{id_anchor} {fallback} {short_keywords}")

        # 8. KM Specific (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• KM)
        if level <= 3 and enabler_id == "KM" and "D" in require_phases:
            queries.append(f"{id_anchor} (‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏° OR ‡∏≠‡∏ö‡∏£‡∏° OR ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏° OR ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏Å‡∏£ OR ‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ) {neg_strict}")

        # 9. Advanced/Focus hint
        if level >= 4 or focus_hint:
            adv = "‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏° Best Practice Lesson Learned ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"
            queries.append(f"{id_anchor} {adv} {focus_hint or ''}")

        # Post-process (Deduplicate & Truncate)
        final_queries = []
        seen = set()
        for q in queries:
            words = q.split()
            trunc_len = random.randint(22, 28)
            q_trunc = " ".join(words[:trunc_len])
            q_norm = " ".join(words[:18])
            if q_trunc and q_norm not in seen:
                final_queries.append(q_trunc)
                seen.add(q_norm)

        random.shuffle(final_queries)

        logger.info(f"üöÄ [Query Gen v2026.2.20] {sub_id} L{level} | Generated {len(final_queries)} queries "
                    f"(Phases: {require_str}) | Neg: {neg_strict}")
        
        return final_queries[:7]
        
    def _get_semantic_tag(self, text: str, sub_id: str, level: int, filename: str = "") -> str:
        """
        [ULTIMATE REVISE v2026.25 ‚Äì Required Phase Aware]
        - Follow required_phase ‡∏à‡∏≤‡∏Å contextual_rules ‡∏Ç‡∏≠‡∏á enabler ‡∏ô‡∏±‡πâ‡∏ô ‡πÜ
        - Prompt ‡∏™‡πà‡∏á require_phase ‡πÉ‡∏´‡πâ LLM ‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á prefer phase ‡πÑ‡∏´‡∏ô
        - Fallback ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å phase ‡∏à‡∏≤‡∏Å require_phase (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ ‚Üí random ‡∏ï‡∏≤‡∏° priority)
        - Heuristic ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å phase + JSON Clean ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô
        """
        tenant = getattr(self.config, 'tenant', 'Unknown').upper()
        enabler = getattr(self.config, 'enabler', 'Unknown').upper()
        text_lower = text.lower().strip()

        # ‡∏î‡∏∂‡∏á required_phase ‡∏à‡∏≤‡∏Å rules (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!)
        require_phases = self.get_rule_content(sub_id, level, "require_phase") or []
        require_str = ", ".join(require_phases) if require_phases else "P,D,C,A"

        # 1. Enhanced Heuristic (‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏ó‡∏∏‡∏Å phase ‚Äì ‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Ñ‡∏≥‡∏à‡∏≤‡∏Å log + defaults)
        if any(k in text_lower for k in [
            "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "‡πÅ‡∏ú‡∏ô", "‡∏¢‡∏∏‡∏ó‡∏ò‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå", "‡∏°‡∏ï‡∏¥", "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á", "‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢", "‡πÄ‡∏à‡∏ï‡∏ô‡∏≤‡∏£‡∏°‡∏ì‡πå",
            "‡∏ß‡∏¥‡∏™‡∏±‡∏¢‡∏ó‡∏±‡∏®‡∏ô‡πå", "master plan", "roadmap", "km policy", "‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÅ‡∏ú‡∏ô"
        ]):
            return "P"

        if any(k in text_lower for k in [
            "‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£", "‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥", "‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", "‡∏≠‡∏ö‡∏£‡∏°", "‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°", "‡∏à‡∏±‡∏î‡∏ó‡∏≥", "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢",
            "‡∏•‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°‡∏ú‡∏•", "‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•", "‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô", "‡∏•‡∏á‡∏ô‡∏≤‡∏°", "‡∏°‡∏ï‡∏¥‡∏ö‡∏≠‡∏£‡πå‡∏î",
            "‡πÄ‡∏´‡πá‡∏ô‡∏ä‡∏≠‡∏ö", "deployment", "‡∏à‡∏±‡∏î‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°", "‡∏ñ‡πà‡∏≤‡∏¢‡∏ó‡∏≠‡∏î", "‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£", "‡∏Ñ‡∏ì‡∏∞‡∏ó‡∏≥‡∏á‡∏≤‡∏ô"
        ]):
            return "D"

        if any(k in text_lower for k in [
            "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•", "‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°", "‡∏ï‡∏±‡∏ß‡∏ä‡∏µ‡πâ‡∏ß‡∏±‡∏î", "kpi", "‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå", "‡∏™‡∏≥‡∏£‡∏ß‡∏à",
            "‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô", "monitoring", "review", "audit", "benchmarking",
            "feedback", "‡πÅ‡∏ö‡∏ö‡∏™‡∏≥‡∏£‡∏ß‡∏à", "‡∏ß‡∏±‡∏î‡∏ú‡∏•"
        ]):
            return "C"

        if any(k in text_lower for k in [
            "‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á", "‡∏û‡∏±‡∏í‡∏ô‡∏≤", "‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç", "‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô", "lesson learned", "‡∏ï‡πà‡∏≠‡∏¢‡∏≠‡∏î",
            "‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°", "‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô", "‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö", "agile", "‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ", "‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô",
            "feedback loop"
        ]):
            return "A"

        # 2. LLM tagging (prompt ‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏° required_phase)
        system_prompt = (
            f"Auditor for {tenant} {enabler}. Classify text to ONE PDCA tag only. "
            "P=Plan (‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢/‡πÅ‡∏ú‡∏ô/‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢), D=Do (‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°/‡∏≠‡∏ö‡∏£‡∏°/‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°/‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢/‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Å‡∏≤‡∏£), "
            "C=Check (‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô/KPI/‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô/‡∏ï‡∏¥‡∏î‡∏ï‡∏≤‡∏°), A=Act (‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á/‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô/‡∏ô‡∏ß‡∏±‡∏ï‡∏Å‡∏£‡∏£‡∏°). "
            f"Required phases for this level: {require_str}. Prefer one of these phases if ambiguous. "
            "JSON only: {\"tag\":\"P/D/C/A/Other\",\"reason\":\"‡∏™‡∏±‡πâ‡∏ô ‡πÜ ‡πÑ‡∏ó‡∏¢\"}"
        )

        user_prompt = f"File: {filename}\nText (first 500 chars):\n{text[:500]}\n‚Üí JSON"

        try:
            response = self.llm.invoke(system_prompt + "\n" + user_prompt)
            # Clean ‡∏ó‡∏ô‡∏ó‡∏≤‡∏ô‡∏™‡∏∏‡∏î
            cleaned = response.strip()
            cleaned = re.sub(r'^.*?\{', '{', cleaned, flags=re.DOTALL | re.IGNORECASE)
            cleaned = re.sub(r'\}.*?$', '}', cleaned, flags=re.DOTALL | re.IGNORECASE)
            cleaned = cleaned.replace("```json", "").replace("```", "").replace("\n", " ").strip()
            cleaned = re.sub(r',\s*([}\]])', r'\1', cleaned)
            data = json.loads(cleaned)
            if isinstance(data, list) and data:
                data = data[0]
            tag = str(data.get("tag", "Other")).strip().upper()
            if tag in {"P", "D", "C", "A"}:
                reason = data.get('reason', '')
                self.logger.debug(f"[TAG LLM] {tag} | {reason} | {filename[:30]}")
                return tag
        except Exception as e:
            self.logger.warning(f"[TAG LLM FAIL] {sub_id} L{level} {filename[:30]} ‚Üí {str(e)} | Raw: {response[:100]}...")

        # 3. Final fallback (‡∏ï‡∏≤‡∏° required_phase ‚Äì ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢ phase ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏≤‡∏° priority ‡∏Ç‡∏≠‡∏á level)
        if require_phases:
            # Priority: ‡πÄ‡∏ô‡πâ‡∏ô phase ‡πÅ‡∏£‡∏Å‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡πÄ‡∏ä‡πà‡∏ô L1 ‚Üí D ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ, L4 ‚Üí C, L5 ‚Üí A)
            for phase in require_phases:
                if phase in ["P", "D", "C", "A"]:
                    self.logger.debug(f"[TAG FALLBACK] L{level} ‚Üí {phase} (from required phases)")
                    return phase
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ require_phase ‚Üí fallback ‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ‡∏ï‡∏≤‡∏° level
        if level <= 3:
            return "D"
        elif level == 4:
            return "C"
        else:
            return "A"
    
    def _build_pdca_context(self, blocks: Dict[str, str]) -> str:
        """
        [REVISED v2026.2]
        - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏ì‡∏µ content ‡∏ß‡πà‡∏≤‡∏á/‡∏™‡∏±‡πâ‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô
        - ‡πÉ‡∏ä‡πâ XML-like ‡πÅ‡∏ï‡πà‡∏ï‡∏±‡∏î‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏≠‡∏Å
        """
        tags = ["Plan", "Do", "Check", "Act", "Other"]
        parts = []

        for t in tags:
            content = blocks.get(t, "").strip()
            if not content or len(content) < 10:
                content = "[‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô]"
            # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô prompt ‡∏¢‡∏≤‡∏ß‡πÄ‡∏Å‡∏¥‡∏ô
            content = content[:800]
            parts.append(f"<{t}>{content}</{t}>")

        return "\n".join(parts)

    def _normalize_thai_text(self, text: str) -> str:
        """ 
        [LIGHTWEIGHT FIX] ‡πÉ‡∏ä‡πâ unicodedata ‡πÅ‡∏ó‡∏ô pythainlp ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Unicode 
        ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô
        """
        if not text: return ""
        
        # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Unicode (‡πÉ‡∏ä‡πâ 'NFKC' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏£‡πà‡∏≤‡∏á‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
        # ‡∏ä‡πà‡∏ß‡∏¢‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏™‡∏£‡∏∞‡∏ó‡∏µ‡πà‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÅ‡∏¢‡∏Å‡πÄ‡∏õ‡πá‡∏ô 2 ‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÉ‡∏´‡πâ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
        text = unicodedata.normalize('NFKC', text)
        
        # 2. ‡∏•‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏•‡πà‡∏≠‡∏á‡∏´‡∏ô (Zero-width characters) ‡∏ó‡∏µ‡πà‡∏°‡∏±‡∏Å‡∏û‡∏ö‡πÉ‡∏ô PDF
        text = text.replace('\u200b', '').replace('\ufeff', '')
        
        # 3. ‡∏•‡∏ö‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏¥‡∏î‡∏Å‡∏±‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏© (Regex ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
        text = re.sub(r'\s+', ' ', text)
        
        return text.strip()

    def _is_previous_level_passed(self, sub_id: str, level: int) -> bool:
        """
        [STRICT REVISE v2026.01.18.1] - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Level ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏Ç‡πâ‡∏°‡∏á‡∏ß‡∏î
        """
        if level <= 1: 
            return True
            
        prev_level = level - 1
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Key ‡∏ó‡∏±‡πâ‡∏á‡∏™‡∏≠‡∏á‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏≤‡∏à‡πÉ‡∏ä‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        possible_keys = [f"{sub_id}.L{prev_level}", f"{sub_id}_L{prev_level}"]
        
        for key in possible_keys:
            # ‡πÉ‡∏ä‡πâ get() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            result = getattr(self, 'assessment_results_map', {}).get(key)
            if result:
                if result.get('is_passed') is True:
                    self.logger.info(f"‚úÖ [LEVEL-GATE] Level {prev_level} passed for {sub_id}")
                    return True
                else:
                    self.logger.warning(f"‚ö†Ô∏è [LEVEL-GATE] Level {prev_level} found but status is FAIL")
                    return False

        # Safe Guard: ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏° Level ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
        self.logger.warning(f"üö´ [LEVEL-GATE] No assessment record for L{prev_level}. Blocking L{level}.")
        return False

    def _perform_adaptive_retrieval(self, sub_id: str, level: int, stmt: str, vectorstore_manager: Any):
        """
        [ULTIMATE RETRIEVAL v2026.1.22 ‚Äì FULL & STABLE]
        - ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Early Exit ‡πÅ‡∏•‡∏∞ Fallback ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö‡∏ß‡πà‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÑ‡∏°‡πà‡∏û‡∏≠
        """
        # 0. Params & Setup
        MAX_TOTAL_CHUNKS = 45
        MIN_QUALITY_FOR_EXIT = 0.88
        MIN_NEW_FOR_EXIT = 5
        MIN_QUERIES_FOR_EXIT = 2
        FORCE_EXTRA_LOOP_THRESHOLD = 3
        current_tenant = getattr(self.config, 'tenant', '‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£')
        
        # 1. Priority Chunks Retrieval
        mapped_ids, priority_docs = self._get_mapped_uuids_and_priority_chunks(
            sub_id, level, stmt, vectorstore_manager
        ) or (set(), [])

        candidates = []
        final_max_rerank = 0.0
        used_queries = 0
        forced_continue = False
        new_counts = []
        priority_uuids = {p.get('chunk_uuid') for p in priority_docs if p and p.get('chunk_uuid')}

        # 2. Search Loops (‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 queries)
        queries = self.enhance_query_for_statement(stmt, sub_id, f"{sub_id}.L{level}", level)
        queries = queries[:5]

        for i, q in enumerate(queries):
            q = self._normalize_thai_text(q) # Normalize ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô Search
            used_queries += 1
            
            res = self.rag_retriever(
                query=q, doc_type=self.doc_type, sub_id=sub_id, level=level,
                vectorstore_manager=vectorstore_manager, stable_doc_ids=mapped_ids
            ) or {"top_evidences": []}

            loop_docs = res.get("top_evidences", [])
            if not loop_docs:
                new_counts.append(0)
                continue

            loop_scores = [self.get_actual_score(d) for d in loop_docs if d]
            if loop_scores:
                current_max = max(loop_scores)
                final_max_rerank = max(final_max_rerank, current_max)

            # Deduplication
            new_docs = [d for d in loop_docs if d.get('chunk_uuid') not in priority_uuids]
            for d in new_docs:
                if d.get('chunk_uuid'): priority_uuids.add(d.get('chunk_uuid'))
            
            candidates.extend(new_docs)
            new_counts.append(len(new_docs))

            self.logger.info(f"üîç [LOOP {i+1}] Query: {q[:40]}... | New: {len(new_docs)} | Max: {final_max_rerank:.4f}")

            # Logic: ‡∏ñ‡πâ‡∏≤‡∏•‡∏π‡∏õ‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏•‡∏π‡∏õ‡∏™‡∏≠‡∏á
            if i == 0 and len(new_docs) == 0: forced_continue = True
            
            # Smart Early Exit
            total_count = len(priority_docs) + len(candidates)
            if (final_max_rerank >= MIN_QUALITY_FOR_EXIT and total_count >= 12 and 
                len(new_docs) >= MIN_NEW_FOR_EXIT and used_queries >= MIN_QUERIES_FOR_EXIT and not forced_continue):
                self.logger.info(f"üéØ [SMART EXIT] Loop {i+1} ‡∏¢‡∏∏‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏™‡∏π‡∏á‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
                break

        # 3. Phase-Aware Fallback (‡πÄ‡∏ô‡πâ‡∏ô‡∏´‡∏≤ C ‡πÅ‡∏•‡∏∞ A ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ï‡∏¥‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤)
        if (sum(new_counts) == 0 and used_queries >= 2) or (level >= 3 and final_max_rerank < 0.75):
            self.logger.warning(f"‚ö†Ô∏è [FALLBACK] L{level} ‡∏û‡∏ö Gap ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‚Üí ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡πÄ‡∏ô‡πâ‡∏ô Phase (PDCA)")
            req_phases = self.get_rule_content(sub_id, level, "require_phase") or ["P", "D"]
            
            # ‡∏ñ‡πâ‡∏≤ Level ‡∏™‡∏π‡∏á ‡πÉ‡∏´‡πâ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏Ç‡∏¢‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏õ‡∏ó‡∏µ‡πà C ‡πÅ‡∏•‡∏∞ A ‡πÄ‡∏™‡∏°‡∏≠
            target_p = list(set(req_phases + (["C", "A"] if level >= 3 else [])))
            fb_query = self._normalize_thai_text(f"{sub_id} {' OR '.join(target_p)} {current_tenant}")
            
            res_fb = self.rag_retriever(query=fb_query, doc_type=self.doc_type, sub_id=sub_id, level=level, vectorstore_manager=vectorstore_manager)
            if res_fb and res_fb.get("top_evidences"):
                fb_new = [d for d in res_fb["top_evidences"] if d.get('chunk_uuid') not in priority_uuids]
                candidates.extend(fb_new)
                self.logger.info(f"‚úÖ [FALLBACK] ‡∏î‡∏∂‡∏á‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ {len(fb_new)} chunks")

        # 4. Final Processing & Deduplication
        unique_docs = {}
        for doc in (priority_docs + candidates):
            if not doc: continue
            uid = doc.get('chunk_uuid') or hashlib.sha256(str(doc.get('page_content','')).encode()).hexdigest()
            if uid not in unique_docs: unique_docs[uid] = doc

        final_docs = list(unique_docs.values())
        if len(final_docs) > MAX_TOTAL_CHUNKS:
            final_docs = sorted(final_docs, key=lambda x: (x.get('is_priority', False), self.get_actual_score(x)), reverse=True)[:MAX_TOTAL_CHUNKS]

        # 5. Safety Floor
        for p in final_docs:
            if p.get('chunk_uuid') in [d.get('chunk_uuid') for d in priority_docs]:
                p['is_priority'] = True
                p['rerank_score'] = max(self.get_actual_score(p), 0.70)

        return final_docs, final_max_rerank

    def _log_pdca_status(self, sub_id, name, level, blocks, req_phases, sources_count, score, conf_level, **kwargs):
        """
        [THE AUDITOR DASHBOARD v2026.3.10 - FULL REVISED]
        üß© ‡∏£‡∏∞‡∏ö‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ PDCA ‡πÅ‡∏ö‡∏ö Real-Count Dashboard
        - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç Maturity Gap ‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà Save ‡∏à‡∏£‡∏¥‡∏á
        - ‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏ö‡∏ö Double-Check (Payload Count + Tagging List)
        """
        try:
            # 1. ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å Payload ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏â‡∏µ‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤ (Single Source of Truth)
            # ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å pdca_breakdown ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡∏™‡πà‡∏á‡∏°‡∏≤‡∏à‡∏≤‡∏Å _run_single_assessment
            actual_counts = kwargs.get('pdca_breakdown', {}) 
            raw_tagging = kwargs.get('tagging_result') or []
            is_safety_pass = kwargs.get('is_safety_pass', False)
            
            status_parts = []
            extract_parts = []
            
            # Mapping ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Key ‡πÉ‡∏ô JSON Response ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏ß‡∏¢‡πà‡∏≠ Phase
            mapping = [
                ("Extraction_P", "P"), 
                ("Extraction_D", "D"), 
                ("Extraction_C", "C"), 
                ("Extraction_A", "A")
            ]

            # 2. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏£‡∏≤‡∏¢ Phase
            for full_key, short in mapping:
                # --- [REVISED COUNTING LOGIC] ---
                # ‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: 1. ‡∏î‡∏π‡∏à‡∏≤‡∏Å actual_counts | 2. ‡∏ô‡∏±‡∏ö‡∏à‡∏≤‡∏Å raw_tagging list
                if actual_counts and short in actual_counts:
                    count = actual_counts[short]
                elif isinstance(raw_tagging, list):
                    count = raw_tagging.count(short)
                else:
                    count = 0
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ LLM ‡∏™‡∏Å‡∏±‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (Extraction) ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÑ‡∏î‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠ N/A ‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Icon ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
                content = str(blocks.get(full_key, "")).strip()
                ai_found = bool(content and content.lower() not in [
                    "-", "n/a", "none", "null", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô", "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏"
                ])
                
                # --- [ICON LOGIC v2026.3.10] ---
                # ‚úÖ: ‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏ä‡∏¥‡∏á‡∏õ‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏©‡πå (Count > 0)
                # üî∑: ‡∏£‡∏∞‡∏ö‡∏ö Force Pass ‡∏´‡∏£‡∏∑‡∏≠ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏à‡∏≠‡πÄ‡∏≠‡∏á‡πÅ‡∏ï‡πà RAG Tagging ‡πÑ‡∏°‡πà‡∏ï‡∏¥‡∏î
                # ‚ûñ: ‡πÄ‡∏ü‡∏™‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö (Not in req_phases)
                # ‚ùå: ‡πÄ‡∏ü‡∏™‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡πÄ‡∏•‡∏¢ (Count=0 ‡πÅ‡∏•‡∏∞ AI ‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠)
                
                if count > 0: 
                    icon = "‚úÖ" 
                elif ai_found or (is_safety_pass and short in req_phases): 
                    icon = "üî∑"
                elif short not in req_phases: 
                    icon = "‚ûñ"
                else: 
                    icon = "‚ùå"
                
                # ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ ‡πÄ‡∏ä‡πà‡∏ô P:‚úÖ(15)
                status_parts.append(f"{short}:{icon}({count})")
                
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏±‡πâ‡∏ô‡πÜ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Trace Log (2 ‡∏ä‡∏¥‡πâ‡∏ô‡πÅ‡∏£‡∏Å)
                if ai_found and len(extract_parts) < 2:
                    clean_content = content.replace("\n", " ")
                    extract_parts.append(f"[{short}: {clean_content[:60]}...]")

            # 3. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            display_score = float(score) if score is not None else 0.0
            
            # 4. [DASHBOARD OUTPUT] ‡∏û‡∏¥‡∏°‡∏û‡πå Log ‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠
            # ‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á
            self.logger.info(
                f"üìä [PDCA-STATUS] {sub_id} L{level} | {str(name)[:60]}...\n"
                f"   Maturity Gap: {' '.join(status_parts)}{' üõ°Ô∏è[SAFETY-PASS]' if is_safety_pass else ''}\n"
                f"   Summary: Score={display_score:.2f} | Evidence={sources_count} chunks | Conf={conf_level.upper()}"
            )
            
            # 5. ‡∏û‡∏¥‡∏°‡∏û‡πå Log ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô (Traceability)
            if extract_parts:
                self.logger.info(f"üîç [EXTRACT-TRACE] {' | '.join(extract_parts)}")

        except Exception as e:
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏±‡∏á‡∏´‡∏≤‡∏Å‡πÄ‡∏Å‡∏¥‡∏î Error ‡πÉ‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥ Log Dashboard
            self.logger.error(f"‚ùå Critical Error in _log_pdca_status: {str(e)}")

    def _summarize_evidence_list_short(self, evidences: list, max_sentences: int = 3) -> str:
        """
        [REVISED v2026.SUMMARY.4]
        - ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Method ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ self.logger
        - ‡πÄ‡∏ô‡πâ‡∏ô‡∏î‡∏∂‡∏á Source ‡πÅ‡∏•‡∏∞ Page ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á Audit Traceability
        - ‡∏õ‡∏£‡∏±‡∏ö Formatting ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô Bullet points (LLM ‡∏≠‡πà‡∏≤‡∏ô‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤ Pipe '|')
        """
        if not evidences:
            return "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°"
        
        parts = []
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û (‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤) ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏° max_sentences
        valid_evidences = [
            ev for ev in evidences 
            if isinstance(ev, dict) and (ev.get("text") or ev.get("content", "")).strip()
        ]
        
        # ‡∏ï‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏à‡∏£‡∏¥‡∏á)
        target_count = max(1, min(len(valid_evidences), max_sentences))
        
        for ev in valid_evidences[:target_count]:
            # 1. ‡∏™‡∏Å‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤ (Source Mapping)
            filename = (ev.get("file_name") or ev.get("source") or 
                        ev.get("source_filename") or "‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå")
            page = ev.get("page", "-")
            
            # 2. ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤ (Data Cleaning)
            raw_text = ev.get("text") or ev.get("content") or ""
            # ‡∏•‡∏ö‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô ‡πÅ‡∏•‡∏∞‡∏ï‡∏±‡∏î‡πÄ‡∏≠‡∏≤‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ï‡πâ‡∏ô
            clean_text = " ".join(raw_text.split()).strip()
            text_preview = clean_text[:150] # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏õ‡πá‡∏ô 150 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡∏ó‡∏µ‡πà‡∏ä‡∏±‡∏î‡∏Ç‡∏∂‡πâ‡∏ô
            
            # 3. ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö‡∏£‡πà‡∏≤‡∏á (Formatting)
            if text_preview:
                parts.append(f"‚Ä¢ [{filename}, ‡∏´‡∏ô‡πâ‡∏≤ {page}]: \"{text_preview}...\"")
            else:
                parts.append(f"‚Ä¢ [{filename}, ‡∏´‡∏ô‡πâ‡∏≤ {page}]: (‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÑ‡∏î‡πâ)")

        # ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏Ç‡∏∂‡πâ‡∏ô‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÉ‡∏´‡∏°‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡πÅ‡∏¢‡∏Å‡πÅ‡∏¢‡∏∞‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏¥‡πâ‡∏ô‡πÑ‡∏î‡πâ‡∏á‡πà‡∏≤‡∏¢
        return "\n".join(parts) 
    
    def relevance_score_fn(self, evidence: Dict[str, Any], sub_id: str, level: int) -> float:
        """
        [REVISED RELEVANCE SCORE v2026.3.1 - Balanced & Robust]
        - 45% Rerank + 35% Keyword + 20% Bonuses
        - PDCA tag bonus ‡∏™‡∏π‡∏á‡∏Ç‡∏∂‡πâ‡∏ô‡∏ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö required phases
        - Source grading ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏î‡∏∏‡∏• (primary + secondary)
        - Min floor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö rerank ‡∏™‡∏π‡∏á
        - Logging ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô
        """
        if not evidence:
            return 0.0

        # 1. Rerank (45%)
        rerank_raw = evidence.get('rerank_score') or evidence.get('score') or 0.0
        rerank_score = float(rerank_raw) if isinstance(rerank_raw, (int, float)) else 0.0
        normalized_rerank = min(max(rerank_score, 0.0), 1.0)

        # 2. ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
        text = (evidence.get('text') or evidence.get('page_content') or '').lower().strip()
        meta = evidence.get('metadata', {}) if isinstance(evidence.get('metadata'), dict) else {}
        filename = (meta.get('source') or meta.get('source_filename') or '').lower()

        # 3. Cumulative rules
        cum_rules = self.get_cumulative_rules(sub_id, level)

        # 4. Source Grading (‡∏õ‡∏£‡∏±‡∏ö‡∏™‡∏°‡∏î‡∏∏‡∏•)
        source_bonus = 0.0
        primary = ["‡∏°‡∏ï‡∏¥", "‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å", "‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á", "‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®", "‡∏ô‡πÇ‡∏¢‡∏ö‡∏≤‡∏¢", "‡πÅ‡∏ú‡∏ô‡πÅ‡∏°‡πà‡∏ö‡∏ó", "‡∏°‡∏ï‡∏¥‡∏ö‡∏≠‡∏£‡πå‡∏î"]
        secondary = ["assessment report", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô", "‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•", "‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•", "kpi"]
        if any(p in filename for p in primary):
            source_bonus += 0.20
        if any(p in filename for p in secondary):
            source_bonus += 0.10  # ‡πÑ‡∏°‡πà‡∏•‡∏ö ‡πÅ‡∏ï‡πà‡∏•‡∏î‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å

        # 5. Keyword Score (35%)
        target_kws = set()
        if level <= 2:
            target_kws.update(cum_rules.get('plan_keywords', []) + cum_rules.get('do_keywords', []))
        else:
            target_kws.update(cum_rules.get('check_keywords', []) + cum_rules.get('act_keywords', []))

        match_count = sum(1 for kw in target_kws if kw.lower() in text)
        expected = max(1, len(target_kws) * 0.3)  # ‡∏õ‡∏£‡∏±‡∏ö threshold ‡∏•‡∏á‡∏ô‡∏¥‡∏î
        keyword_score = min((match_count / expected) ** 0.6, 1.0)  # ^0.6 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô
        keyword_score = max(keyword_score, 0.20 if match_count >= 1 else 0.0)

        # 6. PDCA Tag Bonus (0.30 ‡∏ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á required)
        pdca_bonus = 0.0
        pdca_tag = evidence.get('pdca_tag') or meta.get('pdca_tag') or ""
        required_phases = cum_rules.get('required_phases', [])
        if pdca_tag and str(pdca_tag).upper() in required_phases:
            pdca_bonus = 0.30
        elif pdca_tag and str(pdca_tag).upper() in {'P', 'D', 'C', 'A'}:
            pdca_bonus = 0.15  # bonus ‡πÄ‡∏•‡πá‡∏Å‡∏ñ‡πâ‡∏≤‡∏ï‡∏£‡∏á PDCA ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô required

        # 7. Neighbor Bonus
        neighbor_bonus = 0.15 if evidence.get('is_neighbor', False) or meta.get('is_neighbor', False) else 0.0

        # 8. Specific Rule Bonus (‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö rule ‡πÄ‡∏â‡∏û‡∏≤‡∏∞)
        specific_rule = cum_rules.get('specific_contextual_rule', '').lower()
        rule_bonus = 0.15 if specific_rule and any(word in text for word in specific_rule.split()[:10]) else 0.0

        # 9. ‡∏£‡∏ß‡∏°‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (45% Rerank + 35% Keyword + 20% Bonuses)
        final_score = (
            0.45 * normalized_rerank +
            0.35 * keyword_score +
            source_bonus + pdca_bonus + neighbor_bonus + rule_bonus
        )

        # 10. Min floor ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö rerank ‡∏™‡∏π‡∏á
        if normalized_rerank > 0.80:
            final_score = max(final_score, 0.45)

        final_score = min(max(final_score, 0.0), 1.0)

        # 11. Logging (info ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö high score, debug ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏∏‡∏Å‡∏ï‡∏±‡∏ß)
        if normalized_rerank > 0.75 or final_score > 0.60:
            self.logger.info(
                f"[HIGH-RELEVANCE] {sub_id} L{level} | "
                f"final={final_score:.4f} | rerank={normalized_rerank:.4f} | "
                f"kw={keyword_score:.4f} | pdca_bonus={pdca_bonus:.3f} | "
                f"tag={pdca_tag} | source_bonus={source_bonus:.3f}"
            )

        self.logger.debug(
            f"[{sub_id} L{level}] RelScore: {final_score:.4f} | Rerank: {normalized_rerank:.4f} | "
            f"KW: {keyword_score:.4f} | PDCA: {pdca_bonus:.3f} | Src: {source_bonus:.3f}"
        )

        return final_score

    def _build_multichannel_context_for_level( # ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô Private Method
        self, # ‡πÄ‡∏û‡∏¥‡πà‡∏° self
        level: int,
        top_evidences: List[Dict[str, Any]],
        previous_levels_map: Optional[Dict[str, Any]] = None,
        previous_levels_evidence: Optional[List[Dict[str, Any]]] = None,
        max_main_context_tokens: int = 3000, 
        max_summary_sentences: int = 4,
        max_context_length: Optional[int] = None, 
        **kwargs
    ) -> Dict[str, Any]:
        """
        [ULTIMATE OPTIMIZED v2026.8 - REFACTORED AS CLASS METHOD]
        """
        K_MAIN = 5
        # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Config ‡πÉ‡∏ô Class ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ‡πÄ‡∏ä‡πà‡∏ô self.config.l1_threshold
        MIN_RELEVANCE_FOR_AUX = 0.15 if level == 1 else 0.4 

        # 1. Baseline Summary
        baseline_evidence = previous_levels_evidence or []
        if previous_levels_map:
            for lvl_ev in previous_levels_map.values():
                baseline_evidence.extend(lvl_ev)

        # Normalize list (‡∏ï‡∏≤‡∏° Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡∏ö‡∏±‡πä‡∏Å Slice ‡πÅ‡∏•‡πâ‡∏ß)
        baseline_evidence_list = []
        if isinstance(baseline_evidence, list):
            baseline_evidence_list = baseline_evidence
        elif isinstance(baseline_evidence, dict):
            baseline_evidence_list = list(baseline_evidence.values())
        
        summarizable_baseline = [
            item for item in baseline_evidence_list[:40] 
            if isinstance(item, dict) and (item.get("text") or item.get("content", "")).strip()
        ]

        if not summarizable_baseline:
            baseline_summary = "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà Level 1)"
        else:
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ú‡πà‡∏≤‡∏ô self
            baseline_summary = self._summarize_evidence_list_short(
                summarizable_baseline,
                max_sentences=max_summary_sentences
            )

        # 2. Direct + Aux Separation
        direct, aux_candidates = [], []

        for idx, ev in enumerate(top_evidences[:40], 1):
            if not isinstance(ev, dict): continue

            tag = (ev.get("pdca_tag") or ev.get("PDCA") or "Other").upper()
            relevance = ev.get("rerank_score") or ev.get("score", 0.0)
            text_preview = (ev.get('text', '')[:80] + "...") if ev.get('text') else "[No text]"

            # ‡πÉ‡∏ä‡πâ self.logger ‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
            self.logger.debug(f"[TAG-CHECK L{level} #{idx}] Rel: {relevance:.3f} | Tag: {tag} | Preview: {text_preview}")

            if tag in {"P", "PLAN", "D", "DO", "C", "CHECK", "A", "ACT"}:
                direct.append(ev)
            elif relevance >= MIN_RELEVANCE_FOR_AUX:
                aux_candidates.append(ev)

        # 3. Logic ‡∏Å‡∏≤‡∏£‡∏¢‡πâ‡∏≤‡∏¢ Aux ‡πÅ‡∏•‡∏∞ Fallback (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏° ‡πÅ‡∏ï‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô self.logger)
        if len(direct) < K_MAIN:
            need = K_MAIN - len(direct)
            moved = aux_candidates[:need]
            direct.extend(moved)
            aux_candidates = aux_candidates[need:]
            self.logger.info(f"[DIRECT-FILL] Moved {need} aux chunks to direct (total direct: {len(direct)})")

        if level == 1 and len(direct) == 0 and top_evidences:
            need = min(K_MAIN, len(top_evidences))
            forced_chunks = sorted(top_evidences, key=lambda e: e.get("rerank_score", 0) or e.get("score", 0), reverse=True)[:need]
            direct.extend(forced_chunks)
            self.logger.warning(f"[L1-ULTRA-FALLBACK] No PDCA tag at all ‚Üí Forced top {need} chunks to direct")

        # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á aux_summary (‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ú‡πà‡∏≤‡∏ô self)
        aux_summary = self._summarize_evidence_list_short(aux_candidates, max_sentences=3) if aux_candidates else \
            "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏£‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠"

        # 6. Return ‡∏û‡∏£‡πâ‡∏≠‡∏° Debug Meta
        self.logger.info(f"Context L{level} ‚Üí Direct:{len(direct)} | Aux:{len(aux_candidates)} | Baseline:{len(summarizable_baseline)}")

        return {
            "baseline_summary": baseline_summary,
            "direct_context": "", 
            "aux_summary": aux_summary,
            "debug_meta": {
                "level": level,
                "direct_count": len(direct),
                "aux_count": len(aux_candidates),
                "top_relevance": max((ev.get("rerank_score", 0) for ev in top_evidences), default=0)
            },
        }

    def _run_expert_re_evaluation(
        self,
        sub_id: str,
        level: int,
        statement_text: str,
        context: str,
        first_attempt_reason: str,
        missing_tags: Union[List[str], Set[str]],
        highest_rerank_score: float,
        sub_criteria_name: str,
        llm_evaluator_to_use: Any,
        base_kwargs: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        [JUDICIAL REVIEW MODULE v2026.3.10] - ‡∏£‡∏∞‡∏ö‡∏ö‡∏≠‡∏∏‡∏ó‡∏ò‡∏£‡∏ì‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
        ‡∏ó‡∏≥‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ã‡πâ‡∏≥‡πÄ‡∏°‡∏∑‡πà‡∏≠ Rerank Score ‡∏™‡∏π‡∏á (>0.75) ‡πÅ‡∏ï‡πà AI ‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏´‡πâ‡∏ï‡∏Å
        ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ '‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥‡∏à‡∏£‡∏¥‡∏á' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡∏õ‡∏±‡∏ç‡∏´‡∏≤ AI ‡∏ï‡∏≤‡∏ö‡∏≠‡∏î (False Negative)
        """
        self.logger.info(f"‚öñÔ∏è [EXPERT-APPEAL] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ó‡∏ò‡∏£‡∏ì‡πå {sub_id} L{level} | Max Rerank: {highest_rerank_score:.4f}")
        
        # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≤‡∏î‡∏´‡∏≤‡∏¢‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡πÉ‡∏ö‡πâ (Hint) ‡πÉ‡∏´‡πâ LLM
        missing_str = ", ".join(sorted(set(missing_tags))) if missing_tags else "‡∏û‡∏§‡∏ï‡∏¥‡∏Å‡∏£‡∏£‡∏°‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå PDCA"
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á Expert Instruction ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á AI ‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 2
        hint_msg = f"""
        ### üö® EXPERT AUDIT INSTRUCTION (SECOND CHANCE) üö®
        ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏û‡∏¥‡πÄ‡∏®‡∏©‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç:
        - [CONTEXT]: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≠‡∏ö‡πÅ‡∏£‡∏Å‡πÑ‡∏°‡πà‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å: "{first_attempt_reason[:200]}..."
        - [OPPORTUNITY]: ‡∏£‡∏∞‡∏ö‡∏ö RAG ‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å ({highest_rerank_score:.4f}) ‡∏ã‡∏∂‡πà‡∏á‡∏≠‡∏≤‡∏à‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á: {missing_str}
        - [MANDATE]: ‡πÉ‡∏ä‡πâ‡∏Å‡∏é 'Substance over Form' - ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô ‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏° ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏ö‡∏±‡∏ï‡∏¥ ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≥‡∏ï‡∏£‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå 100% ‡πÉ‡∏´‡πâ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ "‡∏ú‡πà‡∏≤‡∏ô (is_passed: true)"
        - [FOCUS]: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà Rerank ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î 5 ‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
        """
        
        # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Parameter ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ Re-evaluation
        expert_kwargs = base_kwargs.copy()
        expert_kwargs["context"] = f"{context}\n\n{hint_msg}"
        expert_kwargs["ai_confidence"] = "MAX"  # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ AI ‡∏Å‡∏•‡πâ‡∏≤‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        
        try:
            # 4. ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ LLM ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≠‡∏ö‡∏ó‡∏µ‡πà 2 (‡πÉ‡∏ä‡πâ evaluator ‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏ï‡πà‡∏â‡∏µ‡∏î Guideline ‡πÉ‡∏´‡∏°‡πà)
            re_eval_result = llm_evaluator_to_use(**expert_kwargs)
            
            # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Å‡∏£‡∏ì‡∏µ LLM ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None
            if not re_eval_result:
                return {"is_passed": False, "score": 0.0, "reason": "Expert System: No response from LLM"}

            re_eval_result["is_expert_evaluated"] = True
            
            # 5. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏Å‡∏£‡∏ì‡∏µ‡∏≠‡∏∏‡∏ó‡∏ò‡∏£‡∏ì‡πå‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
            if re_eval_result.get("is_passed", False):
                self.logger.info(f"üõ°Ô∏è [OVERRIDE-SUCCESS] {sub_id} L{level} | Appeal Granted by Expert System")
                
                # ‡∏â‡∏µ‡∏î Flag ‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Dashboard ‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô üõ°Ô∏è ‡πÅ‡∏•‡∏∞ üî∑
                re_eval_result["is_safety_pass"] = True 
                re_eval_result["appeal_status"] = "GRANTED"
                
                # ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏•‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏≠‡∏∏‡∏ó‡∏ò‡∏£‡∏ì‡πå
                original_reason = re_eval_result.get('reason', '')
                re_eval_result["reason"] = f"üåü [EXPERT OVERRIDE]: {original_reason}"
            else:
                self.logger.info(f"‚ùå [APPEAL-DENIED] {sub_id} L{level} | Evidence still insufficient")
                re_eval_result["appeal_status"] = "DENIED"
                re_eval_result["is_safety_pass"] = False

            return re_eval_result

        except Exception as e:
            self.logger.error(f"üõë [EXPERT-ERROR] {sub_id} L{level} System Failure: {str(e)}")
            return {
                "is_passed": False, 
                "score": 0.0, 
                "reason": f"Appeal System Error: {str(e)}",
                "is_safety_pass": False
            }
        
    def _apply_diversity_filter(self, evidences: List[Any], level: int) -> List[Dict[str, Any]]:
        """
        [ORIGINAL VERSION - ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡πÄ‡∏´‡πá‡∏ô tag ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏£‡∏¥‡∏á + ‡∏°‡∏µ‡∏´‡∏ô‡πâ‡∏≤]
        """
        if not evidences:
            self.logger.warning(f"‚ö†Ô∏è [DIVERSITY-FILTER] No evidence input for Level {level}")
            return []

        unique_chunks = {}
        seen_contents = set()
        source_distribution = {}
        
        # --- ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏π‡∏ô‡πÉ‡∏´‡∏°‡πà‡πÉ‡∏´‡πâ‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Ç‡∏∂‡πâ‡∏ô ---
        # ‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏¥‡∏ö‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Ç‡∏∂‡πâ‡∏ô‡πÉ‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏™‡∏π‡∏á (‡πÄ‡∏î‡∏¥‡∏° 5 ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 8)
        MAX_PER_SOURCE = 10 if level <= 2 else 8  
        
        # ‡∏•‡∏î‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏•‡∏á‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ (‡πÄ‡∏î‡∏¥‡∏° 0.25 ‡πÄ‡∏õ‡πá‡∏ô 0.18) 
        # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà "‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á" ‡∏´‡∏•‡∏∏‡∏î‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡πÉ‡∏´‡πâ AI ‡∏ä‡πà‡∏ß‡∏¢‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÑ‡∏î‡πâ
        MIN_SCORE_THRESHOLD = 0.18 if level >= 3 else 0.22
        
        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏±‡∏Å‡∏©‡∏≤‡πÑ‡∏ß‡πâ (‡πÄ‡∏î‡∏¥‡∏° 5 ‡πÄ‡∏õ‡πá‡∏ô 8)
        EMERGENCY_MIN_COUNT = 8

        # 1. Standardize
        standardized_ev = []
        for ev in evidences:
            try:
                if hasattr(ev, 'page_content'):
                    text = str(ev.page_content).strip()
                    meta = getattr(ev, 'metadata', {})
                elif isinstance(ev, dict):
                    text = str(ev.get('text', '') or ev.get('page_content', '')).strip()
                    meta = ev.get('metadata', {})
                else:
                    continue
                
                if text:
                    score = self.get_actual_score(ev)  # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á score ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ
                    standardized_ev.append({
                        "text": text,
                        "metadata": meta,
                        "score": score
                    })
            except Exception as e:
                self.logger.error(f"Error standardizing chunk: {e}")

        # 2. Sort
        sorted_ev = sorted(standardized_ev, key=lambda x: x.get('score', 0), reverse=True)

        # 3. Main Filter Loop
        for ev in sorted_ev:
            text = ev["text"]
            meta = ev["metadata"]
            score = ev["score"]

            if score < MIN_SCORE_THRESHOLD and len(unique_chunks) >= EMERGENCY_MIN_COUNT:
                continue

            content_fingerprint = "".join(text[:400].split()).lower()
            if content_fingerprint in seen_contents:
                continue

            source = str(meta.get('source_filename') or meta.get('source') or "Unknown")
            source_count = source_distribution.get(source, 0)
            
            if source_count >= MAX_PER_SOURCE and len(source_distribution) > 1:
                continue

            uid = meta.get("chunk_uuid") or hash(content_fingerprint)
            unique_chunks[uid] = ev
            seen_contents.add(content_fingerprint)
            source_distribution[source] = source_count + 1

        filtered_list = list(unique_chunks.values())
        
        # Final Log
        self.logger.info(
            f"üõ°Ô∏è [DIVERSITY-FILTER] Level {level} | "
            f"In: {len(evidences)} -> Out: {len(filtered_list)} | "
            f"Sources: {len(set([str(v['metadata'].get('source_filename', 'Unknown')) for v in filtered_list]))} files"
        )
        
        return filtered_list
    
    def _generate_action_plan_safe(
        self, 
        sub_id: str, 
        name: str, 
        enabler: str, 
        results: List[Dict]
    ) -> Any:
        """
        [ULTIMATE STRATEGIC REVISE v2026.3.23 - Production Ready]
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Pydantic-validated output ‡∏à‡∏≤‡∏Å llm_data_utils
        - ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Error Handling ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°‡∏Å‡∏£‡∏ì‡∏µ Validation ‡∏û‡∏±‡∏á
        """
        try:
            self.logger.info(f"üöÄ [ACTION PLAN] Generating for {sub_id} - {name}")

            to_recommend = []
            has_major_gap = False

            # 1. ‡∏à‡∏±‡∏î‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Gaps ‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
            sorted_results = sorted(results, key=lambda x: x.get('level', 0))

            for r in sorted_results:
                level = r.get('level', 0)
                is_passed = r.get('is_passed', False)
                score = float(r.get('score', 0.0))
                pdca_raw = r.get('pdca_breakdown', {})

                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏≤ PDCA Phase ‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ (‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 0.5)
                missing = [p for p in ['P', 'D', 'C', 'A'] if float(pdca_raw.get(p, 0.0)) < 0.5]

                coaching = r.get('coaching_insight', '').strip()
                # ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏π‡∏á ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á summary_thai ‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏à‡∏∏‡∏î‡πÅ‡∏Ç‡πá‡∏á
                strength = r.get('summary_thai', r.get('reason', '')).strip() if is_passed and score >= 0.8 else ""

                payload = {
                    "level": level,
                    "is_passed": is_passed,
                    "score": score,
                    "missing_phases": missing,
                    "coaching_insight": coaching,
                    "strength_context": strength,
                    "recommendation_type": "FAILED_REMEDIATION" if not is_passed else
                                          "QUALITY_REFINEMENT" if missing or score < 1.0 else
                                          "EXCELLENCE_MAINTENANCE"
                }

                if not is_passed or missing:
                    has_major_gap = True
                to_recommend.append(payload)

            # 2. ‡∏Å‡∏£‡∏ì‡∏µ‡∏ú‡πà‡∏≤‡∏ô‡∏´‡∏°‡∏î (Excellence) -> ‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©
            if not has_major_gap:
                self.logger.info(f"üåü {sub_id} EXCELLENT - No major gaps")
                return {
                    "status": "EXCELLENT",
                    "message": "‡∏ö‡∏£‡∏£‡∏•‡∏∏‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå",
                    "coaching_summary": "‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡∏û‡∏±‡∏í‡∏ô‡∏≤‡πÄ‡∏õ‡πá‡∏ô Best Practice ‡∏ï‡πà‡∏≠‡πÑ‡∏õ"
                }

            # 3. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Args ‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ Strategic Action Plan Engine
            action_plan_args = {
                "recommendation_statements": to_recommend,
                "sub_id": sub_id,
                "sub_criteria_name": name,
                "enabler": enabler,
                "target_level": getattr(self.config, 'target_level', 5),
                "llm_executor": self.llm,
                "logger": self.logger,
                "enabler_rules": getattr(self.config, 'enabler_rules', {})
            }

            self.logger.info(f"[ACTION PLAN] Invoking engine with {len(to_recommend)} items")
            
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏ô llm_data_utils.py ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏û‡∏¥‡πà‡∏á‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á (‡∏ã‡∏∂‡πà‡∏á‡πÉ‡∏ä‡πâ Pydantic ‡∏î‡πâ‡∏≤‡∏ô‡πÉ‡∏ô)
            action_plan_result = create_structured_action_plan(**action_plan_args)

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå: ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á (‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà LLM ‡∏û‡πà‡∏ô‡∏Ç‡∏¢‡∏∞‡πÅ‡∏•‡∏∞ Pydantic ‡∏î‡∏±‡∏Å‡∏ó‡∏¥‡πâ‡∏á) ‡πÉ‡∏´‡πâ‡πÄ‡∏Ç‡πâ‡∏≤ Fallback
            if not action_plan_result:
                raise ValueError("Engine returned empty or invalid action plan after validation")

            return action_plan_result

        except Exception as e:
            self.logger.error(f"‚ùå Action Plan Failed for {sub_id}: {str(e)}")
            # ‡πÉ‡∏ä‡πâ Emergency Fallback Plan ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ User ‡∏¢‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö Roadmap ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 1 Phase
            return _get_emergency_fallback_plan(
                sub_id=sub_id, 
                sub_criteria_name=name, 
                target_level=getattr(self.config, 'target_level', 5), 
                is_sustain_mode=False, 
                is_quality_refinement=False, 
                enabler=enabler,
                recommendation_statements=to_recommend
            )


    # ------------------------------------------------------------------------------------------
    # [ULTIMATE ORCHESTRATOR v2026.3] run_assessment - COMPLETE 5 LEVELS EDITION
    # ------------------------------------------------------------------------------------------
    def run_assessment(
        self,
        target_sub_id: str = "all",
        export: bool = False,
        vectorstore_manager: Optional['VectorStoreManager'] = None,
        sequential: bool = False,
        document_map: Optional[Dict[str, str]] = None,
        record_id: str = None,
    ) -> Dict[str, Any]:
        """
        Main Entry Point: ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏Ñ‡∏£‡∏ö 1-5 ‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Gap Analysis
        """
        start_ts = time.time()
        self.is_sequential = sequential
        self.current_record_id = record_id or self.record_id

        # 1. üéØ Step 1: ‡∏Å‡∏£‡∏≠‡∏á‡πÄ‡∏Å‡∏ì‡∏ë‡πå (‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡∏∏‡∏Å Level ‡∏Ç‡∏≠‡∏á Sub-ID ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏)
        all_statements = self._flatten_rubric_to_statements()
        is_all = str(target_sub_id).lower() == "all"
        
        # ‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
        sub_criteria_list = all_statements if is_all else [
            s for s in all_statements if str(s.get('sub_id')).lower() == str(target_sub_id).lower()
        ]

        if not sub_criteria_list:
            return self._create_failed_result(self.current_record_id, f"Criteria '{target_sub_id}' not found", start_ts)

        # üö© [CRITICAL] ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö L1 -> L5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏Ç‡∏≠‡∏á Log ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏£‡∏±‡∏ô‡∏à‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        sub_criteria_list = sorted(sub_criteria_list, key=lambda x: (x.get('sub_id'), x.get('level')))

        total_tasks = len(sub_criteria_list)
        self.db_update_task_status(progress=5, message=f"üìä ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô {total_tasks} ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (Maturity L1-L5)...")

        # 2. üîÑ Step 2: Setup (Evidence Map & VSM)
        existing_data = self._load_evidence_map()
        self.evidence_map = existing_data.get("evidence_map", existing_data) if isinstance(existing_data, dict) else {}

        # 3. üöÄ Step 3: Execution Phase
        max_workers = int(os.environ.get('MAX_PARALLEL_WORKERS', 4))
        run_parallel = is_all and not sequential
        results_list = []

        if run_parallel:
            self.db_update_task_status(progress=15, message=f"üöÄ Parallel Execution: {max_workers} Workers ‡∏£‡∏±‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...")
            worker_args = [self._prepare_worker_tuple(s, document_map) for s in sub_criteria_list]
            try:
                ctx = multiprocessing.get_context('spawn')
                with ctx.Pool(processes=max_workers) as pool:
                    results_list = pool.map(_static_worker_process, worker_args)
            except Exception as e:
                self.db_update_task_status(progress=0, message=f"‚ùå ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {str(e)}", status="FAILED")
                raise
        else:
            vsm = vectorstore_manager or self._init_local_vsm()
            for idx, sub_criteria in enumerate(sub_criteria_list):
                curr_id = sub_criteria.get('sub_id', 'Unknown')
                curr_lv = sub_criteria.get('level', '?')
                
                # Dynamic Progress 15% -> 85%
                dynamic_progress = 15 + int((idx / total_tasks) * 70)
                self.db_update_task_status(
                    progress=dynamic_progress, 
                    message=f"üß† ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {curr_id} ‡∏£‡∏∞‡∏î‡∏±‡∏ö L{curr_lv} ({idx+1}/{total_tasks})..."
                )
                
                res = self._run_sub_criteria_assessment_worker(sub_criteria, vsm)
                results_list.append(res)

        # 4. üß© Step 4: Integration (Merge & Final Stats)
        self.db_update_task_status(progress=85, message="üß© ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• AI ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå Gap Analysis...")
        
        if results_list:
            for res in results_list:
                worker_data = res[0] if isinstance(res, tuple) else res
                worker_map = res[1] if isinstance(res, tuple) else res.get('temp_map_for_level', {})
                self._merge_worker_results(worker_data, worker_map)

            # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÅ‡∏•‡∏∞ Deduplicate
            merged_evidence = self.merge_evidence_mappings(results_list)
            self._update_internal_evidence_map(merged_evidence)

        # 5. üìä Step 5: Final Scoring Logic (Gatekeeper applied here)
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Maturity Level ‡∏à‡∏£‡∏¥‡∏á ‡πÇ‡∏î‡∏¢‡∏î‡∏π‡∏à‡∏≤‡∏Å Dependency (‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡πâ‡∏≤ L1 ‡∏ï‡∏Å ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô 0 ‡πÅ‡∏°‡πâ L2 ‡∏à‡∏∞‡∏ú‡πà‡∏≤‡∏ô)
        self._calculate_overall_stats(target_sub_id)
        
        # 6. üíæ Step 6: Persistence
        self.db_update_task_status(progress=95, message="üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÅ‡∏•‡∏∞ Export ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        try:
            self._save_evidence_map({"record_id": self.current_record_id, "evidence_map": self.evidence_map})
        except Exception as e:
            self.logger.error(f"‚ùå Persistence Error: {e}")

        # 7. üèÅ Step 7: Final Response
        final_response = {
            "record_id": self.current_record_id,
            "status": "COMPLETED",
            "summary": self.total_stats, # ‡∏à‡∏∞‡πÇ‡∏ä‡∏ß‡πå‡∏ú‡∏• Maturity ‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ä‡πá‡∏Ñ Dependency
            "sub_criteria_results": self.final_subcriteria_results, # ‡πÇ‡∏ä‡∏ß‡πå‡∏ú‡∏• L1-L5 ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π Gap
            "run_time_seconds": round(time.time() - start_ts, 2)
        }

        if export:
            final_response["export_path"] = self._export_results(self.final_subcriteria_results, target_sub_id)

        self.db_update_task_status(progress=100, message="‚úÖ ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå", status="COMPLETED")
        return final_response
    
    # ------------------------------------------------------------------------------------------
    # üöÄ CORE WORKER: Assessment Execution (FINAL v2026.1.26 - STABLE + ANTI-CRASH)
    # ------------------------------------------------------------------------------------------
    def _run_sub_criteria_assessment_worker(
        self,
        sub_criteria: Dict[str, Any],
        vectorstore_manager: Optional['VectorStoreManager'] = None
    ) -> Tuple[Dict[str, Any], Dict[str, List[Dict[str, Any]]]]:
        """
        [FINAL PRODUCTION v2026.1.26]
        - ‡πÅ‡∏Å‡πâ KeyError 'reason' ‡∏î‡πâ‡∏ß‡∏¢ .get() + fallback ‡∏ó‡∏∏‡∏Å field
        - ‡πÑ‡∏°‡πà cap sequential ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass/appeal (‡πÉ‡∏ä‡πâ max + override)
        - Robust unpack + fallback ‡∏ñ‡πâ‡∏≤ LLM return ‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö
        - Log ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô‡∏ó‡∏∏‡∏Å‡∏à‡∏∏‡∏î + trace force-pass levels
        - ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö L1-L5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠ full gap analysis
        - ‡∏ñ‡πâ‡∏≤ no evidences ‚Üí fallback dummy result (‡πÑ‡∏°‡πà crash)
        """
        MAX_RETRY_ATTEMPTS = 3
        sub_id = sub_criteria.get('sub_id', 'Unknown')
        sub_criteria_name = sub_criteria.get('sub_criteria_name', 'No Name')
        sub_weight = float(sub_criteria.get('weight', 0.0))
        
        current_enabler = getattr(self.config, 'enabler', 'Unknown')
        vsm = vectorstore_manager or getattr(self, 'vectorstore_manager', None)
        
        self.logger.info(f"[WORKER START] Enabler: {current_enabler} | Sub: {sub_id} | Name: {sub_criteria_name}")
        
        # --- [TRACKING STATES] ---
        current_sequential_pass_level = 0 
        found_primary_gap = False  
        force_pass_levels = []  
        raw_results_for_sub_seq: List[Dict[str, Any]] = []
        level_details_map = {} 
        current_worker_evidence_map = {} 
        start_ts = time.time() 

        all_rules_for_sub = getattr(self, 'contextual_rules_map', {}).get(sub_id, {})
        levels_to_assess = sorted(sub_criteria.get('levels', []), key=lambda x: x.get('level', 0))

        # -----------------------------------------------------------
        # EVALUATION LOOP (‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö L1-L5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠ gap analysis)
        # -----------------------------------------------------------
        for statement_data in levels_to_assess:
            level = statement_data.get('level')
            if level is None or level > getattr(self.config, 'target_level', 5):
                self.logger.debug(f"[SKIP] Sub {sub_id} L{level} > target_level")
                continue
            
            self.logger.info(f"[EVAL START] Enabler: {current_enabler} | Sub: {sub_id} | L{level}")
            
            level_result = {}
            for attempt_num in range(1, MAX_RETRY_ATTEMPTS + 1):
                try:
                    raw_res = self._run_single_assessment(
                        sub_criteria=sub_criteria,
                        statement_data=statement_data,
                        vectorstore_manager=vsm,
                        attempt=attempt_num,
                        record_id=self.current_record_id,
                        evidence_map=self.evidence_map,
                        **all_rules_for_sub.get(str(level), {})
                    )

                    # Robust unpack
                    if isinstance(raw_res, tuple) and len(raw_res) > 0:
                        level_result = raw_res[0] if isinstance(raw_res[0], dict) else {}
                    elif isinstance(raw_res, dict):
                        level_result = raw_res
                    else:
                        level_result = {}

                    # Fallback critical fields (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô KeyError)
                    level_result.setdefault("is_passed", False)
                    level_result.setdefault("score", 0.0)
                    level_result.setdefault("reason", "No reason provided from LLM")
                    level_result.setdefault("pdca_breakdown", {"P":0,"D":0,"C":0,"A":0})
                    level_result.setdefault("is_force_pass", False)

                    self.logger.info(f"[EVAL SUCCESS] Sub {sub_id} L{level} | Passed: {level_result['is_passed']} | Score: {level_result['score']}")
                    break
                except Exception as e:
                    self.logger.error(f"‚ùå [L{level} ATTEMPT {attempt_num}] Error: {str(e)}")
                    level_result = {
                        "level": level,
                        "is_passed": False,
                        "score": 0.0,
                        "reason": f"Evaluation failed after {attempt_num} attempts: {str(e)}",
                        "pdca_breakdown": {"P":0,"D":0,"C":0,"A":0},
                        "is_force_pass": False
                    }

            # --- [SEQUENTIAL GAP LOGIC - FIXED: ‡πÑ‡∏°‡πà cap ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass] ---
            is_passed_final = level_result.get('is_passed', False)
            is_force_pass = level_result.get('is_force_pass', False)

            if is_passed_final or is_force_pass:
                current_sequential_pass_level = max(current_sequential_pass_level, level)
                if is_force_pass:
                    force_pass_levels.append(level)
                display_status = "PASSED" + (" (Appeal/Safety-Net)" if is_force_pass else "")
                gap_type = "NONE"
            else:
                if not found_primary_gap:
                    found_primary_gap = True
                    display_status = "FAILED"
                    gap_type = "PRIMARY_GAP"
                else:
                    display_status = "FAILED (GAP)"
                    gap_type = "COMPOUND_GAP"

            level_result.update({
                "display_status": display_status,
                "gap_type": gap_type,
                "is_force_pass": is_force_pass
            })

            self.logger.info(f"[SEQ] Enabler:{current_enabler} Sub:{sub_id} L{level} | Passed: {is_passed_final} (Force: {is_force_pass}) | Highest now: {current_sequential_pass_level} | Gap: {gap_type}")

            # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≤‡∏¢‡πÄ‡∏•‡πÄ‡∏ß‡∏• (‡πÉ‡∏ä‡πâ .get() ‡∏ó‡∏∏‡∏Å‡∏à‡∏∏‡∏î)
            level_details_map[str(level)] = {
                "level": level,
                "is_passed": level_result.get('is_passed', False),
                "score": float(level_result.get('score', 0.0)),
                "pdca_breakdown": level_result.get('pdca_breakdown', {"P":0,"D":0,"C":0,"A":0}),
                "reason": level_result.get('reason', 'No reason'),
                "display_status": level_result.get("display_status", "UNKNOWN"),
                "gap_type": level_result.get("gap_type", "UNKNOWN"),
                "is_force_pass": level_result.get("is_force_pass", False)
            }
            raw_results_for_sub_seq.append(level_result)

        # -----------------------------------------------------------
        # FINAL SYNTHESIS + FORCE-MAX OVERRIDE
        # -----------------------------------------------------------
        weighted_score = round(self._calculate_weighted_score(current_sequential_pass_level, sub_weight), 2)

        # Force-max override ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ force-pass
        final_highest = current_sequential_pass_level
        if force_pass_levels:
            final_highest = max(final_highest, max(force_pass_levels or [0]))
            self.logger.info(f"[FORCE-MAX OVERRIDE] Detected force-pass levels {force_pass_levels} ‚Üí highest now L{final_highest}")

        action_plan_result = self._generate_action_plan_safe(sub_id, sub_criteria_name, current_enabler, raw_results_for_sub_seq)

        final_result = {
            "sub_id": sub_id,
            "sub_criteria_name": sub_criteria_name,
            "highest_full_level": final_highest,
            "weighted_score": weighted_score,

            
            "weight": sub_weight,
            "is_passed": final_highest >= 1,
            "force_pass_levels": force_pass_levels,
            "level_details": level_details_map,
            "action_plan": action_plan_result
        }

        self.logger.info(f"[WORKER END] Enabler: {current_enabler} | Sub: {sub_id} | Highest: L{final_highest} | Weighted: {weighted_score} | Force-Pass: {len(force_pass_levels)} levels {force_pass_levels}")

        return final_result, current_worker_evidence_map
    
# ==========================================================================================
# [SYSTEM CORE: AUDIT INTEGRITY ENGINE v2026.3.10]
# üö© ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô 11 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô (MANDATORY COMPONENTS - DO NOT REMOVE):
# 
# 1.  Dependency Gate        : [Pre-check] ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç Prerequisite ‡πÅ‡∏•‡∏∞‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ Level ‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
# 2.  Baseline Hydration     : [Context] ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Criteria Statement ‡πÅ‡∏•‡∏∞ Keyword Guide ‡∏£‡∏≤‡∏¢ Enabler
# 3.  Adaptive Retrieval     : [Strategy] ‡∏õ‡∏£‡∏±‡∏ö‡∏Å‡∏•‡∏¢‡∏∏‡∏ó‡∏ò‡πå‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Keyword vs Semantic) ‡∏ï‡∏≤‡∏°‡∏£‡∏∞‡∏î‡∏±‡∏ö Level
# 4.  Quality Gate           : [Clean] ‡∏Ñ‡∏±‡∏î‡∏Å‡∏£‡∏≠‡∏á Chunks ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ô‡∏±‡∏¢‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‡πÅ‡∏•‡∏∞‡∏à‡∏±‡∏î‡∏£‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
# 5.  Neighbor Expansion    : [Context] ‡∏î‡∏∂‡∏á‡∏ö‡∏£‡∏¥‡∏ö‡∏ó‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° (Sliding Window) ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≤‡∏î‡∏ï‡∏≠‡∏ô
# 6.  Hybrid Scoring         : [Ranking] ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á (Rerank + Keyword + PDCA Bonus)
# 7.  PDCA Blocking          : [NEW][Structure] ‡πÅ‡∏¢‡∏Å‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏´‡∏°‡∏ß‡∏î P, D, C, A ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
# 8.  Context Prioritization : [Strict] ‡∏à‡∏±‡∏î‡∏•‡∏≥‡∏î‡∏±‡∏ö PDCA Blocks ‡πÅ‡∏•‡∏∞‡∏â‡∏µ‡∏î Dynamic Guideline 
#                             ‡∏ú‡πà‡∏≤‡∏ô _get_level_constraint_prompt (Substance over Form)
# 9.  Dual-Round Evaluation  : [Reasoning] ‡∏£‡∏≠‡∏ö 1: Fact-Check ‡∏à‡∏≤‡∏Å Blocks | ‡∏£‡∏≠‡∏ö 2: Final Scoring
# 10. Expert Safety Net     : [Appeal] ‡∏£‡∏∞‡∏ö‡∏ö Re-evaluation ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡πÅ‡∏ï‡πà AI ‡πÉ‡∏´‡πâ‡∏ï‡∏Å
# 11. Persistence & Guard   : [Trace] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° Type-Guard ‡πÅ‡∏•‡∏∞ PDCA Frequency Injection
# ==========================================================================================

# ==========================================================================================
# [PERSISTENCE STRATEGY & ANTI-BLINDNESS RULES]
# üö© ‡∏Å‡∏é‡πÄ‡∏´‡∏•‡πá‡∏Å‡∏Ñ‡∏ß‡∏ö‡∏Ñ‡∏∏‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (v2026.3.10):
#
# - [Discovery Mandate] : ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô PDCA Blocks ‡∏´‡πâ‡∏≤‡∏° LLM ‡∏™‡∏£‡∏∏‡∏õ‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô" ‡πÄ‡∏î‡πá‡∏î‡∏Ç‡∏≤‡∏î
# - [Zero-Score Killer] : PDCA Breakdown ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏Å‡∏¥‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏ô‡∏±‡∏ö‡∏à‡∏£‡∏¥‡∏á (Frequency Count) ‡πÉ‡∏ô Code ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô 
#                         ‡∏´‡πâ‡∏≤‡∏°‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å AI Response ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
# - [Foundation Flex]   : ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1-L2 ‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏ö "‡∏£‡πà‡∏≠‡∏á‡∏£‡∏≠‡∏¢‡∏Å‡∏¥‡∏à‡∏Å‡∏£‡∏£‡∏°" (Existence) ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏ö‡∏ö
# - [Type Safety Guard] : ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• tagging_result (List/Dict) ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏µ‡∏¢‡∏Å .get() ‡πÄ‡∏™‡∏°‡∏≠
# - [Scoring Integrity] : ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô (P,D,C,A) ‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Extraction ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏ Source ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
# - [Traceability Log]  : ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÑ‡∏≠‡∏Ñ‡∏≠‡∏ô (‚úÖ:‡∏û‡∏ö, üî∑:AI-Detected, ‚ùå:‡πÑ‡∏°‡πà‡∏û‡∏ö) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Dashboard
# ==========================================================================================

    # ------------------------------------------------------------------------------------------
    # [MASTER ENGINE v2026.3.24 - ANTI-L0 + ROBUST PRODUCTION EDITION]
    # üß© ‡∏£‡∏∞‡∏ö‡∏ö‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô 11 ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô ‡∏û‡∏£‡πâ‡∏≠‡∏° PDCA Injection & Expert Safety Net
    # ------------------------------------------------------------------------------------------
    def _run_single_assessment(
        self,
        sub_criteria: Dict[str, Any],
        statement_data: Dict[str, Any],
        vectorstore_manager: Optional[Any],
        **kwargs
    ) -> Dict[str, Any]:
        """
        MASTER ENGINE: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏¢‡∏£‡∏∞‡∏î‡∏±‡∏ö‡πÅ‡∏ö‡∏ö‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
        Rev v2026.3.24:
        - ‡πÅ‡∏Å‡πâ PDCA Breakdown = 0 ‡∏î‡πâ‡∏ß‡∏¢ Frequency Injection ‡∏à‡∏≤‡∏Å audit_conf
        - ‡πÄ‡∏û‡∏¥‡πà‡∏° Anti-Zero-Chunks: ‡∏ñ‡πâ‡∏≤ top_chunks < 5 ‚Üí fallback ‡πÉ‡∏ä‡πâ baseline + top raw
        - ‡∏•‡∏î appeal threshold ‡πÄ‡∏õ‡πá‡∏ô 0.65 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ä‡πà‡∏ß‡∏¢ L1/L3 ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
        - ‡πÄ‡∏û‡∏¥‡πà‡∏° leniency boost ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1-L3 (‡∏ñ‡πâ‡∏≤ chunks ‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏ï‡πà score ‡∏ï‡πà‡∏≥ ‚Üí boost >=1.0)
        - Type-Guard + Fallback ‡∏ó‡∏∏‡∏Å‡∏à‡∏∏‡∏î + Log ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
        """
        start_time = time.time()
        
        # --- [PREPARATION & TYPE SAFETY] ---
        sub_id = str(sub_criteria.get('sub_id', 'Unknown'))
        level = int(statement_data.get('level', 1))
        name = str(sub_criteria.get('name', sub_criteria.get('sub_criteria_name', 'No Title')))
        stmt = str(statement_data.get('statement', f"‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏£‡∏∞‡∏î‡∏±‡∏ö {level}"))
        
        diverse_docs = []
        res = {"is_passed": False, "score": 0.0, "reason": "Initializing...", "pdca_breakdown": {"P":0,"D":0,"C":0,"A":0}}

        try:
            # --- STEP 1-2: Dependency & Baseline Check ---
            self.db_update_task_status(message=f"üîç [{sub_id} L{level}] ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏Å‡∏ì‡∏ë‡πå...")
            is_gap_run = False
            if hasattr(self, '_is_previous_level_passed') and not self._is_previous_level_passed(sub_id, level):
                is_gap_run = True
                self.db_update_task_status(message=f"‚ö†Ô∏è [{sub_id} L{level}] ‡∏û‡∏ö Gap (‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á)")

            # --- STEP 3-5: Adaptive Retrieval & Expansion ---
            self.db_update_task_status(message=f"üìÇ [{sub_id} L{level}] ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô (Adaptive)...")
            retrieval_res = self._perform_adaptive_retrieval(sub_id, level, stmt, vectorstore_manager)
            all_evidences, raw_max_score = (retrieval_res[0], retrieval_res[1]) if retrieval_res else ([], 0.0)
            
            diverse_docs = self._apply_diversity_filter(all_evidences, level) or []
            
            # Neighborhood expansion
            if hasattr(self, '_expand_context_with_neighbor_pages') and vectorstore_manager and raw_max_score > 0.35:
                diverse_docs = self._expand_context_with_neighbor_pages(diverse_docs, f"evidence_{self.enabler.lower()}")

            # --- STEP 6-7: Hybrid Scoring & Prioritization ---
            if diverse_docs:
                for doc in diverse_docs:
                    if not isinstance(doc, dict): continue
                    doc['final_relevance_score'] = self.relevance_score_fn(doc, sub_id, level) if hasattr(self, 'relevance_score_fn') else doc.get('rerank_score', 0)
                sorted_docs = sorted(diverse_docs, key=lambda d: d.get('final_relevance_score', 0), reverse=True)
            else:
                sorted_docs = []

            max_chunks = MAX_CHUNKS_LOW if level <= 2 else MAX_CHUNKS_HIGH
            top_chunks = sorted_docs[:max_chunks]

            # --- ANTI-ZERO-CHUNKS: Fallback ‡∏ñ‡πâ‡∏≤ top_chunks ‡∏ô‡πâ‡∏≠‡∏¢‡πÄ‡∏Å‡∏¥‡∏ô ---
            if len(top_chunks) < 5 and all_evidences:
                self.logger.warning(f"[ANTI-ZERO] Level {level} top_chunks={len(top_chunks)} ‚Üí fallback to top 10 raw + baseline")
                top_chunks = sorted(all_evidences, key=lambda d: d.get('rerank_score', 0), reverse=True)[:10]
                # ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡∏ô‡πâ‡∏≠‡∏¢ ‡πÉ‡∏´‡πâ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å baseline ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
                if len(top_chunks) < 5 and hasattr(self, 'baseline_chunks'):
                    top_chunks.extend(self.baseline_chunks.get(sub_id, [])[:5])

            # --- STEP 7.5: PDCA Blocking ---
            pdca_context_blocks = self._get_pdca_blocks_from_evidences(
                evidences=top_chunks, 
                baseline_evidences=None, 
                level=level, 
                sub_id=sub_id, 
                contextual_rules_map=getattr(self, 'contextual_rules_map', {})
            )
            
            prioritized_context = "\n".join([
                f"[‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô {i+1} | Rel: {d.get('final_relevance_score',0):.3f} | {d.get('source','Unknown')}]\n{d.get('text','')}\n{'-'*40}" 
                for i, d in enumerate(top_chunks)
            ]) if top_chunks else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏≠‡∏á"

            # --- STEP 8: LLM Evaluation ---
            self.db_update_task_status(message=f"üß† [{sub_id} L{level}] ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ AI ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå...")

            req_phases = self.get_rule_content(sub_id, level, "require_phase") or \
                        (['P','D'] if level <= 2 else (['P','D','C'] if level == 3 else ['P','D','C','A']))

            level_guideline = self._get_level_constraint_prompt(
                sub_id=sub_id, level=level, req_phases=req_phases,
                spec_rule=self._get_contextual_rules_prompt(sub_id, level)
            )

            audit_conf = self.calculate_audit_confidence(diverse_docs, sub_id=sub_id, level=level) or {}

            base_llm_params = {
                "context": prioritized_context, 
                "pdca_context": pdca_context_blocks, 
                "sub_criteria_name": name, 
                "level": level, 
                "statement_text": stmt,
                "sub_id": sub_id, 
                "llm_executor": self.llm, 
                "required_phases": req_phases,
                "ai_confidence": str(audit_conf.get('level', "MEDIUM")),
                "specific_contextual_rule": level_guideline, 
                "enabler_full_name": get_enabler_full_name(self.enabler, lang="th") if 'get_enabler_full_name' in globals() else self.enabler, 
                "enabler_code": self.enabler.upper()
            }

            eval_fn = evaluate_with_llm_low_level if level <= 2 else evaluate_with_llm
            res = eval_fn(**base_llm_params) or {"is_passed": False, "score": 0.0}

            # --- STEP 9: Expert Safety Net (Appeal Logic) ---
            is_appeal_granted = False
            if not res.get("is_passed", False) and raw_max_score >= 0.65:  # ‡∏•‡∏î threshold ‡∏à‡∏≤‡∏Å 0.75 ‚Üí ‡∏ä‡πà‡∏ß‡∏¢ L1/L3 ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô
                self.db_update_task_status(message=f"‚öñÔ∏è [{sub_id} L{level}] ‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà‡∏Å‡∏£‡∏∞‡∏ö‡∏ß‡∏ô‡∏Å‡∏≤‡∏£ Expert Re-evaluation...")
                appeal_result = self._run_expert_re_evaluation(
                    sub_id=sub_id, level=level, statement_text=stmt, context=prioritized_context,
                    first_attempt_reason=res.get("reason", "Fail"),
                    missing_tags=list(set(['P','D','C','A']) - set(audit_conf.get('pdca_found', []))),
                    highest_rerank_score=raw_max_score, sub_criteria_name=name,
                    llm_evaluator_to_use=eval_fn, base_kwargs=base_llm_params
                )
                if appeal_result and appeal_result.get("is_passed", False):
                    res = appeal_result
                    is_appeal_granted = True

            # --- STEP 10: PDCA Frequency Injection (Zero-Score Killer) ---
            raw_tags = audit_conf.get('pdca_found', [])
            if not isinstance(raw_tags, list): raw_tags = []
            
            real_pdca_breakdown = {
                "P": raw_tags.count("P"),
                "D": raw_tags.count("D"),
                "C": raw_tags.count("C"),
                "A": raw_tags.count("A")
            }

            # --- LENIENCY BOOST ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö L1-L3 (‡∏ñ‡πâ‡∏≤ chunks ‡πÄ‡∏¢‡∏≠‡∏∞‡πÅ‡∏ï‡πà score ‡∏ï‡πà‡∏≥) ---
            total_chunks = len(top_chunks)
            if level <= 3 and total_chunks >= 10 and res.get("score", 0) < 1.0:
                current_reason = res.get("reason", "‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å")
                res["score"] = max(res.get("score", 0), 1.0)
                res["reason"] = current_reason + f" (Leniency Boost: ‡∏û‡∏ö {total_chunks} chunks ‚Üí ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡πà‡∏≥ 1.0)"
                if not res.get("is_passed", False):
                    res["is_passed"] = True
                    res["reason"] += " (Auto-pass ‡∏î‡πâ‡∏ß‡∏¢ leniency)"

            # --- STEP 11: Persistence & Guard ---
            status_symbol = "‚úÖ" if res.get("is_passed") else "‚ùå"
            self.db_update_task_status(message=f"{status_symbol} [{sub_id} L{level}] ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå")
            
            final_strength = self._save_level_evidences_and_calculate_strength(diverse_docs, sub_id, level, res, raw_max_score)
            evidence_sources = self._resolve_evidence_filenames(diverse_docs)

            final_payload = {
                "sub_id": sub_id,
                "level": level,
                "is_passed": bool(res.get("is_passed", False)),
                "score": float(res.get("score", 0.0)),
                "pdca_breakdown": real_pdca_breakdown,
                "reason": res.get("reason", "No reason provided"),
                "is_force_pass": is_appeal_granted,
                "is_gap_run": is_gap_run, 
                "evidence_sources": evidence_sources, 
                "evidence_strength": final_strength, 
                "duration": round(time.time() - start_time, 2),
                "audit_confidence": audit_conf.get('level', 'N/A'),
                "coaching_insight": res.get("coaching_insight", "")
            }

            if not hasattr(self, 'assessment_results_map'): self.assessment_results_map = {}
            self.assessment_results_map[f"{sub_id}.L{level}"] = final_payload

            self._log_pdca_status(
                sub_id=sub_id, name=name, level=level, blocks=res, 
                req_phases=req_phases, sources_count=len(evidence_sources),
                score=final_payload["score"], conf_level=final_payload["audit_confidence"],
                tagging_result=raw_tags, is_safety_pass=is_appeal_granted
            )

            return final_payload

        except Exception as e:
            error_msg = f"üõë [SYSTEM ERROR L{level}] {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            self.db_update_task_status(message=error_msg)
            return {
                "sub_id": sub_id, "level": level, "score": 0.0, "is_passed": False, 
                "reason": f"System Failure: {str(e)}", "pdca_breakdown": {"P":0,"D":0,"C":0,"A":0}
            }