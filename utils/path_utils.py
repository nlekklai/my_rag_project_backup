# utils/path_utils.py
# Production Final Version â€“ 11 à¸˜.à¸„. 2568 (Path Matching Fixes)

import os
import json
import logging
import hashlib
import uuid
from datetime import datetime, timezone
from typing import Dict, Any, Optional, Tuple, Union, List
import unicodedata # NEW: à¹€à¸à¸´à¹ˆà¸¡ import à¸ªà¸³à¸«à¸£à¸±à¸šà¸à¸²à¸£à¸ˆà¸±à¸”à¸à¸²à¸£ Path/Filename encoding à¸šà¸™ macOS

# ğŸ“Œ ASSUME: config.global_vars à¸¡à¸µà¸à¸²à¸£à¸à¸³à¸«à¸™à¸”à¸„à¹ˆà¸²à¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡à¸•à¸²à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰
from config.global_vars import (
    DATA_STORE_ROOT,
    EVIDENCE_DOC_TYPES,
    DOCUMENT_ID_MAPPING_FILENAME_SUFFIX,
    EVIDENCE_MAPPING_FILENAME_SUFFIX,
    RUBRIC_FILENAME_PATTERN,
    EXPORTS_DIR,
    DEFAULT_TENANT,
    DEFAULT_YEAR,
    DEFAULT_ENABLER,
    PROJECT_NAMESPACE_UUID
)

logger = logging.getLogger(__name__)

# ==================== CORE HELPER ====================
def _n(s: Union[str, None]) -> str:
    """Normalize à¸—à¸¸à¸ string à¸”à¹‰à¸§à¸¢ NFKC â€“ à¹à¸à¹‰ macOS NFD bug à¸–à¸²à¸§à¸£ à¹à¸¥à¸°à¹à¸›à¸¥à¸‡à¹€à¸›à¹‡à¸™ clean key"""
    return unicodedata.normalize('NFKC', s.strip().lower().replace(" ", "_")) if isinstance(s, str) and s.strip() else ""

# ==================== INTERNAL BASE PATH ====================
def _build_tenant_base_path(tenant: str) -> str:
    tenant_clean = _n(tenant)
    return os.path.join(DATA_STORE_ROOT, tenant_clean, "data")

# ==================== 1. SOURCE PATHS ====================
def get_document_source_dir(
    tenant: str,
    year: Optional[Union[int, str]] = None,
    enabler: Optional[str] = None,
    doc_type: str = "",
) -> str:
    if not doc_type:
        raise ValueError("doc_type is required")
    base = _build_tenant_base_path(tenant)
    base = os.path.join(base, _n(doc_type))
    if _n(doc_type) == EVIDENCE_DOC_TYPES.lower():
        if year is not None:
            base = os.path.join(base, str(year))
        if enabler:
            base = os.path.join(base, _n(enabler))
    return base

def get_evidence_base_dir(tenant: str, year: Union[int, str], enabler: str) -> str:
    return get_document_source_dir(tenant, year, enabler, EVIDENCE_DOC_TYPES)

# ==================== 2. VECTORSTORE PATHS ====================
def get_doc_type_collection_key(doc_type: str, enabler: Optional[str] = None) -> str:
    dt = _n(doc_type)
    if dt == EVIDENCE_DOC_TYPES.lower():
        return f"{dt}_{_n(enabler or 'default')}"
    return dt

def get_vectorstore_collection_path(
    tenant: str, year: Optional[Union[int, str]], doc_type: str, enabler: Optional[str] = None
) -> str:
    parts = [DATA_STORE_ROOT, _n(tenant), "vectorstore"]
    if _n(doc_type) == EVIDENCE_DOC_TYPES.lower() and year is not None:
        parts.append(str(year))
    parts.append(get_doc_type_collection_key(doc_type, enabler))
    return os.path.join(*parts)

def get_vectorstore_tenant_root_path(tenant: str) -> str:
    return os.path.join(DATA_STORE_ROOT, _n(tenant), "vectorstore")

# ==================== 3. MAPPING FILES ====================
def get_mapping_file_path(
    doc_type: str,
    tenant: str,
    year: Optional[Union[int, str]] = None,
    enabler: Optional[str] = None
) -> str:
    """
    à¸ªà¸£à¹‰à¸²à¸‡ path à¸‚à¸­à¸‡ mapping file à¸•à¸²à¸¡à¸¡à¸²à¸•à¸£à¸à¸²à¸™à¹ƒà¸«à¸¡à¹ˆ (à¸˜.à¸„. 2568)

    - evidence â†’ /mapping/{year}/pea_{year}_{enabler}_doc_id_mapping.json
    - global doc_type â†’ /mapping/pea_{doc_type}_doc_id_mapping.json
      à¹€à¸Šà¹ˆà¸™:
        pea_seam_doc_id_mapping.json
        pea_document_doc_id_mapping.json
        pea_faq_doc_id_mapping.json
        pea_policy_doc_id_mapping.json

    à¹„à¸¡à¹ˆà¸¡à¸µ fallback à¸Šà¸·à¹ˆà¸­à¹€à¸à¹ˆà¸² (pea_doc_id_mapping.json) à¸­à¸µà¸à¸•à¹ˆà¸­à¹„à¸› â†’ à¸ªà¸°à¸­à¸²à¸” 100%
    """
    base = get_mapping_tenant_root_path(tenant)

    # === 1. Evidence: à¸•à¹‰à¸­à¸‡à¸¡à¸µ year + enabler à¹€à¸—à¹ˆà¸²à¸™à¸±à¹‰à¸™ ===
    if _n(doc_type) == EVIDENCE_DOC_TYPES.lower():
        if year is None:
            raise ValueError("Evidence doc_type à¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸ year")
        if not enabler:
            raise ValueError("Evidence doc_type à¸•à¹‰à¸­à¸‡à¸£à¸°à¸šà¸¸ enabler")
        return os.path.join(
            base,
            str(year),
            f"{_n(tenant)}_{year}_{_n(enabler)}{DOCUMENT_ID_MAPPING_FILENAME_SUFFIX}"
        )

    # === 2. Global doc_type: à¹ƒà¸Šà¹‰à¸Šà¸·à¹ˆà¸­à¹€à¸•à¹‡à¸¡à¹€à¸ªà¸¡à¸­ à¹„à¸¡à¹ˆà¸ªà¸™ year/enabler ===
    # à¹à¸¡à¹‰à¸ˆà¸°à¸ªà¹ˆà¸‡ year/enabler à¸¡à¸²à¸à¹‡à¸•à¸²à¸¡ â†’ à¸•à¹‰à¸­à¸‡à¹à¸¢à¸à¹„à¸Ÿà¸¥à¹Œà¸Šà¸±à¸”à¹€à¸ˆà¸™
    return os.path.join(
        base,
        f"{_n(tenant)}_{_n(doc_type)}{DOCUMENT_ID_MAPPING_FILENAME_SUFFIX}"
    )


def get_evidence_mapping_file_path(tenant: str, year: Union[int, str], enabler: str) -> str:
    # ğŸŸ¢ FIX: à¸ªà¸£à¹‰à¸²à¸‡ Path à¹‚à¸”à¸¢à¸•à¸£à¸‡ à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ EVIDENCE_MAPPING_FILENAME_SUFFIX
    #        (à¹à¸—à¸™à¸à¸²à¸£à¹€à¸£à¸µà¸¢à¸ get_mapping_file_path à¸—à¸µà¹ˆà¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¸œà¸´à¸”)
    
    # 1. à¹„à¸”à¹‰ Root Path à¸‚à¸­à¸‡ mapping/...
    base = get_mapping_tenant_root_path(tenant)
    
    # 2. à¸ªà¸£à¹‰à¸²à¸‡à¸Šà¸·à¹ˆà¸­à¹„à¸Ÿà¸¥à¹Œà¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡: pea_2568_km_evidence_mapping.json
    filename = f"{_n(tenant)}_{year}_{_n(enabler)}{EVIDENCE_MAPPING_FILENAME_SUFFIX}"
    
    # 3. à¸£à¸§à¸¡ Path: .../mapping/2568/pea_2568_km_evidence_mapping.json
    return os.path.join(
        base,
        str(year),
        filename
    )

def get_mapping_tenant_root_path(tenant: str) -> str:
    return os.path.join(DATA_STORE_ROOT, _n(tenant), "mapping")

# ==================== 4. LOAD / SAVE MAPPING ====================
def load_doc_id_mapping(doc_type: str, tenant: str, year: Optional[Union[int, str]], enabler: Optional[str] = None) -> Dict:
    path = get_mapping_file_path(doc_type, tenant, year, enabler)
    if not os.path.exists(path):
        return {}
    try:
        with open(path, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"Load mapping failed {path}: {e}")
        return {}

def save_doc_id_mapping(data: Dict, doc_type: str, tenant: str, year: Optional[Union[int, str]], enabler: Optional[str] = None):
    path = get_mapping_file_path(doc_type, tenant, year, enabler)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"Save mapping failed {path}: {e}")


# ==================== 6. PARSE COLLECTION NAME ====================
def parse_collection_name(collection_name: str) -> Tuple[str, Optional[str]]:
    name = _n(collection_name)
    if name.startswith(f"{EVIDENCE_DOC_TYPES.lower()}_"):
        parts = name.split("_", 1)
        if len(parts) == 2:
            return parts[0], parts[1]
    return name, None

# ==================== 7. DOCUMENT FILE PATH RESOLVER ====================
def get_document_file_path(
    document_uuid: str,
    tenant: str,
    year: Optional[Union[int, str]],
    enabler: Optional[str],
    doc_type_name: str
) -> Optional[Dict[str, str]]:
    
    try:
        mapping_path = get_mapping_file_path(doc_type_name, tenant, year, enabler)
        if not os.path.exists(mapping_path):
            logger.warning(f"Mapping file not found: {mapping_path}")
            return None

        with open(mapping_path, "r", encoding="utf-8") as f:
            mapping_data = json.load(f)

        entry = mapping_data.get(document_uuid)
        if not entry:
            logger.warning(f"UUID {document_uuid} not found in mapping")
            return None

        original_filepath_relative = entry.get("filepath")
        if not original_filepath_relative:
            logger.warning(f"No relative filepath in mapping for UUID {document_uuid}")
            return None

        # ğŸŸ¢ FIX: à¹ƒà¸Šà¹‰ os.path.join() à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸à¸­à¸š Path à¸‚à¸­à¸‡à¹„à¸Ÿà¸¥à¹Œà¸ˆà¸£à¸´à¸‡à¸ˆà¸²à¸ DATA_STORE_ROOT à¹à¸¥à¸° Path à¸ªà¸±à¸¡à¸à¸±à¸—à¸˜à¹Œ
        file_path_abs = os.path.join(DATA_STORE_ROOT, original_filepath_relative)

        if not os.path.exists(file_path_abs):
            logger.error(f"File not found on disk: {file_path_abs}")
            return None

        return {
            "file_path": file_path_abs,
            "original_filename": entry.get("file_name", os.path.basename(file_path_abs))
        }
    except Exception as e:
        logger.error(f"Error resolving document path for UUID {document_uuid}: {e}")
        return None

# ==================== 8. OTHER PATHS ====================
def get_config_tenant_root_path(tenant: str) -> str:
    """Path à¸ªà¸³à¸«à¸£à¸±à¸š Configuration Files à¸—à¸µà¹ˆà¸„à¸‡à¸—à¸µà¹ˆ à¹€à¸Šà¹ˆà¸™ Rubrics, Contextual Rules"""
    return os.path.join(DATA_STORE_ROOT, _n(tenant), "config")

def get_rubric_file_path(tenant: str, enabler: str) -> str:
    return os.path.join(get_config_tenant_root_path(tenant),
                        RUBRIC_FILENAME_PATTERN.format(tenant=_n(tenant), enabler=_n(enabler)))

def get_contextual_rules_file_path(tenant: str, enabler: str) -> str:
    return os.path.join(get_config_tenant_root_path(tenant),
                        f"{_n(tenant)}_{_n(enabler)}_contextual_rules.json")

def get_export_dir(tenant: str, year: Union[int, str], enabler: str) -> str:
    return os.path.join(DATA_STORE_ROOT, _n(tenant), "exports", str(year), _n(enabler))

def get_assessment_export_file_path(tenant: str, year: Union[int, str], enabler: str, suffix: str, ext: str = "json") -> str:
    return os.path.join(get_export_dir(tenant, year, enabler),
                        f"{_n(tenant)}_{year}_{_n(enabler)}_{suffix}.{ext.lower()}")

def get_normalized_metadata(doc_type: str, year_input=None, enabler_input=None, default_enabler=None):
    # Logic: Evidence à¸•à¹‰à¸­à¸‡à¸¡à¸µà¸›à¸µ/Enabler, Doc/Global à¹ƒà¸Šà¹‰ None
    return (None, None) if _n(doc_type) != EVIDENCE_DOC_TYPES.lower() else (year_input, enabler_input or default_enabler)

def resolve_filepath_to_absolute(path: str) -> str:
    """
    à¹à¸›à¸¥à¸‡ Path à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ Absolute Path à¹à¸¥à¸° Normalize (NFKC) à¹€à¸à¸·à¹ˆà¸­à¹à¸à¹‰à¸›à¸±à¸à¸«à¸² macOS
    """
    # 1. à¸—à¸³à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ Absolute Path
    abs_path = os.path.abspath(path)
    # 2. Normalize à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰ Path à¸—à¸µà¹ˆà¸¡à¸µà¸­à¸±à¸à¸‚à¸£à¸°à¸à¸´à¹€à¸¨à¸© (à¸ à¸²à¸©à¸²à¹„à¸—à¸¢) à¸¡à¸µà¸à¸²à¸£à¹€à¸‚à¹‰à¸²à¸£à¸«à¸±à¸ªà¸—à¸µà¹ˆà¸–à¸¹à¸à¸•à¹‰à¸­à¸‡
    return unicodedata.normalize('NFKC', abs_path)

# ==================== 9. EVIDENCE MAPPING ====================
def load_evidence_mapping(tenant=DEFAULT_TENANT, year=DEFAULT_YEAR, enabler=DEFAULT_ENABLER):
    path = get_evidence_mapping_file_path(tenant, year, enabler)
    return json.load(open(path, "r", encoding="utf-8")) if os.path.exists(path) else {}

def save_evidence_mapping(data, tenant=DEFAULT_TENANT, year=DEFAULT_YEAR, enabler=DEFAULT_ENABLER):
    path = get_evidence_mapping_file_path(tenant, year, enabler)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    json.dump(data, open(path, "w", encoding="utf-8"), ensure_ascii=False, indent=4)

# ==================== 10. UPDATE MAPPINGS ====================
def _update_doc_id_mapping(
    new_entries: Dict[str, Any],
    doc_type: str,
    tenant: str,
    year: Optional[Union[str, int]],
    enabler: Optional[str]
) -> None:
    try:
        existing_map = load_doc_id_mapping(doc_type, tenant, year, enabler)
    except FileNotFoundError:
        existing_map = {}
        
    existing_map.update(new_entries)
    save_doc_id_mapping(existing_map, doc_type, tenant, year, enabler)
    
    logger.info(f"Updated {len(new_entries)} entries in mapping for {doc_type} / {enabler or 'None'} / Year {year or 'None'}.")

def _update_evidence_mapping(
    new_entries: Dict[str, Any],
    tenant: str,
    year: Optional[Union[str, int]],
    enabler: Optional[str]
) -> None:
    _update_doc_id_mapping(
        new_entries=new_entries,
        doc_type=EVIDENCE_DOC_TYPES,
        tenant=tenant,
        year=year,
        enabler=enabler
    )

# ==================== 11. PATH KEY RESOLUTION (New Critical Logic) ====================
def get_mapping_key_from_physical_path(physical_path: str) -> str:
    """
    à¹à¸›à¸¥à¸‡ Physical Path (Absolute Path à¸—à¸µà¹ˆà¸ªà¹à¸à¸™à¹€à¸ˆà¸­) à¹ƒà¸«à¹‰à¹€à¸›à¹‡à¸™ Relative Key (format: tenant/data/doc_type/...) 
    à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰à¹ƒà¸™à¸à¸²à¸£à¸„à¹‰à¸™à¸«à¸²à¹ƒà¸™ Doc ID Mapping
    
    à¹ƒà¸Šà¹‰ NFKC normalization à¹à¸¥à¸° forward slashes ('/').
    """
    if not physical_path:
        return ""
    
    # ğŸ“Œ FIX 3: à¸–à¹‰à¸² Path à¸—à¸µà¹ˆà¸ªà¹ˆà¸‡à¹€à¸‚à¹‰à¸²à¸¡à¸²à¹€à¸›à¹‡à¸™ Path à¸ªà¸±à¸¡à¸à¸±à¸—à¸˜à¹Œà¸­à¸¢à¸¹à¹ˆà¹à¸¥à¹‰à¸§ (à¹€à¸Šà¹ˆà¸™ Path à¸ˆà¸²à¸ Mapping DB)
    if not os.path.isabs(physical_path):
        # à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ Path à¸ªà¸±à¸¡à¸à¸±à¸—à¸˜à¹Œ (à¹€à¸«à¸¡à¸·à¸­à¸™à¹ƒà¸™ Mapping) à¹ƒà¸«à¹‰ Normalize à¹à¸¥à¸°à¸„à¸·à¸™à¸„à¹ˆà¸²à¹€à¸¥à¸¢
        relative_key = unicodedata.normalize('NFKC', physical_path).replace('\\', '/')
        return relative_key
        
    # 2. à¸–à¹‰à¸²à¹€à¸›à¹‡à¸™ Absolute Path (à¸¡à¸²à¸ˆà¸²à¸ os.walk à¸«à¸£à¸·à¸­à¸à¸²à¸£à¸ªà¹à¸à¸™)
    
    # ğŸŸ¢ à¹ƒà¸Šà¹‰ resolve_filepath_to_absolute à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹à¸™à¹ˆà¹ƒà¸ˆà¸§à¹ˆà¸²à¹„à¸”à¹‰ NFKC-normalized Absolute Path
    normalized_abs_path = resolve_filepath_to_absolute(physical_path)
    
    # 3. Normalize DATA_STORE_ROOT
    normalized_abs_data_store_root = resolve_filepath_to_absolute(os.path.abspath(DATA_STORE_ROOT))

    # 4. Get Path relative to DATA_STORE_ROOT
    try:
        relative_path = os.path.relpath(normalized_abs_path, normalized_abs_data_store_root)
    except ValueError as e:
        logger.debug(f"Error getting relative path for {physical_path}: {e}")
        return ""

    # 5. Use forward slashes for the final key format and ensure it doesn't start with '..'
    relative_key = relative_path.replace('\\', '/')
    
    # Safety check: à¸–à¹‰à¸² Path à¸­à¸¢à¸¹à¹ˆà¸™à¸­à¸ Root
    if relative_key.startswith('..'):
         logger.debug(f"File path is outside DATA_STORE_ROOT after relpath: {physical_path}")
         return ""
         
    return relative_key

# OTHER PATHS à¹€
def get_tenant_year_export_root(tenant: str, year: Union[int, str]) -> str:
    """à¸„à¸·à¸™à¸„à¹ˆà¸² Path à¸£à¸°à¸”à¸±à¸šà¸›à¸µ (Root à¸‚à¸­à¸‡ exports) à¹€à¸à¸·à¹ˆà¸­à¹ƒà¸Šà¹‰à¸§à¸™à¸«à¸²à¹„à¸Ÿà¸¥à¹Œà¹ƒà¸™à¸—à¸¸à¸ Enabler"""
    return os.path.join(DATA_STORE_ROOT, _n(tenant), "exports", str(year))
# ==================== à¸ˆà¸š utils/path_utils.py ====================

# utils/path_utils.py (à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡)

def get_tenant_year_report_root(tenant: str, year: Union[int, str], enabler: str = None) -> str:
    """
    à¸ªà¸£à¹‰à¸²à¸‡à¹à¸¥à¸°à¸ªà¹ˆà¸‡à¸„à¸·à¸™ Path à¸ªà¸³à¸«à¸£à¸±à¸šà¹€à¸à¹‡à¸šà¹„à¸Ÿà¸¥à¹Œà¸£à¸²à¸¢à¸‡à¸²à¸™ (Reports)
    à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡: data_store/<tenant>/reports/<year>/<enabler>
    """
    base_dir = os.path.join("data_store", _n(tenant), "reports", str(year))
    if enabler:
        base_dir = os.path.join(base_dir, _n(enabler))
    
    if not os.path.exists(base_dir):
        os.makedirs(base_dir, exist_ok=True)
    return base_dir