# -*- coding: utf-8 -*-
# routers/assessment_router.py
# Production Final Version - 2026 Optimized for DB Persistence & Professional Reporting

import os
import re
import uuid
import json
import asyncio
import logging
import mimetypes
import tempfile
import pytz
from datetime import datetime
from typing import Optional, Dict, Any, Union, List

from fastapi import APIRouter, BackgroundTasks, HTTPException, Depends, Query
from fastapi.responses import FileResponse
from pydantic import BaseModel

# --- Docx Imports (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á Report) ---
from docx import Document
from docx.shared import Pt, RGBColor, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn, nsdecls
from docx.oxml import parse_xml

# --- Project Imports ---
from routers.auth_router import get_current_user, check_user_permission, UserMe
from utils.path_utils import (
    _n, 
    get_tenant_year_export_root, 
    load_doc_id_mapping, 
    get_document_file_path,
    get_vectorstore_collection_path,
    get_vectorstore_tenant_root_path
)

from core.seam_assessment import SEAMPDCAEngine, AssessmentConfig
from core.vectorstore import load_all_vectorstores
from models.llm import create_llm_instance
from config.global_vars import (
    EVIDENCE_DOC_TYPES, 
    DEFAULT_LLM_MODEL_NAME, 
    DEFAULT_YEAR, 
    DEFAULT_TENANT,
    DATA_STORE_ROOT
)

# üéØ Database Components (SQLite Persistence)
from database import (
    SessionLocal, 
    AssessmentTaskTable, 
    AssessmentResultTable,
    db_update_task_status,
    db_finish_task
)

MAX_CONCURRENT_TASKS = 4 
assessment_semaphore = asyncio.Semaphore(MAX_CONCURRENT_TASKS)


# ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Logger ‡πÅ‡∏•‡∏∞ Router
logger = logging.getLogger(__name__)
assessment_router = APIRouter(prefix="/api/assess", tags=["Assessment"])

# --- Request Models ---
class StartAssessmentRequest(BaseModel):
    tenant: str
    year: Optional[Union[int, str]] = None
    enabler: str = "KM"
    sub_criteria: Optional[str] = "all"
    sequential_mode: bool = False

# ------------------------------------------------------------------
# [Helpers]
# ------------------------------------------------------------------
def parse_safe_date(raw_date_str: Any, file_path: str) -> str:
    """‡πÅ‡∏õ‡∏•‡∏á‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏≤‡∏Å String ‡∏´‡∏£‡∏∑‡∏≠ File Metadata ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô ISO Format (Bangkok Time)"""
    tz = pytz.timezone('Asia/Bangkok')
    if raw_date_str and isinstance(raw_date_str, str):
        try:
            # ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö format yyyymmdd_hhmmss
            if "_" in raw_date_str:
                dt = datetime.strptime(raw_date_str, "%Y%m%d_%H%M%S")
                return tz.localize(dt).isoformat()
        except: pass
    
    # Fallback: ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    try:
        mtime = os.path.getmtime(file_path)
        dt = datetime.fromtimestamp(mtime, tz)
        return dt.isoformat()
    except:
        return datetime.now(tz).isoformat()


def safe_float(value):
    try:
        if isinstance(value, str):
            value = value.replace('%', '') # ‡∏•‡∏ö % ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
        return float(value)
    except:
        return 0.0
    

@assessment_router.get("/evidence/{doc_type}/{document_uuid}")
async def serve_evidence_file(
    document_uuid: str,
    doc_type: str,
    tenant: str,
    year: str = None,
    enabler: str = None,
    current_user: UserMe = Depends(get_current_user)
):
    check_user_permission(current_user, tenant, enabler or "KM")

    file_info = get_document_file_path(
        document_uuid=document_uuid,
        tenant=tenant,
        year=year,
        enabler=enabler,
        doc_type_name=doc_type
    )

    if not file_info:
        raise HTTPException(status_code=404, detail="File not found")

    file_path = file_info["file_path"]
    
    # ‡∏î‡∏∂‡∏á‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå
    ext = os.path.splitext(file_path)[1].lower()
    
    # üõ°Ô∏è Force MIME Type ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac/Safari
    mime_map = {
        ".pdf": "application/pdf",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
    }
    
    mime_type = mime_map.get(ext) or mimetypes.guess_type(file_path)[0] or "application/octet-stream"

    # ‡∏™‡πà‡∏á FileResponse
    response = FileResponse(
        path=file_path,
        media_type=mime_type,
        content_disposition_type="inline"
    )

    # üí° ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac/Safari:
    # 1. ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ Browser ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Path ‡∏ã‡∏∂‡πà‡∏á‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡πÉ‡∏´‡πâ Header ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
    # 2. ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö Header ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    response.headers["Content-Type"] = mime_type
    response.headers["Accept-Ranges"] = "bytes" 
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô PDF ‡∏ö‡∏ô Mac ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° Cache-Control ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Viewer ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
    if ext == ".pdf":
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"

    return response


@assessment_router.get("/view-document")
async def view_document(
    filename: str, 
    document_uuid: Optional[str] = None, 
    current_user: UserMe = Depends(get_current_user)
):
    """ Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡πÇ‡∏î‡∏¢‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏∂‡πâ‡∏ô """
    
    file_path = None

    # 1. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏´‡∏≤‡∏à‡∏≤‡∏Å UUID ‡∏Å‡πà‡∏≠‡∏ô (‡∏î‡∏µ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ 100% ‡πÅ‡∏°‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏∞‡∏ã‡πâ‡∏≥)
    if document_uuid:
        file_info = get_document_file_path(
            document_uuid=document_uuid,
            tenant=current_user.tenant,
            year=current_user.year,
            enabler="KM", # ‡∏´‡∏£‡∏∑‡∏≠‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å Query Param
            doc_type_name="evidence"
        )
        if file_info:
            file_path = file_info["file_path"]

    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ UUID ‡πÉ‡∏´‡πâ‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
    if not file_path:
        # ‡πÉ‡∏ä‡πâ get_document_source_dir ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ‡πÉ‡∏ô path_utils ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
        from utils.path_utils import get_document_source_dir, resolve_filepath_to_absolute
        
        base_path = get_document_source_dir(
            tenant=current_user.tenant,
            year=current_user.year,
            enabler="KM",
            doc_type="evidence"
        )
        file_path = resolve_filepath_to_absolute(os.path.join(base_path, filename))

    if not file_path or not os.path.exists(file_path):
        logger.error(f"‚ùå File not found: {file_path}")
        raise HTTPException(status_code=404, detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ö‡∏ô‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå")

    # ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå PDF ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ
    return FileResponse(file_path, media_type="application/pdf")


def _transform_result_for_ui(raw_data: Dict[str, Any], current_user: Any = None) -> Dict[str, Any]:
    if not raw_data or not isinstance(raw_data, dict):
        return {"status": "FAILED", "message": "Invalid data format"}

    # --- [0] RESOLVE CORE DATA ---
    res = raw_data.get("result") or raw_data.get("assessment_result") or raw_data
    metadata = res.get("metadata", {})
    summary = res.get("summary") or res.get("result_summary", {})
    global_evidence_map = raw_data.get("evidence_map") or res.get("evidence_map") or {}

    # --- [1] ENABLER ROADMAP ---
    raw_global_roadmap = res.get("enabler_roadmap") or res.get("strategic_roadmap") or {}
    ui_global_roadmap = {
        "status": raw_global_roadmap.get("status", "SUCCESS"),
        "overall_strategy": raw_global_roadmap.get("overall_strategy") or "‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô SE-AM",
        "phases": raw_global_roadmap.get("phases") or []
    }

    # --- [2] SUB-CRITERIA PROCESSING ---
    processed = []
    radar_data = []
    sub_list = res.get("sub_criteria_details") or res.get("sub_criteria_results") or []

    for sub in sub_list:
        sub_id = str(sub.get("sub_id", "N/A"))
        lv_details = sub.get("level_details", {}) or {}
        
        sub_roadmap_data = sub.get("sub_roadmap") or {}
        ui_sub_roadmap = {
            "strategy": sub_roadmap_data.get("overall_strategy") or sub.get("strategic_focus", ""),
            "phases": sub_roadmap_data.get("phases") or [],
            "is_gap_detected": sub_roadmap_data.get("is_gap_detected", False)
        }

        ui_levels = {}
        pdca_matrix = []
        pdca_coverage = {}
        grouped_sources = {str(i): [] for i in range(1, 6)}
        
        # üö© FIX ISSUE 2: ‡∏¢‡πâ‡∏≤‡∏¢ pool ‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡πÄ‡∏û‡∏∑‡πà‡∏≠ Reset ‡∏Ñ‡πà‡∏≤‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏Ç‡∏∂‡πâ‡∏ô Sub-criteria ‡πÉ‡∏´‡∏°‡πà (‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡∏Ç‡∏ö‡∏ß‡∏°)
        sub_conf_pool = {} 

        for lv in range(1, 6):
            k = str(lv)
            info = lv_details.get(k, {}) or {}
            is_passed = bool(info.get("is_passed", False))
            level_key = f"{sub_id}_L{lv}"
            
            # üéØ 1. Resolve Evidence Sources
            sources = info.get("evidence_sources") or info.get("evidences") or []
            if not sources and level_key in global_evidence_map:
                ext_ev = global_evidence_map[level_key]
                sources = [ext_ev] if isinstance(ext_ev, dict) else ext_ev

            # üéØ 2. PDCA Sync
            req_phases = info.get("required_pdca_phases", []) or ["P"]
            actual_found_tags = set()

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ sources ‡πÄ‡∏õ‡πá‡∏ô list ‡∏Å‡πà‡∏≠‡∏ô loop
            current_sources = sources if isinstance(sources, list) else []

            for src in current_sources:
                if not isinstance(src, dict): continue

                fname = str(src.get("filename") or src.get("file") or src.get("source") or "‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
                
                # üö© FIX: Confidence Extraction
                raw_val = None
                if "|SCORE:" in fname:
                    try: raw_val = float(fname.split("SCORE:")[-1])
                    except: pass
                
                if raw_val is None:
                    raw_val = src.get("rerank_score") or src.get("relevance_score") or src.get("confidence")

                try:
                    conf_val = float(raw_val) if raw_val is not None else 0.5
                    if 0 < conf_val <= 1.0: conf_val *= 100
                except: conf_val = 50.0
                
                clean_fname = fname.split("|")[0]
                # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏£‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå
                sub_conf_pool[clean_fname] = max(conf_val / 100, sub_conf_pool.get(clean_fname, 0))

                # üö© FIX: PDCA Tag ‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏°‡∏≤‡πÉ‡∏™‡πà‡πÉ‡∏ô Object ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ UI
                tag = str(src.get("pdca_tag") or src.get("pdca") or "D").upper()
                if tag not in ["P", "D", "C", "A"]: tag = "D"
                actual_found_tags.add(tag)

                grouped_sources[k].append({
                    "filename": clean_fname,
                    "document_uuid": src.get("stable_doc_uuid") or src.get("doc_id"),
                    "page": str(src.get("page", "1")),
                    "pdca_tag": tag, # üö© ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà UI ‡∏ô‡∏≥‡πÑ‡∏õ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
                    "confidence": round(conf_val, 1),
                    "text": src.get("content") or src.get("snippet") or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"
                })

            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Coverage
            actual_passed_phases = [p for p in req_phases if p in actual_found_tags]
            calc_percentage = (len(actual_passed_phases) / len(req_phases)) * 100 if req_phases else 0

            pdca_coverage[k] = {
                "percentage": round(calc_percentage, 1),
                "statement": info.get("rubric_statement") or "",
                "required_phases": req_phases,
                "actual_phases": list(actual_found_tags),
                "status": "PASS" if calc_percentage >= 100 else "GAP"
            }

            ui_levels[k] = {
                "level": lv, 
                "is_passed": is_passed,
                "score": round(float(info.get("score") or (1.0 if is_passed else 0.0)), 2),
                "reason": info.get("reason", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"),
                "coaching_insight": info.get("coaching_insight", ""),
                "action_plan": info.get("action_plan") or info.get("atomic_action_plan", [])
            }
    
            pdca_matrix.append({
                "level": lv, 
                "is_passed": is_passed,
                "pdca": {p: (1 if p in actual_found_tags else 0) for p in ["P", "D", "C", "A"]}
            })

        # --- [4] FINAL ASSEMBLY ---
        # üö© FIX: ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Traceability ‡∏à‡∏≤‡∏Å Pool ‡∏Ç‡∏≠‡∏á‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥)
        if sub_conf_pool:
            avg_conf_total = sum(sub_conf_pool.values()) / len(sub_conf_pool)
            final_traceability = min(avg_conf_total * 100, 100)
        else:
            final_traceability = 0

        processed.append({
            "code": sub_id,
            "name": sub.get("sub_criteria_name", "Unknown"),
            "level": f"L{sub.get('highest_full_level', 0)}",
            "score": round(float(sub.get("weighted_score", 0.0)), 2),
            "strategic_focus": sub.get("strategic_focus", ""),
            "sub_roadmap": ui_sub_roadmap,
            "pdca_matrix": pdca_matrix,
            "pdca_coverage": pdca_coverage,
            "level_details": ui_levels,
            "grouped_sources": grouped_sources,
            "audit_confidence": {
                "source_count": len(sub_conf_pool),
                "traceability_score": round(final_traceability, 1)
            }
        })
        radar_data.append({"axis": sub_id, "value": sub.get("highest_full_level", 0)})

    try:
        processed.sort(key=lambda x: [int(p) for p in x["code"].split(".") if p.isdigit()])
    except: pass
    
    return {
        "status": summary.get("status", "COMPLETED"),
        "record_id": metadata.get("record_id") or raw_data.get("record_id"),
        "tenant": metadata.get("tenant", "n/a"),
        "year": metadata.get("year", "2567"),
        "enabler": metadata.get("enabler") or raw_data.get("enabler"),
        "level": str(summary.get("overall_max_level") or summary.get("maturity_level") or "0").replace("L", ""),
        "score": round(float(summary.get("total_weighted_score") or 0.0), 2),
        "enabler_roadmap": ui_global_roadmap,
        "radar_data": radar_data,
        "sub_criteria": processed
    }

# def _transform_result_for_ui(raw_data: Dict[str, Any], current_user: Any = None) -> Dict[str, Any]:
#     if not raw_data or not isinstance(raw_data, dict):
#         return {"status": "FAILED", "message": "Invalid data format"}

#     # --- [0] RESOLVE CORE DATA ---
#     res = raw_data.get("result") or raw_data.get("assessment_result") or raw_data
#     metadata = res.get("metadata", {})
#     summary = res.get("summary") or res.get("result_summary", {})
#     global_evidence_map = raw_data.get("evidence_map") or res.get("evidence_map") or {}

#     # --- [1] ENABLER ROADMAP ---
#     raw_global_roadmap = res.get("enabler_roadmap") or res.get("strategic_roadmap") or {}
#     ui_global_roadmap = {
#         "status": raw_global_roadmap.get("status", "SUCCESS"),
#         "overall_strategy": raw_global_roadmap.get("overall_strategy") or "‡∏°‡∏∏‡πà‡∏á‡πÄ‡∏ô‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô SE-AM",
#         "phases": raw_global_roadmap.get("phases") or []
#     }

#     # --- [2] SUB-CRITERIA PROCESSING ---
#     processed = []
#     radar_data = []
#     sub_list = res.get("sub_criteria_details") or res.get("sub_criteria_results") or []

#     for sub in sub_list:
#         sub_id = str(sub.get("sub_id", "N/A"))
#         lv_details = sub.get("level_details", {}) or {}
        
#         ui_sub_roadmap = {
#             "strategy": (sub.get("sub_roadmap") or {}).get("overall_strategy") or sub.get("strategic_focus", ""),
#             "phases": (sub.get("sub_roadmap") or {}).get("phases") or [],
#             "is_gap_detected": (sub.get("sub_roadmap") or {}).get("is_gap_detected", False)
#         }

#         ui_levels = {}
#         pdca_matrix = []
#         pdca_coverage = {}
#         grouped_sources = {str(i): [] for i in range(1, 6)}
        
#         # üö© ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Traceability ‡∏ó‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
#         sub_conf_pool = {} 

#         for lv in range(1, 6):
#             k = str(lv)
#             info = lv_details.get(k, {}) or {}
#             is_passed = bool(info.get("is_passed", False))
#             level_key = f"{sub_id}_L{lv}"
            
#             # üéØ 1. Resolve Evidence Sources
#             sources = info.get("evidence_sources") or info.get("evidences") or []
#             if not sources and level_key in global_evidence_map:
#                 ext_ev = global_evidence_map[level_key]
#                 sources = [ext_ev] if isinstance(ext_ev, dict) else ext_ev

#             # üéØ 2. PDCA Sync - ‡∏™‡∏£‡πâ‡∏≤‡∏á Set ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠‡πÉ‡∏ô Level ‡∏ô‡∏µ‡πâ
#             req_phases = info.get("required_pdca_phases", []) or ["P"]
#             actual_found_tags = set()

#             for src in sources:
#                 # Resolve Filename & Score
#                 fname = str(src.get("filename") or src.get("file") or src.get("source") or "‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
                
#                 # üö© FIX ISSUE 3: Confidence Extraction (‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å SCORE:0.xxxx)
#                 raw_val = None
#                 if "|SCORE:" in fname:
#                     try:
#                         raw_val = float(fname.split("SCORE:")[-1])
#                     except: pass
                
#                 # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏î‡∏π‡∏ó‡∏µ‡πà Key ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô
#                 if raw_val is None:
#                     raw_val = src.get("rerank_score") or src.get("relevance_score") or src.get("confidence")

#                 try:
#                     conf_val = float(raw_val) if raw_val is not None else 0.5
#                     # ‡∏ñ‡πâ‡∏≤‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô 0.75 ‡πÉ‡∏´‡πâ‡∏Ñ‡∏π‡∏ì 100 ‡πÄ‡∏õ‡πá‡∏ô 75.0
#                     if 0 < conf_val <= 1.0: conf_val *= 100
#                 except:
#                     conf_val = 50.0
                
#                 clean_fname = fname.split("|")[0]
#                 # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏£‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå (Scale 0-1)
#                 sub_conf_pool[clean_fname] = max(conf_val / 100, sub_conf_pool.get(clean_fname, 0))

#                 # ‡∏™‡∏Å‡∏±‡∏î PDCA Tag
#                 tag = str(src.get("pdca_tag") or src.get("pdca") or "D").upper()
#                 if tag not in ["P", "D", "C", "A"]: tag = "D"
#                 actual_found_tags.add(tag)

#                 grouped_sources[k].append({
#                     "filename": clean_fname,
#                     "document_uuid": src.get("stable_doc_uuid") or src.get("doc_id"),
#                     "page": str(src.get("page", "1")),
#                     "pdca_tag": tag,
#                     "confidence": round(conf_val, 1),
#                     "text": src.get("content") or src.get("snippet") or "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°"
#                 })

#             # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Coverage
#             actual_passed_phases = [p for p in req_phases if p in actual_found_tags]
#             calc_percentage = (len(actual_passed_phases) / len(req_phases)) * 100 if req_phases else 0

#             pdca_coverage[k] = {
#                 "percentage": round(calc_percentage, 1),
#                 "statement": info.get("rubric_statement") or "",
#                 "required_phases": req_phases,
#                 "actual_phases": list(actual_found_tags),
#                 "status": "PASS" if calc_percentage >= 100 else "GAP"
#             }

#             ui_levels[k] = {
#                 "level": lv, 
#                 "is_passed": is_passed,
#                 "score": round(float(info.get("score") or (1.0 if is_passed else 0.0)), 2),
#                 "reason": info.get("reason", "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô"),
#                 "coaching_insight": info.get("coaching_insight", ""),
#                 "action_plan": info.get("action_plan") or info.get("atomic_action_plan", [])
#             }
    
#             # üö© FIX ISSUE 1: PDCA Matrix ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà Required)
#             pdca_matrix.append({
#                 "level": lv, 
#                 "is_passed": is_passed,
#                 "pdca": {p: (1 if p in actual_found_tags else 0) for p in ["P", "D", "C", "A"]}
#             })

#         # --- [4] FINAL ASSEMBLY ---
#         # üö© FIX ISSUE 2: Traceability Score (‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏±‡πà‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô)

#         if sub_conf_pool:
#             avg_conf_total = sum(sub_conf_pool.values()) / len(sub_conf_pool)
#             final_traceability = min(avg_conf_total * 100, 100)
#         else:
#             final_traceability = 0

#         processed.append({
#             "code": sub_id,
#             "name": sub.get("sub_criteria_name", "Unknown"),
#             "level": f"L{sub.get('highest_full_level', 0)}",
#             "score": round(float(sub.get("weighted_score", 0.0)), 2),
#             "strategic_focus": sub.get("strategic_focus", ""),
#             "sub_roadmap": ui_sub_roadmap,
#             "pdca_matrix": pdca_matrix,
#             "pdca_coverage": pdca_coverage,
#             "level_details": ui_levels,
#             "grouped_sources": grouped_sources,
#             "audit_confidence": {
#                 "source_count": len(sub_conf_pool),
#                 "traceability_score": round(final_traceability, 1)
#             }
#         })
#         radar_data.append({"axis": sub_id, "value": sub.get("highest_full_level", 0)})

#     try:
#         processed.sort(key=lambda x: [int(p) for p in x["code"].split(".") if p.isdigit()])
#     except: pass
    
#     return {
#         "status": summary.get("status", "COMPLETED"),
#         "record_id": metadata.get("record_id") or raw_data.get("record_id"),
#         "tenant": metadata.get("tenant", "n/a"),
#         "year": metadata.get("year", "2567"),
#         "enabler": metadata.get("enabler") or raw_data.get("enabler"),
#         "level": str(summary.get("overall_max_level") or summary.get("maturity_level") or "0").replace("L", ""),
#         "score": round(float(summary.get("total_weighted_score") or 0.0), 2),
#         "enabler_roadmap": ui_global_roadmap,
#         "radar_data": radar_data,
#         "sub_criteria": processed
#     }

def set_thai_font(run, size=14, bold=False, color=None):
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ü‡∏≠‡∏ô‡∏ï‡πå TH Sarabun New ‡πÉ‡∏´‡πâ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©"""
    run.font.name = 'TH Sarabun New'
    # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ XML ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡πÉ‡∏ä‡πâ TH Sarabun New ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏≠‡∏±‡∏Å‡∏Ç‡∏£‡∏∞‡∏û‡∏¥‡πÄ‡∏®‡∏©‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
    run._element.rPr.rFonts.set(qn('w:eastAsia'), 'TH Sarabun New')
    run._element.rPr.rFonts.set(qn('w:ascii'), 'TH Sarabun New')
    run._element.rPr.rFonts.set(qn('w:hAnsi'), 'TH Sarabun New')
    run.font.size = Pt(size)
    run.bold = bold
    if color:
        run.font.color.rgb = color

def set_cell_background(cell, fill_color):
    """‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏™‡∏µ‡∏û‡∏∑‡πâ‡∏ô‡∏´‡∏•‡∏±‡∏á‡πÉ‡∏´‡πâ Cell ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á (fill_color ‡∏Ñ‡∏∑‡∏≠ hex code ‡πÄ‡∏ä‡πà‡∏ô 'D9EAD3')"""
    shading_elm = parse_xml(f'<w:shd {nsdecls("w")} w:fill="{fill_color}"/>')
    cell._tc.get_or_add_tcPr().append(shading_elm)


def create_docx_report_similar_to_ui(ui_data: dict) -> Document:
    """
    [v2026.FINAL - Revised for level_details structure]
    ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô Word ‡πÇ‡∏î‡∏¢‡∏≠‡∏¥‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å UI-Ready JSON ‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô‡∏Å‡∏≤‡∏£ transform ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
    """
    doc = Document()
    
    # 1. ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô (Header)
    header = doc.add_paragraph()
    header.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run_h = header.add_run(f"‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Maturity Audit ({ui_data.get('enabler', 'KM')})\n")
    set_thai_font(run_h, size=20, bold=True, color=RGBColor(30, 58, 138))

    # 2. ‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏£‡∏∏‡∏õ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏° (Overall Summary)
    maturity_lv = str(ui_data.get('level', '0'))
    total_score = ui_data.get('score', 0)
    full_score = ui_data.get('full_score', 5)
    metrics = ui_data.get('metrics', {})

    sum_p = doc.add_paragraph()
    sum_p.alignment = WD_ALIGN_PARAGRAPH.CENTER
    run_sum = sum_p.add_run(
        f"‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ß‡∏∏‡∏í‡∏¥‡∏†‡∏≤‡∏ß‡∏∞: L{maturity_lv} | ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏ß‡∏°: {total_score}/{full_score} "
        f"({metrics.get('completion_rate', 0)}% ‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢)"
    )
    set_thai_font(run_sum, size=16, bold=True, color=RGBColor(22, 101, 52))

    # 3. ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏£‡∏≤‡∏¢‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ (Sub-Criteria)
    for item in ui_data.get('sub_criteria', []):
        # ‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡πÄ‡∏Å‡∏ì‡∏ë‡πå
        doc.add_paragraph() 
        title_p = doc.add_paragraph()
        run_title = title_p.add_run(f"‡πÄ‡∏Å‡∏ì‡∏ë‡πå {item.get('code', '')}: {item.get('name', '')}")
        set_thai_font(run_title, size=16, bold=True, color=RGBColor(30, 58, 138))

        # --- 3.1 ‡∏ï‡∏≤‡∏£‡∏≤‡∏á Audit Confidence ---
        conf_table = doc.add_table(rows=1, cols=3)
        conf_table.style = 'Table Grid'
        conf = item.get('audit_confidence', {})
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (Traceability)
        trace_val = conf.get('traceability_score', 0)
        if trace_val <= 1.0: trace_val = int(trace_val * 100) # ‡πÅ‡∏õ‡∏•‡∏á 0.8 -> 80
        
        metrics_cells = [
            ("Independence", f"{conf.get('source_count', 0)} Files"),
            ("Traceability", f"{trace_val}% Confidence"),
            ("Audit Status", f"{conf.get('level', 'VERIFIED')}")
        ]
        
        for i, (label, val) in enumerate(metrics_cells):
            cell = conf_table.rows[0].cells[i]
            p = cell.paragraphs[0]
            p.alignment = WD_ALIGN_PARAGRAPH.CENTER
            set_thai_font(p.add_run(label), size=10, bold=True)
            set_thai_font(p.add_run(f"\n{val}"), size=12, bold=True)
            set_cell_background(cell, "F3F4F6")

        # --- 3.2 PDCA Capability Matrix ---
        doc.add_paragraph()
        set_thai_font(doc.add_paragraph().add_run("üìä PDCA Capability Matrix:"), size=13, bold=True)
        pdca_table = doc.add_table(rows=2, cols=5)
        pdca_table.style = 'Table Grid'
        
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å pdca_matrix ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤ transform ‡∏°‡∏≤‡πÅ‡∏•‡πâ‡∏ß
        for i, lv_data in enumerate(item.get('pdca_matrix', [])):
            if i >= 5: break
            cell_top = pdca_table.cell(0, i)
            p_top = cell_top.paragraphs[0]
            p_top.alignment = WD_ALIGN_PARAGRAPH.CENTER
            set_thai_font(p_top.add_run(f"Level {lv_data['level']}"), bold=True)
            
            if lv_data.get('is_passed'):
                set_cell_background(cell_top, "D9EAD3") # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô

            cell_bot = pdca_table.cell(1, i)
            p_bot = cell_bot.paragraphs[0]
            p_bot.alignment = WD_ALIGN_PARAGRAPH.CENTER
            
            # ‡πÅ‡∏™‡∏î‡∏á P D C A ‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞ (1=‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß, 0=‡πÅ‡∏î‡∏á)
            for char, val in lv_data.get('pdca', {}).items():
                run_char = p_bot.add_run(f" {char} ")
                color = RGBColor(22, 101, 52) if val == 1 else RGBColor(185, 28, 28)
                set_thai_font(run_char, size=11, bold=True, color=color)

        # --- 3.3 ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô (Evidence Mapping) ---
        doc.add_paragraph()
        set_thai_font(doc.add_paragraph().add_run("üìé ‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö (Evidence Mapping):"), size=12, bold=True)
        
        grouped_sources = item.get('grouped_sources', {})
        has_evidence = False
        
        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ Level 1-5 ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô
        for lv_key in ["1", "2", "3", "4", "5"]:
            sources = grouped_sources.get(lv_key, [])
            for src in sources:
                has_evidence = True
                # ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå (‡πÄ‡∏≠‡∏≤ SCORE ‡∏≠‡∏≠‡∏Å‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)
                clean_filename = src.get('filename', '').split('|')[0]
                evi_text = (
                    f"Level {lv_key}: {clean_filename} "
                    f"(‡∏´‡∏ô‡πâ‡∏≤ {src.get('page', '1')}) - "
                    f"Relevance: {src.get('rerank_score', 0)}%"
                )
                p_evi = doc.add_paragraph(style='List Bullet')
                set_thai_font(p_evi.add_run(evi_text), size=10)
        
        if not has_evidence:
            set_thai_font(doc.add_paragraph().add_run("- ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô‡πÅ‡∏ô‡∏ö‡πÉ‡∏ô‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ô‡∏µ‡πâ -"), size=10)

        # --- 3.4 Insights & Recommendations ---
        # Strength
        doc.add_paragraph()
        set_thai_font(doc.add_paragraph().add_run("üí° AI Strength Summary:"), size=13, bold=True, color=RGBColor(22, 101, 52))
        reason_txt = item.get('reason', '‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏ï‡∏≤‡∏°‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î')
        set_thai_font(doc.add_paragraph(reason_txt).runs[0], size=12)

        # Next Step
        set_thai_font(doc.add_paragraph().add_run("üöÄ Next Step Recommendation:"), size=13, bold=True, color=RGBColor(30, 58, 138))
        next_step_txt = item.get('next_step', '‡∏£‡∏±‡∏Å‡∏©‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏á‡∏≤‡∏ô‡πÅ‡∏•‡∏∞‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏™‡∏π‡πà‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ñ‡∏±‡∏î‡πÑ‡∏õ')
        set_thai_font(doc.add_paragraph(next_step_txt).runs[0], size=12)

        doc.add_page_break() 
        
    return doc

@assessment_router.get("/status/{record_id}")
async def get_assessment_status(
    record_id: str, 
    current_user: UserMe = Depends(get_current_user)
):
    """
    [v2026.01.27 ‚Äî THE SHIELDED STATUS REVISE]
    - ‚ö° Layer 1: Check Database (The Truth) -> ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô Race Condition ‡∏´‡∏•‡∏±‡∏á Start
    - üß† Layer 2: Check Active Tasks (Memory) -> ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Real-time Update
    - üìÇ Layer 3: Check Disk (Persistence) -> ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏à‡∏ö‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß
    """
    db = SessionLocal()
    try:
        # --- LAYER 1: CHECK DATABASE (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤ 404 ‡∏´‡∏•‡∏±‡∏á‡∏Å‡∏î Start) ---
        task_record = db.query(AssessmentTaskTable).filter(
            AssessmentTaskTable.record_id == record_id
        ).first()

        # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏à‡∏≠‡πÉ‡∏ô DB ‡πÅ‡∏õ‡∏•‡∏ß‡πà‡∏≤‡∏á‡∏≤‡∏ô‡∏ñ‡∏π‡∏Å‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ô‡πà‡∏ô‡∏≠‡∏ô (‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£‡∏ï‡∏≠‡∏ö 404)
        if task_record:
            # ‡∏ñ‡πâ‡∏≤‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏£‡πá‡∏à ‡πÉ‡∏´‡πâ‡∏ï‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏à‡∏≤‡∏Å DB/Memory
            if task_record.status not in ["COMPLETED", "FAILED"]:
                # ‡πÄ‡∏ä‡πá‡∏Ñ Memory ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Å‡∏ß‡πà‡∏≤)
                active_tasks = globals().get("ACTIVE_TASKS", {})
                mem_task = active_tasks.get(record_id, {})
                
                return {
                    "status": task_record.status, # QUEUED, PROCESSING
                    "record_id": record_id,
                    "progress": mem_task.get("progress") or task_record.progress_percent or 5,
                    "message": mem_task.get("message") or task_record.progress_message or "‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Å‡∏≤‡∏£...",
                    "enabler": task_record.enabler,
                    "is_final": False,
                    "updated_at": datetime.now().isoformat()
                }
            
            # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ô DB ‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ FAILED ‡πÉ‡∏´‡πâ‡πÅ‡∏à‡πâ‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
            if task_record.status == "FAILED":
                return {
                    "status": "FAILED",
                    "record_id": record_id,
                    "message": task_record.progress_message or "‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß",
                    "is_final": True
                }

        # --- LAYER 2: CHECK DISK (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà COMPLETED ‡πÅ‡∏•‡πâ‡∏ß) ---
        # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô _find_assessment_file ‡∏à‡∏∞‡∏ó‡∏≥ Deep Scan ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå JSON
        try:
            file_path = _find_assessment_file(record_id, current_user)
        except HTTPException:
            file_path = None

        if not file_path or not os.path.exists(file_path):
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏ó‡∏±‡πâ‡∏á‡πÉ‡∏ô DB ‡πÅ‡∏•‡∏∞ Disk ‡∏à‡∏£‡∏¥‡∏á‡πÜ
            if not task_record:
                logger.warning(f"üîç [Status] Record not found anywhere: {record_id}")
                return {
                    "status": "NOT_FOUND",
                    "record_id": record_id,
                    "message": "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏£‡∏´‡∏±‡∏™‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ô‡∏µ‡πâ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö",
                    "suggestion": "‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏£‡∏´‡∏±‡∏™‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÉ‡∏´‡∏°‡πà"
                }
            
            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏µ‡πÉ‡∏ô DB ‡∏ß‡πà‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÑ‡∏ü‡∏•‡πå‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏≤ (I/O Delay)
            return {
                "status": "PROCESSING",
                "record_id": record_id,
                "progress": 95,
                "message": "AI ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå...",
                "is_final": False
            }

        # --- LAYER 3: DATA TRANSFORMATION ---
        with open(file_path, "r", encoding="utf-8") as f:
            raw_data = json.load(f)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏à‡∏≤‡∏Å Data ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå
        meta = raw_data.get("metadata", {}) or raw_data.get("summary", {}) or {}
        check_user_permission(current_user, meta.get("tenant"), meta.get("enabler"))

        # Transform ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ UI
        ui_result = _transform_result_for_ui(raw_data, current_user)
        ui_result["status"] = "COMPLETED"
        ui_result["record_id"] = record_id
        ui_result["is_final"] = True

        return ui_result

    except Exception as e:
        logger.error(f"üí• [Status Error] {record_id}: {str(e)}", exc_info=True)
        if isinstance(e, HTTPException): raise e
        raise HTTPException(status_code=500, detail="Internal Server Error ‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞")
    finally:
        db.close()

@assessment_router.get("/history")
async def get_assessment_history(
    tenant: str, 
    year: Optional[str] = Query(None),
    enabler: Optional[str] = Query(None),
    current_user: UserMe = Depends(get_current_user)
):
    """
    [v2026.FINAL.HISTORY] - ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô
    - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Scope ‡πÄ‡∏õ‡πá‡∏ô ALL ‡πÇ‡∏î‡∏¢‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å metadata.sub_id ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏à‡∏£‡∏¥‡∏á
    - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏õ‡∏±‡∏ç‡∏´‡∏≤ Level ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á ‡πÇ‡∏î‡∏¢‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å result_summary.maturity_level
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Hybrid ‡∏ó‡∏±‡πâ‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡∏°‡πà
    """
    check_user_permission(current_user, tenant)
    history_list = []
    from config.global_vars import DATA_STORE_ROOT
    from datetime import datetime
    
    norm_tenant = _n(tenant)
    search_roots = [
        os.path.join(DATA_STORE_ROOT, norm_tenant, "exports"),
        os.path.join("data_store", norm_tenant, "exports")
    ]
    
    tenant_export_root = next((p for p in search_roots if os.path.exists(p)), None)
    if not tenant_export_root:
        return {"items": [], "total_found": 0, "message": "No export data found"}

    user_allowed_enablers = [e.upper() for e in current_user.enablers]
    target_enabler = enabler.upper() if enabler else None

    # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
    if not year or str(year).lower() == "all":
        search_years = [d for d in os.listdir(tenant_export_root) if d.isdigit()]
    else:
        search_years = [str(year)]

    for y in search_years:
        year_path = os.path.join(tenant_export_root, y)
        if not os.path.exists(year_path): continue

        for root, _, files in os.walk(year_path):
            for f in files:
                if not f.lower().endswith(".json"): continue
                file_path = os.path.join(root, f)
                
                try:
                    with open(file_path, "r", encoding="utf-8") as jf:
                        data = json.load(jf)

                    # 1. ‡πÅ‡∏¢‡∏Å‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (v2026 ‡πÉ‡∏ä‡πâ metadata ‡πÅ‡∏•‡∏∞ result_summary)
                    metadata = data.get("metadata", {})
                    res_sum = data.get("result_summary", {})
                    old_sum = data.get("summary", {})

                    # 2. RECORD ID
                    record_id = data.get("record_id") or metadata.get("record_id") or old_sum.get("record_id")
                    if not record_id:
                        parts = f.replace(".json", "").split("_")
                        record_id = parts[2] if len(parts) >= 3 else f.replace(".json", "")

                    # 3. ENABLER
                    file_enabler = (metadata.get("enabler") or res_sum.get("enabler") or "KM").upper()
                    if file_enabler not in user_allowed_enablers: continue
                    if target_enabler and file_enabler != target_enabler: continue

                    # 4. SCOPE (‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á sub_id ‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥)
                    details = data.get("sub_criteria_details", [])
                    found_subs = []

                    # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ sub_id ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏£‡∏¥‡∏á‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ
                    if isinstance(details, list):
                        for detail in details:
                            # ‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏±‡∏ô‡∏ú‡πà‡∏≤‡∏ô Worker (‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á Tier-2)
                            sub_results = detail.get("sub_criteria_results", [])
                            for res in sub_results:
                                sid = res.get("sub_id")
                                if sid: found_subs.append(str(sid))
                            
                            # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (Tier-1)
                            if not sub_results and detail.get("sub_id"):
                                found_subs.append(str(detail.get("sub_id")))

                    # ‡∏Å‡∏≥‡∏à‡∏±‡∏î‡∏ï‡∏±‡∏ß‡∏ã‡πâ‡∏≥‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö (‡πÄ‡∏ä‡πà‡∏ô 1.1, 1.2)
                    unique_subs = sorted(list(set(found_subs)))

                    # --- ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ö‡∏ô UI ---
                    if len(unique_subs) == 1:
                        # üéØ ‡∏Å‡∏£‡∏ì‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠: ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ‡πÄ‡∏ä‡πà‡∏ô "1.1"
                        scope = unique_subs[0]
                    elif 1 < len(unique_subs) <= 3:
                        # üéØ ‡∏Å‡∏£‡∏ì‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ö‡∏≤‡∏á‡∏™‡πà‡∏ß‡∏ô (2-3 ‡∏Ç‡πâ‡∏≠): ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏•‡∏Ç‡∏Ç‡πâ‡∏≠‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏Å‡∏±‡∏ô ‡πÄ‡∏ä‡πà‡∏ô "1.1, 1.2"
                        scope = ", ".join(unique_subs)
                    elif len(unique_subs) > 3:
                        # üéØ ‡∏Å‡∏£‡∏ì‡∏µ‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏°‡∏≤‡∏Å ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á Enabler
                        scope = "MULTI"
                    else:
                        # üéØ Fallback ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡∏ñ‡πâ‡∏≤‡∏´‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏à‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡∏±‡πâ‡∏á Enabler
                        raw_scope = metadata.get("sub_id") or old_sum.get("sub_criteria_id") or "ALL"
                        scope = str(raw_scope).upper()

                    scope = scope.upper()

                    # 5. LEVEL LOGIC
                    display_level = res_sum.get("maturity_level") or old_sum.get("highest_pass_level")
                    if display_level:
                        l_str = str(display_level).strip().upper()
                        display_level = l_str if l_str.startswith("L") else f"L{l_str}"
                    else:
                        display_level = "N/A"

                    # 6. SCORE
                    total_score = round(safe_float(
                        res_sum.get("total_weighted_score") or 
                        old_sum.get("total_weighted_score") or 0.0
                    ), 2)

                    # 7. DATE PARSING
                    date_candidates = [
                        metadata.get("exported_at"), # ‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô‡πÉ‡∏´‡∏°‡πà
                        metadata.get("export_at"),
                        old_sum.get("timestamp")
                    ]
                    date_str, parsed_dt = "N/A", None
                    for cand in date_candidates:
                        if cand:
                            try:
                                parsed_dt = datetime.fromisoformat(str(cand).replace('Z', '+00:00'))
                                date_str = parsed_dt.isoformat()
                                break
                            except: continue

                    if not parsed_dt:
                        mtime = os.path.getmtime(file_path)
                        parsed_dt = datetime.fromtimestamp(mtime)
                        date_str = parsed_dt.isoformat()

                    history_list.append({
                        "record_id": record_id,
                        "date": date_str,
                        "date_dt": parsed_dt,
                        "tenant": tenant,
                        "year": y,
                        "enabler": file_enabler,
                        "scope": scope,
                        "level": display_level,
                        "score": total_score,
                        "status": "COMPLETED"
                    })

                except Exception as e:
                    logger.error(f"‚ùå Skip corrupted/old file {f}: {e}")
                    continue

    # 8. Sort ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    sorted_history = sorted(history_list, key=lambda x: x['date_dt'] or datetime.min, reverse=True)
    for item in sorted_history: item.pop('date_dt', None)

    return {
        "items": sorted_history,
        "total_found": len(history_list),
        "displayed": len(sorted_history)
    }

# ------------------------------------------------------------------
# 1. Start Assessment Endpoint
# ------------------------------------------------------------------
@assessment_router.post("/start")
async def start_assessment(
    request: StartAssessmentRequest, 
    background_tasks: BackgroundTasks, 
    current_user: UserMe = Depends(get_current_user)
):
    """
    [FINAL v2026.6.20 ‚Äî Start Assessment + Friendly Response]
    - Permission + Data Integrity Check
    - Persistent Task Entry (DB)
    - Background Worker Delegation
    - Response ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ + estimated_time
    """
    enabler_uc = request.enabler.upper()
    target_year = str(request.year if request.year else (current_user.year or DEFAULT_YEAR)).strip()
    target_sub = str(request.sub_criteria).strip().lower() if request.sub_criteria else "all"

    # 1. Permission & Data Integrity Check
    check_user_permission(current_user, request.tenant, enabler_uc)

    vs_path = get_vectorstore_collection_path(request.tenant, target_year, "evidence", enabler_uc)
    if not os.path.exists(vs_path):
        raise HTTPException(status_code=400, detail=f"Data Store ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {enabler_uc}/{target_year} ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏™‡∏£‡πâ‡∏≤‡∏á")

    # 2. Generate Traceable Record ID
    record_id = uuid.uuid4().hex[:12]
    
    # 3. Persistent Task Entry
    db = SessionLocal()
    try:
        new_task = AssessmentTaskTable(
            record_id=record_id,
            user_id=current_user.id,
            tenant=request.tenant,
            year=target_year,
            enabler=enabler_uc,
            sub_criteria=target_sub,
            status="QUEUED",
            progress_percent=5,
            progress_message="‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏ß‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô..."
        )
        db.add(new_task)
        db.commit()
        db.refresh(new_task)
    except Exception as e:
        logger.error(f"‚ùå Initial DB Error: {e}")
        db.rollback()
        raise HTTPException(status_code=500, detail="‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏•‡∏á‡∏ó‡∏∞‡πÄ‡∏ö‡∏µ‡∏¢‡∏ô‡∏á‡∏≤‡∏ô‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà")
    finally:
        db.close()

    # 4. Delegate to Background Worker
    background_tasks.add_task(
        run_assessment_engine_task,
        assessment_semaphore,     # ‡∏™‡πà‡∏á‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÑ‡∏õ‡πÄ‡∏•‡∏¢ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠
        record_id,
        request.tenant,
        target_year,
        enabler_uc,
        target_sub,
        request.sequential_mode
    )

    return {
        "record_id": record_id,
        "status": "QUEUED",
        "message": f"‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô {enabler_uc} ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß (‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏ß‡∏á‡∏≤‡∏ô)",
        "estimated_time": "20-40 ‡∏ô‡∏≤‡∏ó‡∏µ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏°‡∏î sequential)",
        "poll_url": f"/api/assess/status/{record_id}",
        "poll_interval_seconds": 15
    }

# ------------------------------------------------------------------
# 2. Background Task Engine (Robust Implementation)
# ------------------------------------------------------------------
async def run_assessment_engine_task(
    semaphore: asyncio.Semaphore, 
    record_id: str, 
    tenant: str, 
    year: str, 
    enabler: str, 
    sub_id: str, 
    sequential: bool
):
    """
    [v2026.FINAL.REVISED ‚Äî Robust Background Worker]
    - üîí Semaphore Control: ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ GPU/RAM ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
    - üßπ Memory Management: Cleanup ‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏ö‡∏á‡∏≤‡∏ô
    - üìä Accurate DB Sync: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Scope ‡πÅ‡∏•‡∏∞ Level ‡∏à‡∏£‡∏¥‡∏á‡∏•‡∏á‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    """
    # 1. üîí Acquire Semaphore (Queue Management)
    async with semaphore:
        logger.info(f"‚öôÔ∏è [Task {record_id}] Processing Started (Semaphore Acquired)...")
        engine = None
        vsm = None
        
        try:
            # --- [STEP 1: RESOURCE HYDRATION] ---
            db_update_task_status(record_id, 10, "‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Vector Database ‡πÅ‡∏•‡∏∞‡πÇ‡∏´‡∏•‡∏î Mapping...")
            
            # ‡∏£‡∏±‡∏ô CPU/IO Bound tasks ‡πÉ‡∏ô Thread
            vsm = await asyncio.to_thread(
                load_all_vectorstores, tenant, year, None, EVIDENCE_DOC_TYPES, enabler
            )
            doc_map_raw = await asyncio.to_thread(
                load_doc_id_mapping, EVIDENCE_DOC_TYPES, tenant, year, enabler
            )
            doc_map = {d_id: d.get("file_name", d_id) for d_id, d in doc_map_raw.items()}

            # --- [STEP 2: ENGINE & MODEL SETUP] ---
            db_update_task_status(record_id, 20, f"‡πÇ‡∏´‡∏•‡∏î AI Model ({DEFAULT_LLM_MODEL_NAME})...")
            
            llm = await asyncio.to_thread(
                create_llm_instance, model_name=DEFAULT_LLM_MODEL_NAME, temperature=0.0
            )
            
            config = AssessmentConfig(
                enabler=enabler, 
                tenant=tenant, 
                year=year, 
                force_sequential=sequential
            )
            
            engine = SEAMPDCAEngine(
                config=config, 
                llm_instance=llm, 
                logger_instance=logger, 
                doc_type=EVIDENCE_DOC_TYPES, 
                vectorstore_manager=vsm, 
                document_map=doc_map,
                record_id=record_id 
            )

            # --- [STEP 3: CORE ASSESSMENT] ---
            db_update_task_status(record_id, 35, "AI ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô (RAG Assessment)...")
            
            result = await asyncio.to_thread(
                engine.run_assessment, 
                target_sub_id=sub_id, 
                export=True, 
                record_id=record_id,
                vectorstore_manager=vsm,
                sequential=sequential
            )

            # --- [STEP 4: FINALIZE & SYNC DB] ---
            if isinstance(result, dict) and result.get("status") == "FAILED":
                error_msg = result.get("error_message", "AI Engine Error")
                db_update_task_status(record_id, 0, f"‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß: {error_msg}", status="FAILED")
            else:
                # üéØ [CRITICAL] ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏•‡∏á DB ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
                # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ API /history ‡∏î‡∏∂‡∏á Scope ‡πÅ‡∏•‡∏∞ Level ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡πÑ‡∏î‡πâ
                await asyncio.to_thread(db_finish_task, record_id, result)
                
                # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
                db_update_task_status(record_id, 100, "‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå", status="COMPLETED")
                logger.info(f"‚úÖ [Task {record_id}] Finished Successfully")
                
        except Exception as e:
            logger.error(f"üí• [Task {record_id}] Critical Failure: {str(e)}", exc_info=True)
            db_update_task_status(record_id, 0, f"‡∏£‡∏∞‡∏ö‡∏ö‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {str(e)}", status="FAILED")
            
        finally:
            # --- [STEP 5: POLISHING & CLEANUP] ---
            # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ö‡∏ô GPU L40S ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ Memory ‡∏Ñ‡πâ‡∏≤‡∏á
            import gc
            import torch
            
            # ‡∏•‡∏ö Instance ‡∏Ç‡∏ô‡∏≤‡∏î‡πÉ‡∏´‡∏ç‡πà
            del engine
            del vsm
            
            if torch.cuda.is_available():
                torch.cuda.empty_cache() # ‡∏Ñ‡∏∑‡∏ô VRAM
            
            gc.collect() # ‡∏Ñ‡∏∑‡∏ô RAM
            logger.info(f"üßπ [Task {record_id}] Memory cleanup completed.")
            

def _find_assessment_file(search_id: str, current_user: UserMe) -> str:
    """
    [HYBRID DEEP SEARCH v2026.3]
    - ‡∏ä‡∏±‡πâ‡∏ô 1: DB Hit (‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å Database ‡∏ï‡∏£‡∏á‡πÜ)
    - ‡∏ä‡∏±‡πâ‡∏ô 2: Fast Disk Scan (‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå - ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ ID ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠)
    - ‡∏ä‡∏±‡πâ‡∏ô 3: Deep Disk Scan (‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡πà‡∏≤‡∏ô JSON Metadata ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤ record_id) **NEW**
    """
    norm_tenant = _n(current_user.tenant)
    norm_search = str(search_id).strip().lower()

    # --- ‡∏ä‡∏±‡πâ‡∏ô 1: DB Hit (‡∏Ñ‡πâ‡∏ô‡∏à‡∏≤‡∏Å SQLite) ---
    db = SessionLocal()
    try:
        res_record = db.query(AssessmentResultTable).filter(
            AssessmentResultTable.record_id == search_id
        ).first()
        
        if res_record and res_record.full_result_json:
            try:
                data = json.loads(res_record.full_result_json)
                # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á path ‡∏à‡∏≤‡∏Å‡∏´‡∏•‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏ô JSON
                db_path = data.get("export_path_used") or data.get("metadata", {}).get("full_path")
                if db_path and os.path.exists(db_path):
                    logger.info(f"‚ö° [Search] DB Hit! Found: {db_path}")
                    return db_path
            except: pass
    finally:
        db.close()

    # --- ‡∏ä‡∏±‡πâ‡∏ô 2 & 3: Disk Scan (Fallback) ---
    search_paths = [
        os.path.join(DATA_STORE_ROOT, norm_tenant, "exports"),
        os.path.join("data_store", norm_tenant, "exports")
    ]
    
    logger.info(f"üîç [Search] DB Miss. Deep Scanning Disk for ID: {norm_search}...")

    for s_path in search_paths:
        if not os.path.exists(s_path): continue
            
        for root, _, files in os.walk(s_path):
            for f in files:
                if not f.lower().endswith(".json"): continue
                
                full_path = os.path.join(root, f)
                
                # [Fast Scan] ‡∏ñ‡πâ‡∏≤‡πÇ‡∏ä‡∏Ñ‡∏î‡∏µ‡∏°‡∏µ ID ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå
                if norm_search in f.lower():
                    logger.info(f"‚úÖ [Search] Fast Scan Success: {full_path}")
                    return full_path
                
                # [Deep Scan] ‡πÄ‡∏õ‡∏¥‡∏î‡∏≠‡πà‡∏≤‡∏ô Metadata ‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô (‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏°‡∏µ ID)
                try:
                    with open(full_path, "r", encoding="utf-8") as jf:
                        # ‡∏≠‡πà‡∏≤‡∏ô‡πÅ‡∏Ñ‡πà‡∏´‡∏±‡∏ß‡πÑ‡∏ü‡∏•‡πå (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏´‡∏ç‡πà‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πâ‡∏≤‡∏á)
                        first_part = jf.read(1000) 
                        # ‡πÄ‡∏ä‡πá‡∏Ñ‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏î‡πâ‡∏ß‡∏¢ string search ‡∏Å‡πà‡∏≠‡∏ô‡πÇ‡∏´‡∏•‡∏î json ‡πÄ‡∏ï‡πá‡∏°
                        if norm_search in first_part:
                            jf.seek(0)
                            data = json.load(jf)
                            f_id = data.get("record_id") or data.get("metadata", {}).get("record_id")
                            if str(f_id).lower() == norm_search:
                                logger.info(f"üéØ [Search] Deep Scan Success! Found ID in Metadata: {full_path}")
                                return full_path
                except:
                    continue
                    
    logger.error(f"‚ùå [Search] Total Failure for ID: {norm_search}")
    raise HTTPException(
        status_code=404, 
        detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (ID: {search_id}) ‡πÅ‡∏°‡πâ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ Deep Scan ‡πÅ‡∏•‡πâ‡∏ß"
    )

# ------------------------------------------------------------------
# 3. Task List API (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏ô‡πâ‡∏≤ UI ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏°‡∏≤‡πÇ‡∏ä‡∏ß‡πå)
# ------------------------------------------------------------------
@assessment_router.get("/tasks")
async def get_assessment_tasks(current_user: UserMe = Depends(get_current_user)):
    db = SessionLocal()
    try:
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡∏≠‡∏á Tenant ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡πÉ‡∏´‡∏°‡πà‡∏™‡∏∏‡∏î‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô
        tasks = db.query(AssessmentTaskTable).filter(
            AssessmentTaskTable.tenant == current_user.tenant
        ).order_by(AssessmentTaskTable.created_at.desc()).limit(20).all()
        
        return {"tasks": tasks}
    finally:
        db.close()


# ------------------------------------------------------------------
# 4. Download API (Full Revised)
# ------------------------------------------------------------------
@assessment_router.get("/download/{record_id}/{file_type}")
async def download_assessment_file(
    record_id: str,
    file_type: str,
    background_tasks: BackgroundTasks,
    current_user: UserMe = Depends(get_current_user)
):
    """
    [v2026.6 - Final Production]
    - ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á Enabler ‡∏à‡∏≤‡∏Å Metadata ‡πÉ‡∏´‡∏°‡πà
    - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á Word ‡∏à‡∏≤‡∏Å UI Data ‡∏ï‡∏±‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
    """
    logger.info(f"üì• Download request: record_id={record_id}, type={file_type} by {current_user.email}")

    # 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö (JSON) ‡∏î‡πâ‡∏ß‡∏¢ Deep Search ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÅ‡∏Å‡πâ‡∏Å‡∏±‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
    json_path = _find_assessment_file(record_id, current_user)

    # 2. ‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    try:
        with open(json_path, "r", encoding="utf-8") as f:
            raw_data = json.load(f)
    except Exception as e:
        logger.error(f"Error reading JSON: {e}")
        raise HTTPException(status_code=500, detail="‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ")

    # 3. üõ°Ô∏è ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå (‡∏õ‡∏£‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà v2026)
    # ‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å metadata.enabler ‡∏´‡∏£‡∏∑‡∏≠ result_summary.enabler
    metadata = raw_data.get("metadata", {})
    res_sum = raw_data.get("result_summary", {})
    enabler = (metadata.get("enabler") or res_sum.get("enabler") or "KM").upper()
    
    check_user_permission(current_user, current_user.tenant, enabler)

    file_type = file_type.lower()

    # --- ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå JSON ---
    if file_type == "json":
        return FileResponse(
            path=json_path,
            filename=f"SEAM_Result_{enabler}_{record_id}.json",
            media_type="application/json"
        )

    # --- ‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡∏≠‡πÑ‡∏ü‡∏•‡πå Word (DOCX) ---
    elif file_type in ["word", "docx"]:
        logger.info(f"üìÑ Generating Word report for {record_id}...")

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢ Transformer ‡∏ï‡∏±‡∏ß‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î (v2026.5) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ Roadmap ‡πÅ‡∏•‡∏∞ Evidence ‡∏Ñ‡∏£‡∏ö
        ui_data = _transform_result_for_ui(raw_data)
        
        try:
            # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Report (‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏™‡πà‡∏á ui_data ‡∏ó‡∏µ‡πà‡∏°‡∏µ Roadmap ‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß)
            doc = create_docx_report_similar_to_ui(ui_data)
        except Exception as e:
            logger.error(f"Word Generation Error: {e}")
            raise HTTPException(status_code=501, detail=f"‡∏£‡∏∞‡∏ö‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Word ‡∏Ç‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏á: {str(e)}")

        with tempfile.NamedTemporaryFile(delete=False, suffix=".docx") as tmp:
            doc.save(tmp.name)
            temp_path = tmp.name

        background_tasks.add_task(os.remove, temp_path)

        return FileResponse(
            path=temp_path,
            filename=f"SEAM_Report_{enabler}_{record_id}.docx",
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )

    else:
        raise HTTPException(status_code=400, detail="‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö json, word)")

@assessment_router.get("/view-evidence/{record_id}/{lv}/{filename}")
async def view_evidence_file(
    record_id: str,
    lv: str,
    filename: str,
    current_user: UserMe = Depends(get_current_user)
):
    # 1. ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á record ‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏° (Security Check)
    json_path = _find_assessment_file(record_id, current_user)
    
    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå Tenant/Enabler (‡πÉ‡∏ä‡πâ Logic ‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ)
    metadata = data.get("metadata", {})
    check_user_permission(current_user, metadata.get("tenant"), metadata.get("enabler"))

    # 3. ‡∏õ‡∏£‡∏∞‡∏Å‡∏≠‡∏ö Path ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏ô Evidence Store
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á: data_store/{tenant}/{year}/evidence/{enabler}/{filename}
    file_path = os.path.join(
        DATA_STORE_ROOT, 
        metadata.get("tenant"), 
        metadata.get("year"), 
        "evidence", 
        metadata.get("enabler").upper(), 
        filename
    )

    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")

    # 4. ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÉ‡∏´‡πâ UI
    return FileResponse(path=file_path, filename=filename)