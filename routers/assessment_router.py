# -*- coding: utf-8 -*-
# routers/assessment_router.py
# Production Final Version - 20 ‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏° 2568 (Fixed parameter order + stable UUID + full assessment flow)

import os
import uuid
import json
import asyncio
import logging
import mimetypes
from datetime import datetime
from typing import Optional, Dict, Any, Union, List

from fastapi import APIRouter, BackgroundTasks, HTTPException, Depends, Query
from fastapi.responses import FileResponse
from pydantic import BaseModel

from routers.auth_router import UserMe, get_current_user
from utils.path_utils import _n, get_tenant_year_export_root, load_doc_id_mapping, get_document_file_path, get_vectorstore_collection_path
from core.seam_assessment import SEAMPDCAEngine, AssessmentConfig
from core.vectorstore import load_all_vectorstores
from models.llm import create_llm_instance
from config.global_vars import EVIDENCE_DOC_TYPES, DEFAULT_LLM_MODEL_NAME, DEFAULT_YEAR
import pytz


logger = logging.getLogger(__name__)
assessment_router = APIRouter(prefix="/api/assess", tags=["Assessment"])

ACTIVE_TASKS: Dict[str, Any] = {}

class StartAssessmentRequest(BaseModel):
    tenant: str
    year: Union[int, str]
    enabler: str
    sub_criteria: Optional[str] = "all"
    sequential_mode: bool = True

# ------------------- Permission Helper -------------------
def check_user_permission(user: UserMe, tenant: str, enabler: str):
    if _n(user.tenant) != _n(tenant):
        raise HTTPException(status_code=403, detail="Tenant mismatch")
    if user.enablers and enabler.upper() not in [e.upper() for e in user.enablers]:
        raise HTTPException(status_code=403, detail=f"Enabler '{enabler}' not allowed")

# ------------------- Helpers -------------------
def parse_safe_date(raw_date_str: Any, file_path: str) -> str:
    tz = pytz.timezone('Asia/Bangkok') # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Timezone ‡πÑ‡∏ó‡∏¢
    
    if raw_date_str and isinstance(raw_date_str, str):
        try:
            # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö %Y%m%d_%H%M%S (‡πÄ‡∏ä‡πà‡∏ô‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå)
            if "_" in raw_date_str:
                dt = datetime.strptime(raw_date_str, "%Y%m%d_%H%M%S")
                # ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏•‡∏≤‡πÑ‡∏ó‡∏¢
                return tz.localize(dt).isoformat()
        except:
            pass

    try:
        # ‡∏î‡∏∂‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏ü‡∏•‡πå‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Disk
        mtime = os.path.getmtime(file_path)
        dt = datetime.fromtimestamp(mtime, tz) # ‡∏£‡∏∞‡∏ö‡∏∏ Timezone ‡∏ï‡∏≠‡∏ô‡∏î‡∏∂‡∏á timestamp
        return dt.isoformat()
    except:
        # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Thai Timezone
        return datetime.now(tz).isoformat()

def _find_assessment_file(search_id: str, current_user: UserMe) -> str:
    # 1. ‡∏´‡∏≤ root ‡∏Ç‡∏≠‡∏á tenant
    # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡∏õ‡∏µ 2568 ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏ï‡∏±‡πâ‡∏á‡∏ï‡πâ‡∏ô‡∏Å‡πà‡∏≠‡∏ô
    sample_path = get_tenant_year_export_root(current_user.tenant, "2568")
    tenant_export_root = os.path.dirname(sample_path)
    
    norm_search = _n(search_id).lower()

    # 2. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡∏™‡∏≥‡∏£‡∏≠‡∏á (‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏±‡∏ô‡∏ö‡∏ô Linux/Docker ‡πÅ‡∏•‡πâ‡∏ß /app/ ‡∏´‡∏≤‡∏¢‡πÑ‡∏õ)
    search_paths = [tenant_export_root]
    if tenant_export_root.startswith("/app/"):
        search_paths.append(tenant_export_root.replace("/app/", "", 1))

    for s_path in search_paths:
        if os.path.exists(s_path):
            for root, _, files in os.walk(s_path):
                for f in files:
                    if f.endswith(".json") and norm_search in _n(f).lower():
                        return os.path.join(root, f)
                    
    raise HTTPException(status_code=404, detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô ID: {search_id}")


@assessment_router.get("/evidence/{doc_type}/{document_uuid}")
async def serve_evidence_file(
    document_uuid: str,
    doc_type: str,
    tenant: str,
    year: str = None,
    enabler: str = None,
    current_user: UserMe = Depends(get_current_user)
):
    check_user_permission(current_user, tenant, enabler or "KM")

    file_info = get_document_file_path(
        document_uuid=document_uuid,
        tenant=tenant,
        year=year,
        enabler=enabler,
        doc_type_name=doc_type
    )

    if not file_info:
        raise HTTPException(status_code=404, detail="File not found")

    file_path = file_info["file_path"]
    
    # ‡∏î‡∏∂‡∏á‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå
    ext = os.path.splitext(file_path)[1].lower()
    
    # üõ°Ô∏è Force MIME Type ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac/Safari
    mime_map = {
        ".pdf": "application/pdf",
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
    }
    
    mime_type = mime_map.get(ext) or mimetypes.guess_type(file_path)[0] or "application/octet-stream"

    # ‡∏™‡πà‡∏á FileResponse
    response = FileResponse(
        path=file_path,
        media_type=mime_type,
        content_disposition_type="inline"
    )

    # üí° ‡∏´‡∏±‡∏ß‡πÉ‡∏à‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Mac/Safari:
    # 1. ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ Browser ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Path ‡∏ã‡∏∂‡πà‡∏á‡∏ö‡∏≤‡∏á‡∏ó‡∏µ‡∏°‡∏µ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÅ‡∏•‡πâ‡∏ß‡∏ó‡∏≥‡πÉ‡∏´‡πâ Header ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô
    # 2. ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö Header ‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô
    response.headers["Content-Type"] = mime_type
    response.headers["Accept-Ranges"] = "bytes" 
    
    # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô PDF ‡∏ö‡∏ô Mac ‡πÉ‡∏´‡πâ‡πÄ‡∏ï‡∏¥‡∏° Cache-Control ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Viewer ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡πÑ‡∏î‡πâ‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô
    if ext == ".pdf":
        response.headers["Cache-Control"] = "no-cache, no-store, must-revalidate"

    return response


@assessment_router.get("/view-document")
async def view_document(filename: str, page: Optional[str] = "1", current_user: UserMe = Depends(get_current_user)):
    """ Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå PDF ‡πÑ‡∏õ‡∏¢‡∏±‡∏á‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ """
    # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡∏≠‡∏á Tenant
    import os
    from utils.path_utils import get_tenant_year_import_root
    
    # ‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ß‡πà‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå import/EVIDENCE_DOC
    base_path = os.path.join(get_tenant_year_import_root(current_user.tenant, current_user.year), "EVIDENCE_DOC")
    file_path = os.path.join(base_path, filename)

    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: {filename}")

    # ‡∏™‡πà‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Browser ‡πÄ‡∏õ‡∏¥‡∏î (‡∏£‡∏∞‡∏ö‡∏∏‡∏´‡∏ô‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢ #page=X ‡πÉ‡∏ô‡∏ù‡∏±‡πà‡∏á Frontend)
    return FileResponse(file_path, media_type="application/pdf")

def _transform_result_for_ui(raw_data: Dict[str, Any], current_user: Any = None) -> Dict[str, Any]:
    """
    ‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô Hybrid + Bottleneck Support:
    1. ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö is_gap_analysis ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÇ‡∏ä‡∏ß‡πå Badge Bottleneck ‡πÉ‡∏ô UI
    2. ‡∏™‡πà‡∏á rerank_score ‡πÅ‡∏•‡∏∞ snippet ‡πÅ‡∏ö‡∏ö‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥ Tooltip
    3. ‡πÅ‡∏¢‡∏Å evaluation_mode (NORMAL/GAP_ONLY) ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏∞‡∏ö‡∏≤‡∏¢‡∏™‡∏µ PDCA Matrix
    """
    summary = raw_data.get("summary", {})
    sub_results = raw_data.get("sub_criteria_results", [])

    processed_sub_criteria = []
    radar_data = []

    # --- 1. Metrics & Score Calculation ---
    total_score = round(float(summary.get("Total Weighted Score Achieved") or summary.get("achieved_weight") or 0.0), 2)
    full_score_all = round(float(summary.get("Total Possible Weight") or 4.0), 2)
    
    total_expected = int(summary.get("total_subcriteria") or 12)
    passed_count = int(summary.get("total_subcriteria_assessed") or len(sub_results))
    completion_rate = (passed_count / total_expected * 100) if total_expected > 0 else 0.0
    
    overall_level = summary.get("Overall Maturity Level (Weighted)") or f"L{summary.get('highest_pass_level', 0)}"
    enabler_name = (summary.get("enabler") or "N/A").upper()

    for res in sub_results:
        cid = res.get("sub_criteria_id", "N/A")
        cname = res.get("sub_criteria_name", f"‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏¢‡πà‡∏≠‡∏¢ {cid}")
        highest_pass = int(res.get("highest_full_level") or 0)
        raw_levels_list = res.get("raw_results_ref", [])
        
        # --- 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Bottleneck (‡∏Ç‡πâ‡∏≤‡∏°‡πÄ‡∏•‡πÄ‡∏ß‡∏•) ---
        # ‡∏´‡∏≤‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô (is_passed=True) ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        has_higher_potential = any(
            int(r.get("level", 0)) > highest_pass and r.get("is_passed") 
            for r in raw_levels_list
        )

        # ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏£‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠
        current_sub_score = round(float(res.get("weighted_score", 0.0)), 2)
        current_sub_full = round(float(res.get("weight", 0.0)), 2)

        # --- 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á PDCA Matrix (Enhanced for UI colors) ---
        pdca_matrix = []
        raw_levels_map = {item.get("level"): item for item in raw_levels_list}
        
        for lv_idx in range(1, 6):
            lv_info = raw_levels_map.get(lv_idx)
            is_passed = lv_info.get("is_passed", False) if lv_info else (lv_idx <= highest_pass)
            
            # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î Mode: ‡∏ñ‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡πÅ‡∏ï‡πà‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏•‡πÄ‡∏ß‡∏•‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡∏Å‡∏≤‡∏£ ‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô GAP_ONLY (‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô‡πÉ‡∏ô UI)
            eval_mode = "NORMAL"
            if is_passed and lv_idx > highest_pass:
                eval_mode = "GAP_ONLY"

            pdca_matrix.append({
                "level": lv_idx,
                "is_passed": is_passed,
                "evaluation_mode": eval_mode,
                "pdca": lv_info.get("pdca_breakdown", {"P": 0, "D": 0, "C": 0, "A": 0}) if lv_info else ({"P": 1, "D": 1, "C": 1, "A": 1} if lv_idx <= highest_pass else {"P": 0, "D": 0, "C": 0, "A": 0}),
                "reason": lv_info.get("reason", "‡∏ú‡πà‡∏≤‡∏ô‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô") if not lv_info and lv_idx <= highest_pass else (lv_info.get("reason", "") if lv_info else "‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏ñ‡∏∂‡∏á‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô")
            })

        # --- 4. ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏° Sources (‡∏â‡∏ö‡∏±‡∏ö‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏∂‡∏á Confidence) ---
        grouped_sources = {str(lv): [] for lv in range(1, 6)}
        for ref in raw_levels_list:
            lv_key = str(ref.get("level"))
            seen_in_lv = set()
            for source in ref.get("temp_map_for_level", []):
                # 1. ‡∏î‡∏∂‡∏á Metadata ‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∞‡πÅ‡∏ô‡∏ô‡∏à‡∏£‡∏¥‡∏á)
                meta = source.get('metadata', {})
                
                fname = source.get('filename') or meta.get('filename') or "Unknown Document"
                pnum = str(source.get('page_number') or meta.get('page') or source.get('page_label') or "1")
                d_uuid = source.get('document_uuid') or source.get('doc_id') or meta.get('doc_id')
                if not d_uuid: continue
                
                doc_key = f"{fname}-{pnum}"
                if doc_key not in seen_in_lv:
                    # ‚úÖ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏à‡∏∏‡∏î‡∏ô‡∏µ‡πâ: ‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å metadata ‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
                    # ‡πÉ‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠ meta.get('rerank_score')
                    score_val = (
                        meta.get("rerank_score") or 
                        source.get("rerank_score") or 
                        meta.get("score") or 
                        source.get("score") or 
                        0.0
                    )

                    grouped_sources[lv_key].append({
                        "filename": fname,
                        "page": pnum,
                        "text": source.get("text", "")[:300],
                        "rerank_score": float(score_val), # ‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô float ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ Frontend ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÑ‡∏î‡πâ
                        "document_uuid": d_uuid,
                        "doc_type": source.get("doc_type", "evidence"),
                        "pdca_tag": source.get("pdca_tag") or meta.get("pdca_tag", "N/A")  # ‡πÄ‡∏û‡∏¥‡πà‡∏° pdca_tag ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ ‡πÇ‡∏î‡∏¢‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å source ‡∏´‡∏£‡∏∑‡∏≠ metadata
                    })
                    seen_in_lv.add(doc_key)

        # --- 5. Roadmap & Action Plan ---
        ui_roadmap = []
        raw_plans = res.get("action_plan") or []
        for p in raw_plans:
            ui_roadmap.append({
                "phase": p.get("phase", "‡πÅ‡∏ú‡∏ô‡∏á‡∏≤‡∏ô‡∏û‡∏±‡∏í‡∏ô‡∏≤"),
                "goal": p.get("goal", "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏¢‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡πÄ‡∏Å‡∏ì‡∏ë‡πå"),
                "tasks": [
                    {
                        "level": str(act.get("failed_level", highest_pass + 1)),
                        "recommendation": act.get("recommendation", ""),
                        "steps": [
                            {
                                "step": str(s.get("step") or i+1),
                                "description": s.get("description", ""),
                                "responsible": s.get("responsible", "‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å")
                            } for i, s in enumerate(act.get("steps", []))
                        ]
                    } for act in p.get("actions", [])
                ]
            })

        # --- 6. Hybrid Summary & Gap ---
        evidence_analysis = ""
        if pdca_matrix:
            for m in reversed(pdca_matrix):
                if m.get("is_passed"):
                    evidence_analysis = m.get("reason", "")
                    break

        context_criteria = res.get("summary_thai") or ""
        sthai = f"**‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏´‡∏•‡∏±‡∏Å‡∏ê‡∏≤‡∏ô:**\n{evidence_analysis}\n\n**‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á:**\n{context_criteria}" if evidence_analysis and context_criteria else (evidence_analysis or context_criteria)

        gap_data = res.get("gap_analysis") or res.get("gap") or ""
        if not gap_data.strip() and ui_roadmap:
            gap_list = [f"L{t['level']}: {t['recommendation']}" for ph in ui_roadmap for t in ph.get("tasks", []) if t.get("recommendation")]
            gap_data = "\n".join(gap_list)

        # --- 7. New Features: PDCA Coverage Summary, Avg Confidence, Potential Level ---
        avg_confidence_per_level = {}
        for lv in range(1, 6):
            sources = grouped_sources[str(lv)]
            if sources:
                avg = sum(s['rerank_score'] for s in sources) / len(sources)
                avg_confidence_per_level[lv] = round(avg, 2)
            else:
                avg_confidence_per_level[lv] = 0.0

        potential_level = max((r.get('level') for r in raw_levels_list if r.get('is_passed')), default=highest_pass)

        pdca_coverage = {}
        for m in pdca_matrix:
            pdca = m['pdca']
            covered = sum(1 for v in pdca.values() if v > 0)
            coverage_pct = (covered / 4 * 100) if covered else 0
            pdca_coverage[m['level']] = {
                'percentage': coverage_pct,
                'details': pdca
            }

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏•‡∏á‡πÉ‡∏ô List ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡∏ó‡∏µ‡πà UI
        processed_sub_criteria.append({
            "code": cid,
            "name": cname,
            "level": f"L{highest_pass}",
            "score": current_sub_score,
            "full_score": current_sub_full,
            "is_gap_analysis": has_higher_potential, # ‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≠‡∏Ç‡∏ß‡∏î‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            "pdca_matrix": pdca_matrix,
            "roadmap": ui_roadmap,
            "grouped_sources": grouped_sources,
            "summary_thai": sthai.strip(),
            "gap": gap_data.strip(),
            # New Features
            "avg_confidence_per_level": avg_confidence_per_level,
            "potential_level": f"L{potential_level}",
            "pdca_coverage": pdca_coverage
        })

        radar_data.append({"axis": cid, "value": int(highest_pass)})

    return {
        "status": "COMPLETED",
        "record_id": raw_data.get("record_id", "unknown"),
        "tenant": str(summary.get("tenant", "N/A")).upper(),
        "year": str(summary.get("year", "2568")),
        "enabler": enabler_name,
        "level": overall_level,
        "score": total_score,
        "full_score": full_score_all,
        "metrics": {
            "total_criteria": total_expected,
            "passed_criteria": passed_count,
            "completion_rate": round(completion_rate, 2)
        },
        "radar_data": radar_data,
        "sub_criteria": processed_sub_criteria
    }

# ------------------- API Endpoints -------------------
@assessment_router.get("/status/{record_id}")
async def get_assessment_status(record_id: str, current_user: UserMe = Depends(get_current_user)):
    # 1. ‡πÄ‡∏ä‡πá‡∏Ñ‡πÉ‡∏ô Memory ‡∏Å‡πà‡∏≠‡∏ô (‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏£‡∏±‡∏ô)
    if record_id in ACTIVE_TASKS:
        return ACTIVE_TASKS[record_id]

    # 2. ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô Memory ‡πÉ‡∏´‡πâ‡πÑ‡∏õ‡∏´‡∏≤‡πÉ‡∏ô Disk (‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß)
    # ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏à‡∏∞‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤‡∏ó‡∏∏‡∏Å‡∏õ‡∏µ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á
    file_path = _find_assessment_file(record_id, current_user)
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            raw_data = json.load(f)

        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Enabler ‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Ñ Permission
        summary = raw_data.get("summary", {})
        enabler = (summary.get("enabler") or "KM").upper()
        tenant = summary.get("tenant") or current_user.tenant
        
        check_user_permission(current_user, tenant, enabler)

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ UI
        return _transform_result_for_ui(raw_data, current_user)
    except Exception as e:
        logger.error(f"Error loading status for {record_id}: {e}")
        raise HTTPException(status_code=500, detail="‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÑ‡∏î‡πâ")

@assessment_router.get("/history")
async def get_assessment_history(
    tenant: str, 
    year: Optional[str] = Query(None), # ‡πÅ‡∏Å‡πâ‡∏à‡∏≤‡∏Å Union ‡πÄ‡∏õ‡πá‡∏ô Optional ‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ default ‡πÄ‡∏õ‡πá‡∏ô None
    current_user: UserMe = Depends(get_current_user)
):
    # 1. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏≠‡∏á‡∏Ñ‡πå‡∏Å‡∏£
    if _n(tenant) != _n(current_user.tenant):
        raise HTTPException(status_code=403, detail="Permission Denied")

    history_list = []
    
    # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á "‡∏õ‡∏µ" ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤
    # ‡∏ñ‡πâ‡∏≤ Frontend ‡πÑ‡∏°‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô "all" ‡πÉ‡∏´‡πâ‡∏™‡πÅ‡∏Å‡∏ô‡∏ó‡∏∏‡∏Å‡∏õ‡∏µ
    search_years = []
    
    # ‡∏´‡∏≤ Root Path ‡∏Ç‡∏≠‡∏á Tenant ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏µ‡πÑ‡∏´‡∏ô‡∏ö‡πâ‡∏≤‡∏á
    # ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏µ 2568 (‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏µ‡πÉ‡∏î‡∏Å‡πá‡πÑ‡∏î‡πâ)
    sample_path = get_tenant_year_export_root(tenant, "2568")
    tenant_export_root = os.path.dirname(sample_path)

    if not year or str(year).lower() == "all":
        if os.path.exists(tenant_export_root):
            # ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏¢‡πà‡∏≠‡∏¢‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (‡∏õ‡∏µ‡∏á‡∏ö‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì) ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
            search_years = [d for d in os.listdir(tenant_export_root) if d.isdigit()]
        else:
            search_years = []
    else:
        search_years = [str(year)]

    # 3. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå JSON ‡∏ï‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
    for y in search_years:
        export_root = get_tenant_year_export_root(tenant, y)
        
        if not os.path.exists(export_root):
            continue

        for root, _, files in os.walk(export_root):
            for f in files:
                if f.lower().endswith(".json"):
                    try:
                        file_path = os.path.join(root, f)
                        with open(file_path, "r", encoding="utf-8") as jf:
                            data = json.load(jf)
                            summary = data.get("summary", {})
                            enabler = (summary.get("enabler") or "KM").upper()
                            
                            # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏£‡∏≤‡∏¢ Enabler (‡∏ñ‡πâ‡∏≤‡∏û‡∏±‡∏á‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≤‡∏°‡πÑ‡∏ü‡∏•‡πå‡∏ô‡∏µ‡πâ‡πÑ‡∏õ)
                            try:
                                check_user_permission(current_user, tenant, enabler)
                            except:
                                continue

                            history_list.append({
                                "record_id": data.get("record_id") or summary.get("record_id") or f.rsplit('.', 1)[0],
                                "date": parse_safe_date(summary.get("export_timestamp"), file_path),
                                "tenant": tenant,
                                "year": y,
                                "enabler": enabler,
                                "scope": summary.get("sub_criteria_id", "ALL"),
                                "level": f"L{summary.get('highest_pass_level_overall', summary.get('highest_pass_level', 0))}",
                                "score": round(float(summary.get("Total Weighted Score Achieved", summary.get("achieved_weight", 0.0))), 2),
                                "status": "COMPLETED"
                            })
                    except Exception as e:
                        logger.error(f"Error reading history file {f} in year {y}: {e}")

    # 4. ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏•‡∏≥‡∏î‡∏±‡∏ö‡∏ï‡∏≤‡∏°‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà (‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏õ‡πÄ‡∏Å‡πà‡∏≤)
    return {"items": sorted(history_list, key=lambda x: x['date'], reverse=True)}

@assessment_router.post("/start")
async def start_assessment(
    request: StartAssessmentRequest, 
    background_tasks: BackgroundTasks, 
    current_user: UserMe = Depends(get_current_user)
):
    """
    Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏≠‡∏¥‡∏™‡∏£‡∏∞
    - ‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏ä‡πâ‡∏õ‡∏µ‡∏à‡∏≤‡∏Å Request ‡πÄ‡∏õ‡πá‡∏ô‡∏≠‡∏±‡∏ô‡∏î‡∏±‡∏ö‡πÅ‡∏£‡∏Å
    - ‡∏£‡∏∞‡∏ö‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö Path ‡πÅ‡∏ö‡∏ö‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Docker/Local Path)
    """
    # 1. ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ñ‡πà‡∏≤ Parameter
    enabler_uc = request.enabler.upper()
    
    # --- ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á Logic ‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏õ‡∏µ (Priority: Request > User Profile > Default) ---
    raw_year = request.year if request.year else (current_user.year or DEFAULT_YEAR)
    target_year = str(raw_year).strip()
    
    target_sub = str(request.sub_criteria).strip().lower() if request.sub_criteria else "all"

    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå
    check_user_permission(current_user, request.tenant, enabler_uc)

    # --- [ERROR DETECTION: Enhanced Pre-flight Check] ---
    from utils.path_utils import get_vectorstore_collection_path, get_vectorstore_tenant_root_path

    # ‡∏´‡∏≤ Path ‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
    vs_path = get_vectorstore_collection_path(
        tenant=request.tenant,
        year=target_year,
        doc_type="evidence",
        enabler=enabler_uc
    )

    # üõ°Ô∏è FIX: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏∑‡∏î‡∏´‡∏¢‡∏∏‡πà‡∏ô‡∏Ç‡∏≠‡∏á Path (‡∏Å‡∏£‡∏ì‡∏µ‡∏£‡∏±‡∏ô‡∏ö‡∏ô Server ‡∏ó‡∏µ‡πà Path ‡∏≠‡∏≤‡∏à‡∏ï‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡πÉ‡∏ô Container)
    resolved_vs_path = vs_path
    if not os.path.exists(resolved_vs_path) and vs_path.startswith("/app/"):
        # ‡∏•‡∏≠‡∏á‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏ï‡∏±‡∏î /app/ ‡∏≠‡∏≠‡∏Å (Local mode)
        alt_path = vs_path.replace("/app/", "", 1)
        if os.path.exists(alt_path):
            resolved_vs_path = alt_path

    # A. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏õ‡∏µ‡∏ô‡∏±‡πâ‡∏ô‡πÜ ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡πÑ‡∏´‡∏°
    if not os.path.exists(resolved_vs_path):
        vs_tenant_root = get_vectorstore_tenant_root_path(request.tenant)
        # ‡∏•‡∏≠‡∏á‡∏™‡πÅ‡∏Å‡∏ô‡∏´‡∏≤ Path ‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ User
        real_root = vs_tenant_root.replace("/app/", "", 1) if not os.path.exists(vs_tenant_root) else vs_tenant_root
        
        available_info = ""
        if os.path.exists(real_root):
            years = [d for d in os.listdir(real_root) if os.path.isdir(os.path.join(real_root, d))]
            if years:
                available_info = f" ‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡∏∑‡∏≠: {', '.join(years)}"
            else:
                available_info = " ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ‡πÉ‡∏î‡πÜ ‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"
        
        logger.error(f"‚ùå Path Not Found: {vs_path} (Resolved: {resolved_vs_path})")
        raise HTTPException(
            status_code=400, 
            detail=f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {enabler_uc} ‡∏Ç‡∏≠‡∏á‡∏õ‡∏µ {target_year}.{available_info}"
        )

    # B. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≤‡∏á‡πÉ‡∏ô (‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡πà‡∏≤‡∏á)
    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ó‡∏±‡πâ‡∏á chroma.sqlite3 ‡∏´‡∏£‡∏∑‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå UUID ‡∏Ç‡∏≠‡∏á Chroma
    db_file = os.path.join(resolved_vs_path, "chroma.sqlite3")
    has_subdirs = any(os.path.isdir(os.path.join(resolved_vs_path, d)) for d in os.listdir(resolved_vs_path)) if os.path.exists(resolved_vs_path) else False
    
    if not os.path.exists(db_file) and not has_subdirs:
        raise HTTPException(
            status_code=400, 
            detail=f"‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ {target_year} ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ñ‡∏π‡∏Å Ingest ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤)"
        )

    # --------------------------------------------------------

    # 3. ‡∏™‡∏£‡πâ‡∏≤‡∏á Record ID
    record_id = uuid.uuid4().hex[:12]
    
    # 4. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏•‡∏á ACTIVE_TASKS
    ACTIVE_TASKS[record_id] = {
        "status": "RUNNING",
        "record_id": record_id,
        "tenant": request.tenant,
        "year": target_year,
        "enabler": enabler_uc,
        "progress_message": f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô {enabler_uc} ‡∏õ‡∏µ {target_year}..."
    }

    # 5. ‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤ Background Task
    background_tasks.add_task(
        run_assessment_engine_task,
        record_id=record_id,
        tenant=request.tenant,
        year=target_year,
        enabler=enabler_uc,
        sub_id=target_sub,
        sequential=request.sequential_mode
    )

    logger.info(f"üöÄ Started Assessment: {record_id} | Year: {target_year} | Path: {resolved_vs_path}")
    return {"record_id": record_id, "status": "RUNNING"}

async def run_assessment_engine_task(
    record_id: str, 
    tenant: str, 
    year: str,  # ‡πÅ‡∏Å‡πâ Type Hint ‡πÄ‡∏õ‡πá‡∏ô str
    enabler: str, 
    sub_id: str, 
    sequential: bool
):
    try:
        str_year = year # ‡πÉ‡∏ä‡πâ‡∏á‡πà‡∏≤‡∏¢‡πÜ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏õ‡∏•‡∏á
        logger.info(f"üöÄ [TASK START] Record: {record_id} | Enabler: {enabler} | Sub-ID: {sub_id} | Year: {str_year}")

        # 1. Load Vectorstores (‡πÉ‡∏ä‡πâ str_year ‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏õ‡∏´‡∏≤ Path)
        vsm = await asyncio.to_thread(
            load_all_vectorstores,
            doc_types=EVIDENCE_DOC_TYPES,
            enabler_filter=enabler,
            tenant=tenant,
            year=str_year
        )
        
        # 2. Load Document Mapping
        doc_map_raw = await asyncio.to_thread(
            load_doc_id_mapping, 
            EVIDENCE_DOC_TYPES, 
            tenant, 
            str_year, 
            enabler
        )
        doc_map = {d_id: d.get("file_name", d_id) for d_id, d in doc_map_raw.items()}

        # 3. Create LLM & Engine
        llm = await asyncio.to_thread(create_llm_instance, model_name=DEFAULT_LLM_MODEL_NAME, temperature=0.0)
        config = AssessmentConfig(enabler=enabler, tenant=tenant, year=str_year, force_sequential=sequential)

        engine = SEAMPDCAEngine(
            config=config,
            llm_instance=llm,
            logger_instance=logger,
            doc_type=EVIDENCE_DOC_TYPES,
            vectorstore_manager=vsm,
            document_map=doc_map
        )

        # 4. Execution
        result = await asyncio.to_thread(
            engine.run_assessment, 
            target_sub_id=sub_id, 
            export=True, 
            vectorstore_manager=vsm, 
            sequential=sequential, 
            record_id=record_id,
            document_map=doc_map
        )

        if isinstance(result, dict) and result.get("status") == "FAILED":
            error_msg = result.get("error_message", "Engine reported an error")
            logger.error(f"‚ùå [TASK FAILED] {record_id}: {error_msg}")
            if record_id in ACTIVE_TASKS:
                ACTIVE_TASKS[record_id]["status"] = "FAILED"
                ACTIVE_TASKS[record_id]["error_message"] = error_msg
            return

        if record_id in ACTIVE_TASKS:
            del ACTIVE_TASKS[record_id]
            logger.info(f"‚úÖ [TASK COMPLETED] Record: {record_id}")
            
    except Exception as e:
        logger.error(f"üí• [TASK CRASH] Record {record_id}: {str(e)}", exc_info=True)
        if record_id in ACTIVE_TASKS:
            ACTIVE_TASKS[record_id]["status"] = "FAILED"
            ACTIVE_TASKS[record_id]["error_message"] = f"Internal Server Error: {str(e)}"

@assessment_router.get("/download/{record_id}/{file_type}")
async def download_assessment_file(record_id: str, file_type: str, current_user: UserMe = Depends(get_current_user)):
    file_path = _find_assessment_file(record_id, current_user)

    expected_ext = f".{file_type.lower()}"
    if file_type.lower() == "word":
        expected_ext = ".docx"

    if not file_path.endswith(expected_ext):
        raise HTTPException(status_code=404, detail="‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á")

    with open(file_path, "r", encoding="utf-8") as f:
        raw_data = json.load(f)
        enabler = (raw_data.get("summary", {}).get("enabler") or "KM").upper()
        check_user_permission(current_user, current_user.tenant, enabler)

    return FileResponse(path=file_path, filename=os.path.basename(file_path))
